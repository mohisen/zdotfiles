/home/bani/Desktop/aliases.zsh.html:<span class="Statement">echo</span> <span class="Constant">&quot;</span><span class="Constant">alias '</span><span class="PreProc">$1</span><span class="Constant">'='</span><span class="PreProc">$2</span><span class="Constant">'</span><span class="Constant">&quot;</span> <span class="Statement">&gt;&gt;</span> ~/.bash_aliases
/home/bani/Desktop/aliases.zsh.html:<span class="Statement">alias</span> update-aliases=<span class="Constant">&quot;</span><span class="Constant">wget -q -O - </span><span class="Special">\&quot;</span><span class="PreProc">$@</span><span class="Special">\&quot;</span><span class="Constant"> <a href="https://alias.sh/user/">https://alias.sh/user/</a></span><span class="PreProc">$ALIAS_SH_USER_ID</span><span class="Constant">/alias &gt; ~/.zsh_alias_sh &amp;&amp; source ~/.zsh_alias_sh</span><span class="Constant">&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Statement">alias</span> update-aliases=<span class="Constant">&quot;</span><span class="Constant">wget -q -O - </span><span class="Special">\&quot;</span><span class="PreProc">$@</span><span class="Special">\&quot;</span><span class="Constant"> <a href="https://alias.sh/user/">https://alias.sh/user/</a></span><span class="PreProc">$ALIAS_SH_USER_ID</span><span class="Constant">/alias &gt; ~/.zsh_alias_sh &amp;&amp; source ~/.oh-my-zsh/lib/aliases.zsh</span><span class="Constant">&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Statement">echo</span> <span class="Constant">&quot;</span><span class="Constant">alias '</span><span class="PreProc">$1</span><span class="Constant">'='</span><span class="PreProc">$2</span><span class="Constant">'</span><span class="Constant">&quot;</span> <span class="Statement">&gt;&gt;</span> ~/.bash_aliases
/home/bani/Desktop/aliases.zsh.html:<span class="Statement">alias</span> update-aliases=<span class="Constant">&quot;</span><span class="Constant">wget -q -O - </span><span class="Special">\&quot;</span><span class="PreProc">$@</span><span class="Special">\&quot;</span><span class="Constant"> <a href="https://alias.sh/user/">https://alias.sh/user/</a></span><span class="PreProc">$ALIAS_SH_USER_ID</span><span class="Constant">/alias &gt; ~/.bash_aliases &amp;&amp; source ~/.bash_aliases</span><span class="Constant">&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias sud=</span><span class="Constant">'</span>sudo -s<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias lr=</span><span class="Constant">'</span>ls -R<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ll=</span><span class="Constant">'</span>ls -lF<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias llr=</span><span class="Constant">'</span>ll -R<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias lll=</span><span class="Constant">'</span>ls -alF<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias le=</span><span class="Constant">'</span>ls --sort=extension<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias lle=</span><span class="Constant">'</span>ll --sort=extension<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias lt=</span><span class="Constant">'</span>ls --sort=<span class="Special">time</span><span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias llt=</span><span class="Constant">'</span>ll --sort=<span class="Special">time</span><span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias edit-aliases=</span><span class="Constant">'</span>nano ~/.bash_aliases<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias l=</span><span class="Constant">'</span>ls -lah<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias wcr=</span><span class="Constant">'</span>wc <span class="PreProc">`</span><span class="PreProc">find</span><span class="Statement"> .</span><span class="PreProc"> -type f</span><span class="PreProc">`</span><span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias rm=</span><span class="Constant">'</span>rm -I<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias gg=&quot;sr google -browser=$BROWSER&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias h=</span><span class="Constant">'</span><span class="Statement">cd</span> <span class="PreProc">$HOME</span><span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias erase=</span><span class="Constant">'</span>shred -n <span class="Constant">35</span> -z -u<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias sulast=</span><span class="Constant">'</span>su -c <span class="PreProc">$(</span><span class="Statement">history</span> -p !-1<span class="PreProc">)</span> root<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ll=</span><span class="Constant">'</span>ls -alFrth<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias sandbox=</span><span class="Constant">'</span><span class="Statement">source</span> <span class="PreProc">${</span><span class="PreProc">HOME</span><span class="PreProc">}</span>/sandbox/bin/activate<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias prs=</span><span class="Constant">'</span>ps faux<span class="Statement">|</span>grep -v grep<span class="Statement">|</span>grep <span class="Constant">&quot;</span><span class="PreProc">$@</span><span class="Constant">&quot;'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias git-root=</span><span class="Constant">'</span>root=<span class="Constant">&quot;</span><span class="PreProc">$(</span><span class="Constant">git rev-parse --show-cdup</span><span class="PreProc">)</span><span class="Constant">&quot;</span>; [ -n <span class="Constant">&quot;</span><span class="PreProc">$root</span><span class="Constant">&quot;</span> ] &amp;&amp; <span class="Statement">cd</span> <span class="Constant">&quot;</span><span class="PreProc">$root</span><span class="Constant">&quot;'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias drupal-sandbox=</span><span class="Constant">'</span>drush qd --db-url=<span class="Constant">&quot;</span><span class="Constant">mysql://user:pass@localhost:3306/db_name</span><span class="Constant">&quot;</span> -y<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias d=</span><span class="Constant">'</span>git diff<span class="Statement">|</span>tig<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias grphp=</span><span class="Constant">'</span>ps -auwx <span class="Statement">|</span> grep php<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ll=</span><span class="Constant">'</span>ls -lhF<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias lla=</span><span class="Constant">'</span>ls -lhFA<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias back=</span><span class="Constant">'</span><span class="Statement">cd</span> <span class="Special">-</span><span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias cd..=</span><span class="Constant">'</span><span class="Statement">cd</span> ..<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias fn=</span><span class="Constant">'</span>find -name<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias fin=</span><span class="Constant">'</span>find -iname<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias fwn=</span><span class="Constant">'</span>find -wholename<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias lns=</span><span class="Constant">'</span>ln -s<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias confcat=&quot;sed -e </span><span class="Constant">'</span>s/[#;].*//;/^<span class="Special">\s</span>*$/d<span class="Constant">'</span><span class="Constant"> &quot;$@&quot;&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias scw=</span><span class="Constant">'</span>screen -wipe<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias sls=</span><span class="Constant">'</span>screen -ls<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias update-aliases=</span><span class="Constant">'</span>wget -q -O <span class="Special">-</span> <span class="Special">\&quot;</span><span class="PreProc">$@</span><span class="Special">\&quot;</span> <a href="https://">https://</a><span class="Statement">alias</span>.sh/user/<span class="PreProc">$ALIAS_SH_USER_ID</span>/<span class="Statement">alias</span> <span class="Statement">&gt;</span> ~/.bash_aliases &amp;&amp; <span class="Statement">source</span> ~/.bash_aliases<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias upgrade=</span><span class="Constant">'</span>apt-get update &amp;&amp; apt-get upgrade &amp;&amp; apt-get clean<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias mkvenv=</span><span class="Constant">'</span>virtualenv --distribute --no-site-packages venv<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias la=</span><span class="Constant">'</span>ls -a<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias rfresh=</span><span class="Constant">'</span> rsync -avz --progress -e  <span class="Constant">&quot;</span><span class="Constant">ssh -p 2233</span><span class="Constant">&quot;</span> user@<span class="Constant">110.11</span>.<span class="Constant">11.11</span>:/your/remote/path /my/<span class="Type">local</span>/path<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias sa=</span><span class="Constant">'</span>ssh-add <span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias whead=</span><span class="Constant">'</span>curl --head <span class="PreProc">$1</span><span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ls=</span><span class="Constant">'</span>ls -alh<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias logs=</span><span class="Constant">'</span>tail -n30 /var/<span class="Statement">log</span>/apache2/error.<span class="Statement">log</span><span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias a2-restart=</span><span class="Constant">'</span>sudo service apache2 restart<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias aa=&quot;git add -A .&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ANYNAMEHERE=</span><span class="Constant">'</span> ssh YOURWEBSITE.com -l USERNAME -p PORTNUMBERHERE<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias gc=&quot;git commit -m &quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias co=&quot;git checkout &quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias gp=&quot;git pull origin &quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias gpm=&quot;gp master&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias pm=&quot;git push origin master&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias gb=&quot;git branch&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant"> alias gs=&quot;git status&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias g=</span><span class="Constant">'</span>grep -P<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias update-aliases=&quot;wget -q -O - \&quot;$@\&quot; <a href="https://alias.sh/user/$ALIAS_SH_USER_ID/alias">https://alias.sh/user/$ALIAS_SH_USER_ID/alias</a> &gt; ~/.zsh_alias_sh &amp;&amp; source ~/.zsh_alias_sh&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ipy=&quot;python -c </span><span class="Constant">'</span>import IPython; IPython.frontend.terminal.ipapp.launch_new_instance()<span class="Constant">'</span><span class="Constant">&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias clr=</span><span class="Constant">'</span>clear;<span class="Statement">pwd</span>;ls<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias vmi=</span><span class="Constant">'</span>vim<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ivm=</span><span class="Constant">'</span>vim<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias cim=</span><span class="Constant">'</span>vim<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias bim=</span><span class="Constant">'</span>vim<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias vi=</span><span class="Constant">'</span>vim<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias sshr=&quot;ssh -l root&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias reload=</span><span class="Constant">'</span><span class="Statement">source</span> <span class="PreProc">$HOME</span>/.bashrc <span class="Constant">1</span><span class="Statement">&gt;</span>/dev/null<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias la=</span><span class="Constant">'</span>ll -a<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ll=</span><span class="Constant">'</span>ls -l<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias realias=</span><span class="Constant">'</span><span class="PreProc">$EDITOR</span> ~/.bash_aliases &amp;&amp; <span class="Statement">source</span> ~/.bash_aliases<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias refunction=</span><span class="Constant">'</span><span class="PreProc">$EDITOR</span> ~/.bash_functions &amp;&amp; <span class="Statement">source</span> ~/.bash_functions<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias sulast=</span><span class="Constant">'</span>sudo <span class="PreProc">$(</span><span class="Statement">history</span> -p !-1<span class="PreProc">)</span><span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias lf=</span><span class="Constant">'</span>/bin/ls -rt<span class="Statement">|</span>tail -n1<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias l=</span><span class="Constant">'</span>ls -CF<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias la=</span><span class="Constant">'</span>ls -A<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ll=</span><span class="Constant">'</span>ls -l --color=auto<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias grep=</span><span class="Constant">'</span>grep --color=auto<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ls=</span><span class="Constant">'</span>ls --color=auto<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias clear=</span><span class="Constant">'</span><span class="Statement">printf</span> <span class="Constant">&quot;</span><span class="Special">\e</span><span class="Constant">c</span><span class="Constant">&quot;'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias trash=</span><span class="Constant">'</span>rm -f *~; <span class="Statement">true</span><span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ll=&quot;ls -l&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias l=&quot;ls -al&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias update=</span><span class="Constant">'</span>sudo apt-get update<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias cgrep=</span><span class="Constant">'</span>grep --color=<span class="Statement">always</span><span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias remove=</span><span class="Constant">'</span>sudo apt-get remove<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias install=</span><span class="Constant">'</span>sudo apt-get install<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias k9=</span><span class="Constant">'</span><span class="Statement">kill</span> -9<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias gs=</span><span class="Constant">'</span>git status<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias gd=&quot;git diff&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias gc=&quot;git commit&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias gl=&quot;git log --graph --full-history --all --color&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias cbuild=&quot;mkdir build &amp;&amp; cd build; cmake ..; make&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ifconfig-ext=</span><span class="Constant">'</span>curl ifconfig.me<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ..1=</span><span class="Constant">'</span><span class="Statement">cd</span> ..<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ..2=</span><span class="Constant">'</span><span class="Statement">cd</span> ../../../<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ..3=</span><span class="Constant">'</span><span class="Statement">cd</span> ../../../../<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ..4=</span><span class="Constant">'</span><span class="Statement">cd</span> ../../../../<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ..5=</span><span class="Constant">'</span><span class="Statement">cd</span> ../../../../../<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias copy=&quot;cp&quot;           # name file -- dir target</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias del=&quot;rm -i&quot;         # name file</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias dir=&quot;ls&quot;              # list of files</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias md=&quot;mkdir&quot;       # name of new dir</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias rd=&quot;rmdir&quot;         # name of dir</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias rename=&quot;mv&quot;     # name file -- dir and new rename file</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias l=&quot;ls -ltr&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias f=&quot;find . | xargs grep -sl&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias gm=</span><span class="Constant">'</span>git merge<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias process=</span><span class="Constant">'</span>ps -ax<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias sniff=</span><span class="Constant">'</span>sudo ngrep -d <span class="Constant">'</span><span class="Constant">en1</span><span class="Constant">'</span> -t <span class="Constant">'</span><span class="Constant">^(GET|POST) </span><span class="Constant">'</span> <span class="Constant">'</span><span class="Constant">tcp and port 80</span><span class="Constant">''</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias sniff=</span><span class="Constant">'</span>sudo ngrep -d <span class="Constant">'</span><span class="Constant">en1</span><span class="Constant">'</span> -t <span class="Constant">'</span><span class="Constant">^(GET|POST) </span><span class="Constant">'</span> <span class="Constant">'</span><span class="Constant">tcp and port 80</span><span class="Constant">''</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias sweep=</span><span class="Constant">'</span>find ~ -type f <span class="Special">\(</span> -name <span class="Constant">'</span><span class="Constant">*.swp</span><span class="Constant">'</span> -o -name <span class="Constant">'</span><span class="Constant">wget.log</span><span class="Constant">'</span> -o -name <span class="Constant">'</span><span class="Constant">foobar*</span><span class="Constant">'</span> -o -name <span class="Constant">'</span><span class="Constant">*~</span><span class="Constant">'</span> -o -name <span class="Constant">'</span><span class="Constant">.netrwhist</span><span class="Constant">'</span>  <span class="Special">\)</span> -delete<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias gb=&quot;git checkout -b&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias open=</span><span class="Constant">'</span>xdg-open<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias display=</span><span class="Constant">'</span>less +F<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias please=&quot;sudo&quot;</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias tm=</span><span class="Constant">'</span>ps -ef <span class="Statement">|</span> grep<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias lf=</span><span class="Constant">'</span>ls -Gl <span class="Statement">|</span> grep ^d<span class="Constant">'</span><span class="Constant"> #Only list directories</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias lsd=</span><span class="Constant">'</span>ls -Gal <span class="Statement">|</span> grep ^d<span class="Constant">'</span><span class="Constant"> #Only list directories, including hidden ones</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ls=</span><span class="Constant">'</span>ls --color=auto<span class="Constant">'</span><span class="Constant"> #For Linux</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ls=</span><span class="Constant">'</span>ls -G<span class="Constant">'</span><span class="Constant"> #For OSX</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias lg=</span><span class="Constant">'</span>git <span class="Statement">log</span> --graph --full-history --all --color --pretty=format:<span class="Constant">&quot;</span><span class="Constant">%x1b[31m%h%x09%x1b[32m%d%x1b[0m%x20%s</span><span class="Constant">&quot;'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias gpm=</span><span class="Constant">'</span>git push origin master<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias sc=</span><span class="Constant">'</span>screen -S<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias sl=</span><span class="Constant">'</span>screen -ls<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias sr=</span><span class="Constant">'</span>screen -r<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias active=</span><span class="Constant">'</span>grep -v -e <span class="Constant">&quot;</span><span class="Constant">^$</span><span class="Constant">&quot;</span> -e<span class="Constant">&quot;</span><span class="Constant">^ *#</span><span class="Constant">&quot;'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias freq=</span><span class="Constant">'</span>cut -f1 -d<span class="Constant">&quot;</span><span class="Constant"> </span><span class="Constant">&quot;</span> ~/.bash_history <span class="Statement">|</span> sort <span class="Statement">|</span> uniq -c <span class="Statement">|</span> sort -nr <span class="Statement">|</span> head -n <span class="Constant">30</span><span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ..=</span><span class="Constant">'</span><span class="Statement">cd</span> ..<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ...=</span><span class="Constant">'</span><span class="Statement">cd</span> ../../<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ....=</span><span class="Constant">'</span><span class="Statement">cd</span> ../../../<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias .....=</span><span class="Constant">'</span><span class="Statement">cd</span> ../../../../<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias ......=</span><span class="Constant">'</span><span class="Statement">cd</span> ../../../../../<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias l.=</span><span class="Constant">'</span>ls -d .* --color=auto<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias c=</span><span class="Constant">'</span>clear<span class="Constant">'</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Constant">alias lr=</span><span class="Constant">'</span>ls -R <span class="Statement">|</span> grep <span class="Constant">&quot;</span><span class="Constant">:$</span><span class="Constant">&quot;</span> <span class="Statement">|</span> sed -e <span class="Constant">'</span><span class="Constant">\</span><span class="Constant">''</span><span class="Constant">s/:$//</span><span class="Constant">'</span><span class="Special">\'</span><span class="Constant">'</span><span class="Constant"> -e </span><span class="Constant">'</span><span class="Special">\'</span><span class="Constant">'</span><span class="Constant">s/[^-][^\/]*\//--/g</span><span class="Constant">'</span><span class="Special">\'</span><span class="Constant">'</span><span class="Constant"> -e </span><span class="Constant">'</span><span class="Special">\'</span><span class="Constant">'</span><span class="Constant">s/^/   /</span><span class="Constant">'</span><span class="Special">\'</span><span class="Constant">'</span><span class="Constant"> -e </span><span class="Constant">'</span><span class="Special">\'</span><span class="Constant">'</span><span class="Constant">s/-/|/</span><span class="Constant">'</span><span class="Special">\'</span><span class="Constant">''</span>
/home/bani/Desktop/aliases.zsh.html:<span class="Statement">alias</span> al=<span class="Constant">'</span><span class="Constant">alias | grep</span><span class="Constant">'</span>
/home/bani/... call urlview to extract URLs out of a message:3.7. Configuring external alias files
/home/bani/... call urlview to extract URLs out of a message:The alias menu is used to help users finding the recipients of messages. For
/home/bani/... call urlview to extract URLs out of a message:names completely because it allows for searching, too. The alias mechanism and
/home/bani/... call urlview to extract URLs out of a message:thus the alias menu also features grouping several addresses by a shorter
/home/bani/... call urlview to extract URLs out of a message:│<Tab>         │<complete>       │complete filename or alias          │
/home/bani/... call urlview to extract URLs out of a message:    Creates a new alias based upon the current message (or prompts for a new
/home/bani/... call urlview to extract URLs out of a message:    one). Once editing is complete, an alias command is added to the file
/home/bani/... call urlview to extract URLs out of a message:alias [ -group name ...] key address [ address ...]
/home/bani/... call urlview to extract URLs out of a message:unalias [ -group name ...] { * | key ... }
/home/bani/... call urlview to extract URLs out of a message:If you want to create an alias for more than one address, you must separate the
/home/bani/... call urlview to extract URLs out of a message:The optional -group argument to alias causes the aliased address(es) to be
/home/bani/... call urlview to extract URLs out of a message:To remove an alias or aliases (“*” means all aliases):
/home/bani/... call urlview to extract URLs out of a message:alias muttdude me@cs.hmc.edu (Michael Elkins)
/home/bani/... call urlview to extract URLs out of a message:alias theguys manny, moe, jack
/home/bani/... call urlview to extract URLs out of a message:file. The alias command can appear anywhere in a configuration file, as long as
/home/bani/... call urlview to extract URLs out of a message:this file is sourced. Consequently, you can have multiple alias files, or you
/home/bani/... call urlview to extract URLs out of a message:Example 3.7. Configuring external alias files
/home/bani/... call urlview to extract URLs out of a message:To use aliases, you merely use the alias at any place in Mutt where Mutt
/home/bani/... call urlview to extract URLs out of a message:expand a partial alias to the full alias. If there are multiple matches, Mutt
/home/bani/... call urlview to extract URLs out of a message:In the alias menu, you can select as many aliases as you want with the
/home/bani/... call urlview to extract URLs out of a message:    The alias menu is the list of your personal aliases as defined in your
/home/bani/... call urlview to extract URLs out of a message:    .muttrc. It is the mapping from a short alias name to the full email
/home/bani/... call urlview to extract URLs out of a message:charset-hook alias charset
/home/bani/... call urlview to extract URLs out of a message:The charset-hook command defines an alias for a character set. This is useful
/home/bani/... call urlview to extract URLs out of a message:similar to the alias completion. In any prompt for address entry, you can use
/home/bani/... call urlview to extract URLs out of a message:│@alias  │to the default save folder as determined by the address of the alias│
/home/bani/... call urlview to extract URLs out of a message:│-A    │expand an alias                                                       │
/home/bani/... call urlview to extract URLs out of a message:  ● alias [ -group name ...] key address [ address ...]
/home/bani/... call urlview to extract URLs out of a message:    unalias [ -group name ...] { * | key ... }
/home/bani/... call urlview to extract URLs out of a message:  ● charset-hook alias charset
/home/bani/... call urlview to extract URLs out of a message:dedicated alias file.
/home/bani/... call urlview to extract URLs out of a message:│%a│alias name                                                    │
/home/bani/... call urlview to extract URLs out of a message:│%f│flags - currently, a “d” for an alias marked for deletion     │
/home/bani/... call urlview to extract URLs out of a message:│%r│address which alias expands to                                │
/home/bani/... call urlview to extract URLs out of a message:│%t│character which indicates if the alias is tagged for inclusion│
/home/bani/... call urlview to extract URLs out of a message:from your aliases in the index menu if it finds an alias that matches the
/home/bani/... call urlview to extract URLs out of a message:alias juser abd30425@somewhere.net (Joe User)
/home/bani/... call urlview to extract URLs out of a message:  ● alias (sort alphabetically by alias name)
/home/bani/... call urlview to extract URLs out of a message:│<create-alias>            │a       │create an alias from a message sender    │
/home/bani/... call urlview to extract URLs out of a message:│<create-alias>          │a       │create an alias from a message sender      │
/home/bani/... call urlview to extract URLs out of a message:│<create-alias>│a          │create an alias from a message sender      │
/home/bani/... call urlview to extract URLs out of a message:│<complete>       │<Tab>      │complete filename or alias                     │
/home/bani/.zshrc:# alias zshconfig="mate ~/.zshrc"
/home/bani/.zshrc:#POWERLINE_DETECT_SSH="true" alias ohmyzsh="mate ~/.oh-my-zsh"
/home/bani/Dropbox/tools/freeplane/doc/freeplane.mm:      <font face="SansSerif, sans-serif" color="#000000"><span style="color: #000000; font-family: SansSerif, sans-serif">To install Freeplane on Mac OS X first use the built in Software Update feature to ensure that you have all the latest available updates, especially Java. Software Update is located under the Apple logo menu in the top left-hand corner of the screen. Then download a Mac-specific version of Freeplane. The .dmg version is easiest to install, though a .zip version may also be available. When the download is complete, the file may be automatically mounted (or un-zipped) depending on your Web browser settings. Otherwise either double-click on the downloaded .dmg file to &quot;mount&quot; it, or double-click on the downloaded .zip file to un-zip it. Now you should see a Freeplane application icon, which you can drag to your Applications folder. Then you may optionally create an alias (short-cut) on the Desktop, and/or on the Dock. To run Freeplane, either double-click on its application icon (in the Applications folder) or on its Desktop short-cut, or click once on its icon in the Dock. The Freeplane Wiki has Macintosh page with more information.</span></font>
/home/bani/Dropbox/tools/freeplane/doc/freeplane.mm:<node TEXT="Antialias Edges" ID="ID_1654348959" CREATED="1311483457645" MODIFIED="1311483550591">
/home/bani/Dropbox/tools/freeplane/doc/freeplane.mm:<node TEXT="Antialias all" ID="ID_627671109" CREATED="1311483468403" MODIFIED="1311483542121">
/home/bani/Dropbox/tools/freeplane/doc/freeplane_it.mm:      Per installare Freeplane con il sistema operativo <b>Mac OS X</b>, la prima cosa &#232; assicurarsi di avere tutti gli ultimi aggiornamenti disponibili, in particolare Java. L'aggiornamento Software si trova sotto il menu logo Apple in alto a sinistra dello schermo.<br/><br/>Quindi scaricare una versione per Mac specifica di Freeplane. La versione Dmg &#232; pi&#249; facile da installare, attraverso un file .zip disponibile. Quando il download &#232; completato, il file pu&#242; essere montato automaticamente (o decompresso) a seconda delle impostazioni del browser web. In caso contrario, fare doppio clic sul file. Dmg scaricato per &quot;montare&quot;, o fare doppio clic sul file. Zip scaricato per scompattarlo.<br/><br/>Ora si dovrebbe vedere una icona dell'applicazione Freeplane, che &#232; possibile trascinare nella cartella Applicazioni. Poi si pu&#242; opzionalmente creare un alias (collegamento) sul desktop, e / o nel Dock. Per eseguire Freeplane, fare doppio clic sulla sua icona dell'applicazione (nella cartella Applicazioni) o sul suo collegamento sul desktop, oppure fare clic una volta sulla sua icona nel Dock. Il wiki di Freeplane ha una pagina per Macintosh, con ulteriori informazioni.
/home/bani/Dropbox/tools/freeplane/doc/history_en.txt:* Antialias and selection option changes are now directly applied.
Binary file /home/bani/Dropbox/tools/w2p/tazjelw/static/images/qastack_design.xcf matches
/home/bani/Dropbox/tools/w2p/tazjelw/modules/CustomAuthentication.py:            self.session.auth_alias = auth_alias
/home/bani/Dropbox/tools/w2p/tazjelw/modules/CustomAuthentication.py:        self.session.auth_alias = email
/home/bani/Dropbox/tools/w2p/tazjelw/modules/CustomAuthentication.py:        # db.auth_users.auth_alias will contain the value of auth_alias
/home/bani/Dropbox/tools/w2p/tazjelw/modules/CustomAuthentication.py:        self.session.auth_alias = auth_alias
/home/bani/Dropbox/tools/w2p/tazjelw/modules/CustomAuthentication.py:        self.session.auth_alias = None
/home/bani/Dropbox/tools/w2p/tazjelw/modules/CustomAuthentication.py:            auth_alias = self.get_user_name()
/home/bani/Dropbox/tools/w2p/tazjelw/modules/CustomAuthentication.py:                    (self.db.auth_users.auth_alias == auth_alias)).select(
/home/bani/Dropbox/tools/w2p/tazjelw/modules/CustomAuthentication.py:               if self.session.auth_alias is None else self.session.auth_alias
/home/bani/Dropbox/tools/w2p/tazjelw/modules/CustomAuthentication.py:        return self.session.auth_alias is not None
/home/bani/Dropbox/tools/w2p/tazjelw/models/db.py:    auth_alias = 'admin@qa-stack.com'
/home/bani/Dropbox/tools/w2p/tazjelw/databases/sql.log:    auth_alias CHAR(255),
/home/bani/Dropbox/tools/w2p/web2py/CHANGELOG:- fixed joins with alias tables
/home/bani/Dropbox/tools/w2p/web2py/scripts/web2py.ubuntu.sh:	# and leave 'force-reload' as an alias for 'restart'.
/home/bani/Dropbox/tools/w2p/web2py/gluon/dal.py:        with alias name.
Binary file /home/bani/Dropbox/tools/w2p/web2py/gluon/dal.pyc matches
Binary file /home/bani/Dropbox/tools/w2p/speedbird-qastack-9d1f0a7571b6/static/images/qastack_design.xcf matches
/home/bani/Dropbox/tools/w2p/speedbird-qastack-9d1f0a7571b6/modules/CustomAuthentication.py:            self.session.auth_alias = auth_alias
/home/bani/Dropbox/tools/w2p/speedbird-qastack-9d1f0a7571b6/modules/CustomAuthentication.py:        self.session.auth_alias = email
/home/bani/Dropbox/tools/w2p/speedbird-qastack-9d1f0a7571b6/modules/CustomAuthentication.py:        # db.auth_users.auth_alias will contain the value of auth_alias
/home/bani/Dropbox/tools/w2p/speedbird-qastack-9d1f0a7571b6/modules/CustomAuthentication.py:        self.session.auth_alias = auth_alias
/home/bani/Dropbox/tools/w2p/speedbird-qastack-9d1f0a7571b6/modules/CustomAuthentication.py:        self.session.auth_alias = None
/home/bani/Dropbox/tools/w2p/speedbird-qastack-9d1f0a7571b6/modules/CustomAuthentication.py:            auth_alias = self.get_user_name()
/home/bani/Dropbox/tools/w2p/speedbird-qastack-9d1f0a7571b6/modules/CustomAuthentication.py:                    (self.db.auth_users.auth_alias == auth_alias)).select(
/home/bani/Dropbox/tools/w2p/speedbird-qastack-9d1f0a7571b6/modules/CustomAuthentication.py:               if self.session.auth_alias is None else self.session.auth_alias
/home/bani/Dropbox/tools/w2p/speedbird-qastack-9d1f0a7571b6/modules/CustomAuthentication.py:        return self.session.auth_alias is not None
/home/bani/Dropbox/tools/w2p/speedbird-qastack-9d1f0a7571b6/models/db.py:    auth_alias = 'admin@qa-stack.com'
/home/bani/Dropbox/tools/kubuntu/shell/xclip_bash.txt:It also comes with a handy cb_ssh alias that copies your SSH public key to the
/home/bani/Dropbox/tools/kubuntu/shell/xclip_bash.txt:alias cbssh="cb ~/.ssh/id_rsa.pub"  
/home/bani/Dropbox/tools/kubuntu/shell/xclip_bash.txt:alias cbwd="pwd | cb"  
/home/bani/Dropbox/tools/kubuntu/shell/xclip_bash.txt:alias cbhs="cat $HISTFILE | tail -n 1 | cb"  
/home/bani/Dropbox/tools/kubuntu/kate/kate_2013/ktexteditor_snippets/data/zsh.xml:alias -g ND='*(/om[1])' # newest directory
/home/bani/Dropbox/tools/kubuntu/kate/kate_2013/ktexteditor_snippets/data/zsh.xml:alias -g NF='*(.om[1])' # newest file
/home/bani/Dropbox/tools/kubuntu/kate/kate_2013/ktexteditor_snippets/data/zsh.xml:alias -g G='| grep -'
/home/bani/Dropbox/tools/kubuntu/kate/kate_2013/ktexteditor_snippets/data/zsh.xml:alias -g L='| less'
/home/bani/Dropbox/tools/kubuntu/kate/kate_2013/ktexteditor_snippets/data/zsh.xml:alias -g R=' > /c/aaa/tee.txt '           # redirect
/home/bani/Dropbox/tools/kubuntu/kate/kate_2013/ktexteditor_snippets/data/zsh.xml:alias -g T=' | tee /c/aaa/tee.txt '       # tee
/home/bani/Dropbox/tools/kubuntu/kate/kate_2013/ktexteditor_snippets/data/zsh.xml:alias -g F=' | fmt -'                     # format
/home/bani/Dropbox/tools/kubuntu/kate/kate_2013/ktexteditor_snippets/data/zsh.xml:alias -g W=' | wc -l'                     # wc
/home/bani/Dropbox/tools/kubuntu/kate/kate_2013/ktexteditor_snippets/data/zsh.xml:alias '..'='cd ..'
/home/bani/Dropbox/tools/kubuntu/kate/kate_2013/ktexteditor_snippets/data/zsh.xml:alias -g ...='../..'
/home/bani/Dropbox/tools/kubuntu/kate/kate_2013/ktexteditor_snippets/data/zsh.xml:alias -g ....='../../..'
/home/bani/Dropbox/tools/kubuntu/kate/kate_2013/ktexteditor_snippets/data/zsh.xml:alias -g .....='../../../..'
/home/bani/Dropbox/tools/kubuntu/kate/kate_2013/ktexteditor_snippets/data/zsh.xml:alias -s jpg='/c/program\ files/IrfanView/i_view32.exe'
/home/bani/Dropbox/tools/kubuntu/kate/kate_2013/ktexteditor_snippets/data/zsh.xml:alias -s php='c:/wamp/php/php.exe'  # now just type test.php to execute it *N*
/home/bani/Dropbox/tools/kubuntu/autokey/ak_2012/0_backup/AK_tazjelw 1/W/c/zbash/cml/You can also make....txt:alias LANshare='python -c "import SimpleHTTPServer; SimpleHTTPServer.test();"'
/home/bani/Dropbox/tools/kubuntu/autokey/ak_2012/0_backup/ak/bp-AK_tazjel_/w/Do/Shell/You can also make....txt:alias LANshare='python -c "import SimpleHTTPServer; SimpleHTTPServer.test();"'
/home/bani/Dropbox/tools/kubuntu/autokey/ak_2012/0_backup/ak/AK_tazjel/w/Do/Shell/You can also make....txt:alias LANshare='python -c "import SimpleHTTPServer; SimpleHTTPServer.test();"'
/home/bani/Dropbox/tools/kubuntu/autokey/ak_2012/0_backup/sy/AK_tazjel/W/c/zbash/cml/You can also make....txt:alias LANshare='python -c "import SimpleHTTPServer; SimpleHTTPServer.test();"'
/home/bani/Dropbox/tools/kubuntu/autokey/ak_2012/0_backup/sy/wak/AK_tazjel/W/c/zbash/cml/You can also make....txt:alias LANshare='python -c "import SimpleHTTPServer; SimpleHTTPServer.test();"'
/home/bani/Dropbox/tools/kubuntu/autokey/ak_2012/0_backup/AK_tazjel/W/d/1/shell/cml/You can also make....txt:alias LANshare='python -c "import SimpleHTTPServer; SimpleHTTPServer.test();"'
/home/bani/Dropbox/tools/kubuntu/autokey/ak_2012/0_backup/AK_tazjel 1/W/c/zbash/cml/You can also make....txt:alias LANshare='python -c "import SimpleHTTPServer; SimpleHTTPServer.test();"'
/home/bani/Dropbox/tools/kubuntu/autokey/ak_2012/0_backup/wAK_tazjel/W/d/Shell/You can also make....txt:alias LANshare='python -c "import SimpleHTTPServer; SimpleHTTPServer.test();"'
/home/bani/Dropbox/tools/kubuntu/autokey/ak_2012/0_backup/ww/AK_tazjel/W/c/zbash/cml/You can also make....txt:alias LANshare='python -c "import SimpleHTTPServer; SimpleHTTPServer.test();"'
/home/bani/Dropbox/tools/kubuntu/autokey/ak_2012/sync/AK_tazjel/W/c/zbash/cml/You can also make....txt:alias LANshare='python -c "import SimpleHTTPServer; SimpleHTTPServer.test();"'
Binary file /home/bani/Dropbox/tools/tazjel/tazjel/static/images/qastack_design.xcf matches
/home/bani/Dropbox/tools/tazjel/tazjel/modules/CustomAuthentication.py:            self.session.auth_alias = auth_alias
/home/bani/Dropbox/tools/tazjel/tazjel/modules/CustomAuthentication.py:        self.session.auth_alias = email
/home/bani/Dropbox/tools/tazjel/tazjel/modules/CustomAuthentication.py:        # db.auth_users.auth_alias will contain the value of auth_alias
/home/bani/Dropbox/tools/tazjel/tazjel/modules/CustomAuthentication.py:        self.session.auth_alias = auth_alias
/home/bani/Dropbox/tools/tazjel/tazjel/modules/CustomAuthentication.py:        self.session.auth_alias = None
/home/bani/Dropbox/tools/tazjel/tazjel/modules/CustomAuthentication.py:            auth_alias = self.get_user_name()
/home/bani/Dropbox/tools/tazjel/tazjel/modules/CustomAuthentication.py:                    (self.db.auth_users.auth_alias == auth_alias)).select(
/home/bani/Dropbox/tools/tazjel/tazjel/modules/CustomAuthentication.py:               if self.session.auth_alias is None else self.session.auth_alias
/home/bani/Dropbox/tools/tazjel/tazjel/modules/CustomAuthentication.py:        return self.session.auth_alias is not None
/home/bani/Dropbox/tools/tazjel/tazjel/models/db.py:    auth_alias = 'admin@qa-stack.com'
/home/bani/Dropbox/tools/tazjel/tazjel/databases/sql.log:    auth_alias CHAR(255),
Binary file /home/bani/Dropbox/tools/tazjel/tazjel/databases/qastack.sqlite matches
/home/bani/Dropbox/tools/web2py/CHANGELOG:- fixed joins with alias tables
/home/bani/Dropbox/tools/web2py/scripts/setup-web2py-nginx-uwsgi-on-centos.sh:#create alias so that python 2.x can be run with 'python2.x'
/home/bani/Dropbox/tools/web2py/scripts/setup-web2py-nginx-uwsgi-on-centos.sh:alias -p python$PREFIX="/opt/python$/bin/python$PREFIX"
/home/bani/Dropbox/tools/web2py/scripts/web2py.ubuntu.sh:	# and leave 'force-reload' as an alias for 'restart'.
/home/bani/Dropbox/tools/web2py/applications/admin/static/codemirror/mode/clike/clike.js:                    " unsafe using virtual void volatile while add alias ascending descending dynamic from get" + 
/home/bani/Dropbox/tools/web2py/applications/admin/static/codemirror/emmet.min.js:vare:'<xsl:variable name="" select=""/>',wp:'<xsl:with-param name="" select=""/>',key:'<xsl:key name="" match="" use=""/>',elem:'<xsl:element name="">',attr:'<xsl:attribute name="">',attrs:'<xsl:attribute-set name="">',cp:'<xsl:copy select=""/>',co:'<xsl:copy-of select=""/>',val:'<xsl:value-of select=""/>',each:'<xsl:for-each select="">',"for":"each",tex:"<xsl:text></xsl:text>",com:"<xsl:comment>",msg:'<xsl:message terminate="no">',fall:"<xsl:fallback>",num:'<xsl:number value=""/>',nam:'<namespace-alias stylesheet-prefix="" result-prefix=""/>',
Binary file /home/bani/Dropbox/tools/web2py/applications/tazjel/static/images/qastack_design.xcf matches
/home/bani/Dropbox/tools/web2py/applications/tazjel/modules/CustomAuthentication.py:            self.session.auth_alias = auth_alias
/home/bani/Dropbox/tools/web2py/applications/tazjel/modules/CustomAuthentication.py:        self.session.auth_alias = email
/home/bani/Dropbox/tools/web2py/applications/tazjel/modules/CustomAuthentication.py:        # db.auth_users.auth_alias will contain the value of auth_alias
/home/bani/Dropbox/tools/web2py/applications/tazjel/modules/CustomAuthentication.py:        self.session.auth_alias = auth_alias
/home/bani/Dropbox/tools/web2py/applications/tazjel/modules/CustomAuthentication.py:        self.session.auth_alias = None
/home/bani/Dropbox/tools/web2py/applications/tazjel/modules/CustomAuthentication.py:            auth_alias = self.get_user_name()
/home/bani/Dropbox/tools/web2py/applications/tazjel/modules/CustomAuthentication.py:                    (self.db.auth_users.auth_alias == auth_alias)).select(
/home/bani/Dropbox/tools/web2py/applications/tazjel/modules/CustomAuthentication.py:               if self.session.auth_alias is None else self.session.auth_alias
/home/bani/Dropbox/tools/web2py/applications/tazjel/modules/CustomAuthentication.py:        return self.session.auth_alias is not None
/home/bani/Dropbox/tools/web2py/applications/tazjel/models/db.py:    auth_alias = 'admin@qa-stack.com'
/home/bani/Dropbox/tools/web2py/applications/tazjel/databases/sql.log:    auth_alias CHAR(255),
Binary file /home/bani/Dropbox/tools/web2py/applications/tazjel/databases/qastack.sqlite matches
/home/bani/Dropbox/tools/web2py/applications/examples/static/epydoc/web2py.gluon.dal.NoSQLAdapter-class.html:      Given a table object, makes a new table object with alias 
/home/bani/Dropbox/tools/web2py/applications/examples/static/epydoc/web2py.gluon.dal.NoSQLAdapter-class.html:  Given a table object, makes a new table object with alias name.
/home/bani/Dropbox/tools/web2py/applications/examples/static/epydoc/web2py.gluon.dal.BaseAdapter-class.html:      Given a table object, makes a new table object with alias 
/home/bani/Dropbox/tools/web2py/applications/examples/static/epydoc/web2py.gluon.dal-pysrc.html:<a name="L1299"></a><tt class="py-lineno">1299</tt>  <tt class="py-line"><tt class="py-docstring">        with alias name.</tt> </tt>
Binary file /home/bani/Dropbox/tools/web2py/applications/qastack/static/images/qastack_design.xcf matches
/home/bani/Dropbox/tools/web2py/applications/qastack/databases/sql.log:    auth_alias CHAR(255),
Binary file /home/bani/Dropbox/tools/web2py/applications/qastack/databases/qastack.sqlite matches
/home/bani/Dropbox/tools/web2py/gluon/dal.py:        with alias name.
Binary file /home/bani/Dropbox/tools/web2py/gluon/dal.pyc matches
/home/bani/Dropbox/tools/web2py/gluon/contrib/fpdf/fpdf.py:        "Define an alias for total number of pages"
/home/bani/Dropbox/tools/web2py/gluon/contrib/fpdf/fpdf.py:            alias = UTF8ToUTF16BE(self.str_alias_nb_pages, False);
/home/bani/Dropbox/tools/web2py/gluon/contrib/pysimplesoap/simplexml.py:        return "<alias '%s' for '%s'>" % (self.xml_type, self.py_type)
/home/bani/Dropbox/tools/web2py/gluon/contrib/pysimplesoap/simplexml.py:        """Replace the defined namespace alias with tohse used by the client."""
/home/bani/Dropbox/tools/web2py/gluon/contrib/pysimplesoap/simplexml.py:                log.warning('Unknown namespace alias %s' % name)
/home/bani/Dropbox/tools/web2py/gluon/contrib/pysimplesoap/client.py:                    alias = True
/home/bani/Dropbox/tools/web2py/gluon/contrib/pysimplesoap/client.py:                    alias = False
/home/bani/Dropbox/tools/web2py/gluon/contrib/pysimplesoap/server.py:        # Change our namespace alias to that given by the client.
/home/bani/Dropbox/tools/FF/w/cache.rdf:                   NS1:content=" home vim mutt blog Kevin's Mutt Tips and Tricks Overview These are a few suggestions for how I like to do things in mutt. I hope someone will find them useful. I use Gmail and FastMail for email. I like Gmail (having worked at Google and all), but FastMail is still pretty cool and bit of a more traditional email provider. I also like to use mutt whenever possible, as it's fast, keyboard driven, standards compliant, and integrates GPG. In order to be able to use mutt with many different accounts, I have my own method of implementing profiles. Profiles in Mutt There are many ways to implement &quot;profiles&quot; in mutt. (By profiles, I mean a group of settings specific to an email account). A quick google search will show many &quot;helper&quot; programs and hooks used to toggle between settings within a single running instance of mutt. The problem with all these is that mutt wasn't designed with profiles in mind. You have to be extremely careful one profile doesn't bleed over into another as you switch between them. I have several accounts I like to check with mutt: gmail, fastmail, and spool. I use a much simpler way of managing them: shell aliases that source a different custom muttrc, along with a single &quot;common&quot; muttrc file. An example will probably make this clearer. My .zshrc file contains the aliases: alias mutt='LOCAL_CONFIG=spool /usr/bin/mutt' alias mutt-fastmail='LOCAL_CONFIG=fastmail /usr/bin/mutt' alias mutt-gmail='LOCAL_CONFIG=gmail /usr/bin/mutt' In my .mutt/muttrc file, the last line uses the environment variable set by each alias to load a custom config file: source ~/.mutt/muttrc.local.$LOCAL_CONFIG The main .mutt/muttrc file contains generic settings I prefer across all my mutt profiles: unset arrow_cursor # use arrow cursor unset askbcc # don't prompt for bcc's unset askcc # don't prompt for cc's unset beep # don't beep on error unset beep_new # don't beep on new message set bounce_delivered # unset: remove Delivered-To: when bouncing? unset collapse_unread # don't collapse threads with unread mails set uncollapse_jump # jump to unread message when uncollapse set confirmappend # may want to change this later set copy # save copies of sent messages set delete # don't ask me to delete messages - just do it! set edit_headers # display the headers when I'm editing a message set fast_reply # don't prompt for stuff when replying set followup_to # add Mail-Followup-To header set help # show help on first line of display unset mark_old # don't mark unread messages as Old unset menu_scroll # scroll menu a page on last line set narrow_tree # narrow threading trees set pager_stop # don't go to next message at end of message ... ... ... source ~/.mutt/muttrc.local.$LOCAL_CONFIG Then, each muttrc.local.[profile] file can contain specifics for connecting and sending mail for that account. Here are my settings for fastmail, in the file .mutt/muttrc.local.fastmail: set my_server=mail.messagingengine.com set my_smtp_server=mail.messagingengine.com set my_user=foo set my_pass=bar set record=&quot;imaps://$my_server/INBOX.Sent Items&quot; set postponed=&quot;imaps://$my_server/INBOX.Drafts&quot; # # This is who I am # set from=&quot;XXXX@XXX.XX&quot; ########################################### # IMAP settings # # # Header caching directory # set header_cache=~/.mutt/hcache/fastmail # # SMTP server to relay to # # NOTE: to get this to work, I had to install the libsasl2-modules package set smtp_url=&quot;smtp://$my_user:$my_pass@$my_smtp_server:587/&quot; # # Slow down over imap # set mail_check=300 # How often to check in seconds set imap_user=$my_user # set imap_pass=$my_pass # # Default inbox # set spoolfile=imaps://$my_server/INBOX # # Default location of mailboxes # set folder=imaps://$my_server/INBOX # # Mailboxes to monitor for mail # (arranged in urgency reading order) # mailboxes imaps://$my_server/INBOX # high mailboxes imaps://$my_server/INBOX.foo mailboxes imaps://$my_server/INBOX.bar mailboxes imaps://$my_server/INBOX.baz ... ... ... The setting for muttrc.local.gmail are similar, with just the different accounts, passwords, smtp servers, etc for that account. Here is an example for gmail. Combined with gnu screen, I can easily flip between different accounts, launching mutt-fastmail in one shell, mutt-gmail in another, etc. It's simple to manage and works well for me. Mutt profiles and GNU Screen I have a command set up called screen-mail. This runs: screen -S mail -c ~/screen/mail.screenrc Inside ~/screen/mail.screenrc: source $HOME/.screenrc screen -t fastmail zsh -i -c mutt-fastmail screen -t gmail zsh -i -c mutt-gmail screen -t spool zsh -i -c mutt screen -t oi zsh -c '$HOME/bin/offlineimap.sh; zsh -i' screen -t newsbeuter newsbeuter This launches all my mutt instances, along with offlineimap, in one go. I added a zsh invocation after offlineimap so that I don't lose the screen window when I exit offlineimap (or it crashes). Those paying attention (or who just haven't fallen asleep) will have noticed my above mutt profile examples use imap directly and here I'm using offlineimap. I actually have an IMAP and a local offlineimap based profile for each: mutt-gmail-imap and mutt-gmail, mutt-fastmail-imap and mutt-fastmail. By default right now I'm using offlineimap and the local profile. But it's easy this way to launch a new screen window and run mutt-fastmail-imap if I want to directly connect using imap for some reason. offlineimap and lbdb (m_inmail) I use lbdb to query several different sources for my address book. One of those is m_inmail, which is populated from the mails I receive. Most sites say to run lbdb-fetchaddr through procmail, adding them as you receive emails. But this isn't practical over IMAP or when using offlineimap. Instead, I use a cron job to find recent emails and add them. One of the difficulties in doing this is that each email has to be piped to the 'lbdb-fetchaddr' command, which is not so easy to do via find. My solution is below: #!/bin/bash find /home/kjm/Mail/fastmail/INBOX -type f -mtime -7 -print0 | \ xargs -0 -n 1 -r /bin/bash -c 'lbdb-fetchaddr -a &lt; &quot;$1&quot;' lbdb-fetchaddr find /home/kjm/Mail/gmail/INBOX -type f -mtime -7 -print0 | \ xargs -0 -n 1 -r /bin/bash -c 'lbdb-fetchaddr -a &lt; &quot;$1&quot;' lbdb-fetchaddr # remove dups SORT_OUTPUT=name /usr/lib/lbdb/lbdb-munge This uses a few clever tricks. The find/xargs invocation is pretty standard, but here we add the flag '-n 1' to invoke the command with one argument at a time. The '-r' prevents the command from running if no results are found. The invocation of the shell by xargs is most interesting. xargs by default will append the file to the command. However, the bash man page says: If there are arguments after the string, they are assigned to the positional parameters, starting with $0. The 'lbdb-fetchaddr' at the end is $0 for the command, and the email file will be $1 (appended by xargs). So this essentially tricks xargs into giving us the file as stdin, (via the sh -c 'mycmd &lt; $1' arg0 arg1 construct). goobook See my goobook page for more about goobook and mutt/lbdb integration. Last modified: Jan 20, 2012 20:09 Powered by Middleman and HTML5 Boilerplate " />
/home/bani/Dropbox/tools/FF/w/cache.rdf:                   NS1:content=" # # Author: Kevin McCarthy # http://www.8t8.us/ # ########################################### # Index settings # unset arrow_cursor # highlight current line instead of using arrow unset collapse_unread # don't collapse threads with unread mails set uncollapse_jump # jump to unread message when uncollapse unset confirmappend # don't confirm saving/copying messages set confirmcreate # but confirm if saving creates a new mailbox set delete # don't ask me to delete messages - just do it! set help # show help on first line of display set mail_check=90 # How often to check in seconds unset mark_old # don't mark unread messages as Old set narrow_tree # narrow threading trees unset sort_re # Use strict threading set strict_threads # ^^^ unset mail_check_recent # keep telling me a mailbox has new mail even if I # visit it (added in 1.5.21) set move=no # don't move messages to mbox and don't ask set print=ask-no # double check when hitting 'p' set quit=ask-yes # double check 'q' too set sleep_time=0 # Don't pause between mailbox changes set sort=threads set sort_aux=last-date-received # secondary sorting (for threads) # set sort_aux=date-sent # set index_format=&quot;%4C %Z %{%b %d} %-15.15L %?M?&gt;#%03M&lt;&amp;(%4l)? %s&quot; # set index_format=&quot;%4C %Z %{%b %d} %-15.15L (%?l?%4l&amp;%4c?) %s&quot; # set index_format=&quot;%4C %Z %[%a %b %d %Y %X] %-15.15L (%?l?%4l&amp;%4c?) %s&quot; # set index_format=&quot;%4C %Z %[%a %x %X] %-15.15L (%?l?%4l&amp;%4c?) %s&quot; # set index_format=&quot;%4C %[%a %x %X] %-15.15L %Z (%?l?%4l&amp;%4c?) %s&quot; set index_format=&quot;%4C %[%a %x %X] %-15.15F %Z (%4c) %s&quot; ########################################### # Message composition settings # set abort_nosubject=ask-yes # abort if no subject set abort_unmodified=ask-yes # abort if message wasn't edited unset askbcc # don't prompt for bcc's unset askcc # don't prompt for cc's set attribution=&quot;%n wrote:&quot; # set autoedit # compose emails without the prompts set edit_headers # display the headers when I'm editing a message set editor=&quot;vim -X '+/^$' '++'&quot; set fast_reply # don't prompt for stuff when replying set followup_to # add Mail-Followup-To header for lists set ispell=&quot;aspell -e -c&quot; unset metoo # remove my email from list of recipients set mime_forward=ask-no # forward messages as rfc822 attachments # - useful for forwarding attachments too set postponed=&quot;=postponed&quot; set reply_to=ask-yes # ask to use from or reply-to set recall=no # Don't ask about postponed when composing # just use 'R' to recall postponed messages ########################################### # Message delivery settings # set bounce_delivered # unset: remove Delivered-To: when bouncing? set copy # save copies of sent messages ########################################### # Pager settings # unset markers # don't insert '+' character for wrapped lines set pager_stop # don't go to next message at end of message set pager_context=1 # display one line on pgup/pgdown set pager_index_lines=8 # display 8 lines of the index while viewing messages # # Headers to display # ignore * unignore From Message-ID Date User-Agent To Cc Bcc Subject unignore Delivery-date unignore x-mailer x-url unignore X-Delivered-to Delivered-To unignore x-spam-score authentication-results unignore x-face unignore openpgp hdr_order date from to cc subject ########################################### # Global settings # unset beep # don't beep on error unset beep_new # don't beep on new message unset menu_scroll # scroll menu a page on last line set timeout=60 # How long to wait for user input # at menus or prompts before timing out unset wait_key # don't prompt for a key after external commands # set print_command=&quot;muttprint&quot; # set print_command=&quot;enscript -G2r&quot; set print_command=&quot;enscript -G&quot; # set query_command=&quot;/usr/local/scripts/mutt-ldap&quot; # set query_command=&quot;~/.mutt/bin/ldapsearch.sh '%s'&quot; # set query_command=&quot;abook --mutt-query '%s'&quot; set query_command=&quot;lbdbq '%s'&quot; # alias file set alias_file=~/.mutt/aliases source ~/.mutt/aliases ########################################### # SSL settings # set certificate_file=~/.mutt/certificates set ssl_force_tls # make sure all connections are encrypted ########################################### # MIME settings # # # Says we prefer plain text to html in multiparts # alternative_order text/plain # # Says to consult mime.types for determining types of these attachments # mime_lookup application/octet-stream # # MIME autoviewing. Requires appropriate .mailcap entry # (with copiousoutput flag set) # auto_view text/html application/msword application/pdf auto_view application/vnd.oasis.opendocument.text ########################################### # Macros # # macro index ,a &lt;save-message&gt;=archive\n # macro pager ,a &lt;save-message&gt;=archive\n # ctrl-b macro index \cb |urlview\n macro pager \cb |urlview\n # macro index,pager A &quot;&lt;pipe-message&gt;abook --add-email&lt;return&gt;&quot; &quot;add the sender address to abook&quot; macro index,pager A &quot;&lt;pipe-message&gt;lbdb-fetchaddr -a&lt;return&gt;&quot; &quot;add the sender address to lbdb&quot; ########################################### # GPG # set pgp_autosign=no # this is overridden in the local configs # Documented at http://josefsson.org/openpgp-header/ my_hdr OpenPGP: id=B6B1CD9613699FB8\; url=http://www.8t8.us/configs/13699FB8.asc.pubkey\; preference=sign # turn on agent support set pgp_use_gpg_agent # try using long key ids (after changing the keyid-format setting in gpg.conf) set pgp_long_ids # These are &quot;standard settings&quot; stolen Debian's /etc/Muttrc.d/gpg.rc set pgp_decode_command=&quot;gpg --status-fd=2 %?p?--passphrase-fd 0? --no-verbose --quiet --batch --output - %f&quot; set pgp_verify_command=&quot;gpg --status-fd=2 --no-verbose --quiet --batch --output - --verify %s %f&quot; set pgp_decrypt_command=&quot;gpg --status-fd=2 %?p?--passphrase-fd 0? --no-verbose --quiet --batch --output - %f&quot; set pgp_sign_command=&quot;gpg --no-verbose --batch --quiet --output - %?p?--passphrase-fd 0? --armor --detach-sign --textmode %?a?-u %a? %f&quot; set pgp_clearsign_command=&quot;gpg --no-verbose --batch --quiet --output - %?p?--passphrase-fd 0? --armor --textmode --clearsign %?a?-u %a? %f&quot; set pgp_encrypt_only_command=&quot;/usr/lib/mutt/pgpewrap gpg --batch --quiet --no-verbose --output - --encrypt --textmode --armor --always-trust -- -r %r -- %f&quot; set pgp_encrypt_sign_command=&quot;/usr/lib/mutt/pgpewrap gpg %?p?--passphrase-fd 0? --batch --quiet --no-verbose --textmode --output - --encrypt --sign %?a?-u %a? --armor --always-trust -- -r %r -- %f&quot; set pgp_import_command=&quot;gpg --no-verbose --import %f&quot; set pgp_export_command=&quot;gpg --no-verbose --export --armor %r&quot; set pgp_verify_key_command=&quot;gpg --verbose --batch --fingerprint --check-sigs %r&quot; set pgp_list_pubring_command=&quot;gpg --no-verbose --batch --quiet --with-colons --list-keys %r&quot; set pgp_list_secring_command=&quot;gpg --no-verbose --batch --quiet --with-colons --list-secret-keys %r&quot; set pgp_good_sign=&quot;^\\[GNUPG:\\] GOODSIG&quot; ########################################### # Colors # source ~/.mutt/colors.kjm ########################################### # Tips # # Useful keys to remember: # # INDEX: # &amp; - link broken threads # first tag the reply, then moving to the parent message and hit '&amp;' # # - break thread # turns the subthread starting from the current message into a whole # different thread. # = - first message # * - last message # # PAGER: # ^ jump to top of message # - previous-page ########################################### # Local configs # # source ~/.mutt/muttrc.local source ~/.mutt/muttrc.local.$LOCAL_CONFIG " />
/home/bani/Dropbox/tools/FF/w/cache.rdf:                   NS1:content=" home vim mutt blog Kevin's Mutt Tips and Tricks Overview These are a few suggestions for how I like to do things in mutt. I hope someone will find them useful. I use Gmail and FastMail for email. I like Gmail (having worked at Google and all), but FastMail is still pretty cool and bit of a more traditional email provider. I also like to use mutt whenever possible, as it's fast, keyboard driven, standards compliant, and integrates GPG. In order to be able to use mutt with many different accounts, I have my own method of implementing profiles. Profiles in Mutt There are many ways to implement &quot;profiles&quot; in mutt. (By profiles, I mean a group of settings specific to an email account). A quick google search will show many &quot;helper&quot; programs and hooks used to toggle between settings within a single running instance of mutt. The problem with all these is that mutt wasn't designed with profiles in mind. You have to be extremely careful one profile doesn't bleed over into another as you switch between them. I have several accounts I like to check with mutt: gmail, fastmail, and spool. I use a much simpler way of managing them: shell aliases that source a different custom muttrc, along with a single &quot;common&quot; muttrc file. An example will probably make this clearer. My .zshrc file contains the aliases: alias mutt='LOCAL_CONFIG=spool /usr/bin/mutt' alias mutt-fastmail='LOCAL_CONFIG=fastmail /usr/bin/mutt' alias mutt-gmail='LOCAL_CONFIG=gmail /usr/bin/mutt' In my .mutt/muttrc file, the last line uses the environment variable set by each alias to load a custom config file: source ~/.mutt/muttrc.local.$LOCAL_CONFIG The main .mutt/muttrc file contains generic settings I prefer across all my mutt profiles: unset arrow_cursor # use arrow cursor unset askbcc # don't prompt for bcc's unset askcc # don't prompt for cc's unset beep # don't beep on error unset beep_new # don't beep on new message set bounce_delivered # unset: remove Delivered-To: when bouncing? unset collapse_unread # don't collapse threads with unread mails set uncollapse_jump # jump to unread message when uncollapse set confirmappend # may want to change this later set copy # save copies of sent messages set delete # don't ask me to delete messages - just do it! set edit_headers # display the headers when I'm editing a message set fast_reply # don't prompt for stuff when replying set followup_to # add Mail-Followup-To header set help # show help on first line of display unset mark_old # don't mark unread messages as Old unset menu_scroll # scroll menu a page on last line set narrow_tree # narrow threading trees set pager_stop # don't go to next message at end of message ... ... ... source ~/.mutt/muttrc.local.$LOCAL_CONFIG Then, each muttrc.local.[profile] file can contain specifics for connecting and sending mail for that account. Here are my settings for fastmail, in the file .mutt/muttrc.local.fastmail: set my_server=mail.messagingengine.com set my_smtp_server=mail.messagingengine.com set my_user=foo set my_pass=bar set record=&quot;imaps://$my_server/INBOX.Sent Items&quot; set postponed=&quot;imaps://$my_server/INBOX.Drafts&quot; # # This is who I am # set from=&quot;XXXX@XXX.XX&quot; ########################################### # IMAP settings # # # Header caching directory # set header_cache=~/.mutt/hcache/fastmail # # SMTP server to relay to # # NOTE: to get this to work, I had to install the libsasl2-modules package set smtp_url=&quot;smtp://$my_user:$my_pass@$my_smtp_server:587/&quot; # # Slow down over imap # set mail_check=300 # How often to check in seconds set imap_user=$my_user # set imap_pass=$my_pass # # Default inbox # set spoolfile=imaps://$my_server/INBOX # # Default location of mailboxes # set folder=imaps://$my_server/INBOX # # Mailboxes to monitor for mail # (arranged in urgency reading order) # mailboxes imaps://$my_server/INBOX # high mailboxes imaps://$my_server/INBOX.foo mailboxes imaps://$my_server/INBOX.bar mailboxes imaps://$my_server/INBOX.baz ... ... ... The setting for muttrc.local.gmail are similar, with just the different accounts, passwords, smtp servers, etc for that account. Here is an example for gmail. Combined with gnu screen, I can easily flip between different accounts, launching mutt-fastmail in one shell, mutt-gmail in another, etc. It's simple to manage and works well for me. Mutt profiles and GNU Screen I have a command set up called screen-mail. This runs: screen -S mail -c ~/screen/mail.screenrc Inside ~/screen/mail.screenrc: source $HOME/.screenrc screen -t fastmail zsh -i -c mutt-fastmail screen -t gmail zsh -i -c mutt-gmail screen -t spool zsh -i -c mutt screen -t oi zsh -c '$HOME/bin/offlineimap.sh; zsh -i' screen -t newsbeuter newsbeuter This launches all my mutt instances, along with offlineimap, in one go. I added a zsh invocation after offlineimap so that I don't lose the screen window when I exit offlineimap (or it crashes). Those paying attention (or who just haven't fallen asleep) will have noticed my above mutt profile examples use imap directly and here I'm using offlineimap. I actually have an IMAP and a local offlineimap based profile for each: mutt-gmail-imap and mutt-gmail, mutt-fastmail-imap and mutt-fastmail. By default right now I'm using offlineimap and the local profile. But it's easy this way to launch a new screen window and run mutt-fastmail-imap if I want to directly connect using imap for some reason. offlineimap and lbdb (m_inmail) I use lbdb to query several different sources for my address book. One of those is m_inmail, which is populated from the mails I receive. Most sites say to run lbdb-fetchaddr through procmail, adding them as you receive emails. But this isn't practical over IMAP or when using offlineimap. Instead, I use a cron job to find recent emails and add them. One of the difficulties in doing this is that each email has to be piped to the 'lbdb-fetchaddr' command, which is not so easy to do via find. My solution is below: #!/bin/bash find /home/kjm/Mail/fastmail/INBOX -type f -mtime -7 -print0 | \ xargs -0 -n 1 -r /bin/bash -c 'lbdb-fetchaddr -a &lt; &quot;$1&quot;' lbdb-fetchaddr find /home/kjm/Mail/gmail/INBOX -type f -mtime -7 -print0 | \ xargs -0 -n 1 -r /bin/bash -c 'lbdb-fetchaddr -a &lt; &quot;$1&quot;' lbdb-fetchaddr # remove dups SORT_OUTPUT=name /usr/lib/lbdb/lbdb-munge This uses a few clever tricks. The find/xargs invocation is pretty standard, but here we add the flag '-n 1' to invoke the command with one argument at a time. The '-r' prevents the command from running if no results are found. The invocation of the shell by xargs is most interesting. xargs by default will append the file to the command. However, the bash man page says: If there are arguments after the string, they are assigned to the positional parameters, starting with $0. The 'lbdb-fetchaddr' at the end is $0 for the command, and the email file will be $1 (appended by xargs). So this essentially tricks xargs into giving us the file as stdin, (via the sh -c 'mycmd &lt; $1' arg0 arg1 construct). goobook See my goobook page for more about goobook and mutt/lbdb integration. Last modified: Jan 20, 2012 20:09 Powered by Middleman and HTML5 Boilerplate " />
/home/bani/Dropbox/tools/FF/w/data/20130227131930/index.html:    <pre>alias mutt='LOCAL_CONFIG=spool /usr/bin/mutt'
/home/bani/Dropbox/tools/FF/w/data/20130227131930/index.html:alias mutt-fastmail='LOCAL_CONFIG=fastmail /usr/bin/mutt'
/home/bani/Dropbox/tools/FF/w/data/20130227131930/index.html:alias mutt-gmail='LOCAL_CONFIG=gmail /usr/bin/mutt'
/home/bani/Dropbox/tools/FF/w/data/20130227131930/index.html:      set by each alias to load a custom config file:
/home/bani/Dropbox/tools/FF/w/data/20130303070434/index.html:$ echo 'use_anti_alias = true' &gt;&gt; ~/.mlterm/main
/home/bani/Dropbox/tools/FF/w/data/20130303070434/index.html:$ echo 'use_anti_alias = true' &gt;&gt; ~/.mlterm/main
/home/bani/Dropbox/tools/FF/w/data/20130227013733/index.html:    <pre>alias mutt='LOCAL_CONFIG=spool /usr/bin/mutt'
/home/bani/Dropbox/tools/FF/w/data/20130227013733/index.html:alias mutt-fastmail='LOCAL_CONFIG=fastmail /usr/bin/mutt'
/home/bani/Dropbox/tools/FF/w/data/20130227013733/index.html:alias mutt-gmail='LOCAL_CONFIG=gmail /usr/bin/mutt'
/home/bani/Dropbox/tools/FF/w/data/20130227013733/index.html:      set by each alias to load a custom config file:
/home/bani/Dropbox/tools/FF/w/data/20130227124041/index.html:<span class="Comment"># alias file</span>
/home/bani/Dropbox/tools/FF/w/data/20130227124052/muttrc.txt:# alias file
/home/bani/Dropbox/tools/zsync/config/autokey/data/AK_tazjel/W/c/zbash/cml/You can also make....txt:alias LANshare='python -c "import SimpleHTTPServer; SimpleHTTPServer.test();"'
Binary file /home/bani/Dropbox/tools/zsync/config/google-chrome/Default/History Index 2012-10 matches
Binary file /home/bani/Dropbox/tools/zsync/config/google-chrome/Default/History Index 2012-09 matches
Binary file /home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/cafiohcgicchdfciefpbjjgigbmajndb/0.6.0_0/res/logo-16.xcf matches
Binary file /home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/cafiohcgicchdfciefpbjjgigbmajndb/0.6.0_0/res/logo-128.xcf matches
Binary file /home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/cafiohcgicchdfciefpbjjgigbmajndb/0.6.0_0/res/logo-48.xcf matches
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/hhjdojledkjmgenockdkeomioneoaddp/1.0.1_0/CodeMirror/contrib/php/js/tokenizephp.js:      "_", /* alias for gettext()*/ 
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/gghkfhpblkcmlkmpcpgaajbbiikbhpdi/0.11.0_0/commandbox.js:    alias = aliases[alias];
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/gghkfhpblkcmlkmpcpgaajbbiikbhpdi/0.11.0_0/commandbox.js:    while (alias != null) {
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/gghkfhpblkcmlkmpcpgaajbbiikbhpdi/0.11.0_0/commandbox.js:      alias = aliases[alias];
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/gghkfhpblkcmlkmpcpgaajbbiikbhpdi/0.11.0_0/commandbox.js:      for (alias in _ref) {
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/gghkfhpblkcmlkmpcpgaajbbiikbhpdi/0.11.0_0/settings.js:      "keyMappingAndAliases": "### Sample Settings\n\n# aliases\n# in this example you can open extensions page by the command ':ext'\n# and Chrome's option page by the command ':option'\nalias ext TabOpenNew chrome://extensions/\nalias option TabOpenNew chrome://settings/browser\nalias downloads TabOpenNew chrome://downloads\nalias history TabOpenNew chrome://history\n\n# mappings for opening your favorite web page\nnmap <Space>tw :TabOpenNew http://www.twitter.com\nnmap <Space>gr :TabOpenNew http://www.google.com/reader\nnmap <Space>m  :TabOpenNew https://mail.google.com/mail/#inbox\n\n# F for continuous f-Mode\n# this is recomended setting but commented out by default.\n# if you want to use this setting, use the following\n#nmap F :GoFMode --newtab --continuous\n\n# you can use <DISCARD> to discard the key so that chrome's default\n# action isn't triggered.\n#nmap <BS> <DISCARD>\n\n# if you want to change the key used to escape EmergencyMode mode,\n# use emap like the following\n#emap <ESC> :Escape\n\n## pagecmd offers you page specific key mapping.\n# in this example you can use <C-l>, <C-h> for moving between tabs\n# on all web pages regardless of your ignored list setting\n# because pagecmd has higher priority than ignored URLs.\npagecmd * nmap <C-l> :TabFocusNext\npagecmd * nmap <C-h> :TabFocusPrev\n\n# almost all Vichrome functions don't work properly for pdf contents\n# so it's useful to enable default key bindings for pdf file.\npagecmd *.pdf nmap <C-f> <NOP>\n\n# if you want to use twitter web's key binding, write settings like below\n#pagecmd http*://twitter.com/* nmap f <NOP>\n#pagecmd http*://twitter.com/* nmap r <NOP>",
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/gghkfhpblkcmlkmpcpgaajbbiikbhpdi/0.11.0_0/command.js:      alias = aliases[alias];
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/gghkfhpblkcmlkmpcpgaajbbiikbhpdi/0.11.0_0/command.js:      while (alias != null) {
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/gghkfhpblkcmlkmpcpgaajbbiikbhpdi/0.11.0_0/command.js:        alias = aliases[alias];
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/akeeaafmkigeapaejnlbknplbbpfbcfp/0.6_0/mootools-1.2.4-all-debug.js:	object.alias = function(a1, a2, a3){
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/dheionainndbbpoacpnopgmnihkcmnkl/5.6.3_0/js/gmelius.js:                        var regexp = new RegExp(separatorExp + alias + separatorExp);
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/iieeldjdihkpoapgipfkeoddjckopgjg/0.7.4_0/src/dojox/color/README:new additions (Generator, Tom Trenka).  Everything is applied to an alias of
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/iieeldjdihkpoapgipfkeoddjckopgjg/0.7.4_0/src/dojox/charting/widget/Chart2D.js.uncompressed.js://	alias all the dojo.Color mechanisms
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/iieeldjdihkpoapgipfkeoddjckopgjg/0.7.4_0/src/dojox/charting/widget/Chart2D.js.uncompressed.js://	alias the dojo.colors mechanisms
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/iieeldjdihkpoapgipfkeoddjckopgjg/0.7.4_0/src/dojox/dtl.js.uncompressed.js:		this.alias = alias;
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/iieeldjdihkpoapgipfkeoddjckopgjg/0.7.4_0/src/dojox/dtl.js.uncompressed.js:			var alias = tokens[tokens.length - 1];
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/iieeldjdihkpoapgipfkeoddjckopgjg/0.7.4_0/src/dojox/dtl.js.uncompressed.js:		this.alias = alias;
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/iieeldjdihkpoapgipfkeoddjckopgjg/0.7.4_0/src/dijit/dijit-all.js.uncompressed.js:			//		Initialize according to value or alias like "white"
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/iieeldjdihkpoapgipfkeoddjckopgjg/0.7.4_0/src/dijit/dijit-all.js.uncompressed.js:			this._alias = alias;
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/iieeldjdihkpoapgipfkeoddjckopgjg/0.7.4_0/src/dojo/dojo.js.uncompressed.js:			// alias used above
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/iieeldjdihkpoapgipfkeoddjckopgjg/0.7.4_0/src/dojo/dojo.js.uncompressed.js:		// 		Existing alias for `dojo.destroy`. Deprecated, will be removed
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/iieeldjdihkpoapgipfkeoddjckopgjg/0.7.4_0/src/dojo/dojo.js.uncompressed.js:	// alias to "dojo" (or the toolkit alias object, e.g., "acme").
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/iieeldjdihkpoapgipfkeoddjckopgjg/0.7.4_0/src/dojo/dojo.js.uncompressed.js:	// MOW: remove dojo._contentHandlers alias in 2.0
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/oiaejidbmkiecgbjeifoejpgmdaleoha/1.7_0/js/libs/jquery.lint.js:    var alias = 'jQuery',
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/oiaejidbmkiecgbjeifoejpgmdaleoha/1.7_0/js/libs/handlebars.js:      // Generate minimizer alias mappings
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/oiaejidbmkiecgbjeifoejpgmdaleoha/1.7_0/js/libs/handlebars.js:        for (var alias in this.context.aliases) {
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/oiaejidbmkiecgbjeifoejpgmdaleoha/1.7_0/js/libs/handlebars.js:          this.source[1] = this.source[1] + ', ' + alias + '=' + this.context.aliases[alias];
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/boamfheepdiallipiieadpmnklbhadhc/0.151_0/lib/prettify/prettify.js:la=x({keywords:"break continue do else for if return while auto case char const default double enum extern float goto int long register short signed sizeof static struct switch typedef union unsigned void volatile catch class delete false import new operator private protected public this throw true try typeof alignof align_union asm axiom bool concept concept_map const_cast constexpr decltype dynamic_cast explicit export friend inline late_check mutable namespace nullptr reinterpret_cast static_assert static_cast template typeid typename using virtual wchar_t where break continue do else for if return while auto case char const default double enum extern float goto int long register short signed sizeof static struct switch typedef union unsigned void volatile catch class delete false import new operator private protected public this throw true try typeof abstract boolean byte extends final finally implements import instanceof null native package strictfp super synchronized throws transient as base by checked decimal delegate descending event fixed foreach from group implicit in interface internal into is lock object out override orderby params partial readonly ref sbyte sealed stackalloc string select uint ulong unchecked unsafe ushort var break continue do else for if return while auto case char const default double enum extern float goto int long register short signed sizeof static struct switch typedef union unsigned void volatile catch class delete false import new operator private protected public this throw true try typeof debugger eval export function get null set undefined var with Infinity NaN caller delete die do dump elsif eval exit foreach for goto if import last local my next no our print package redo require sub undef unless until use wantarray while BEGIN END break continue do else for if return while and as assert class def del elif except exec finally from global import in is lambda nonlocal not or pass print raise try with yield False True None break continue do else for if return while alias and begin case class def defined elsif end ensure false in module next nil not or redo rescue retry self super then true undef unless until when yield BEGIN END break continue do else for if return while case done elif esac eval fi function in local set then until ",
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/boamfheepdiallipiieadpmnklbhadhc/0.151_0/lib/prettify/prettify.js:u(x({keywords:"caller delete die do dump elsif eval exit foreach for goto if import last local my next no our print package redo require sub undef unless until use wantarray while BEGIN END ",hashComments:true,multiLineStrings:true,regexLiterals:true}),["perl","pl","pm"]);u(x({keywords:"break continue do else for if return while alias and begin case class def defined elsif end ensure false in module next nil not or redo rescue retry self super then true undef unless until when yield BEGIN END ",hashComments:true,
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/mbigbapnjcgaffohmbkdlecaccepngjd/1.6_0/lib/jquery.layout-1.2.0.js:	,	c		= config // alias for config hash
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/mbigbapnjcgaffohmbkdlecaccepngjd/1.6_0/lib/jquery.layout-1.2.0.js:	,	cDims	= state.container // alias for easy access to 'container dimensions'
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/abefhanahjellfbchdmkjdcchkogijhk/1.6_0/api.xml:  <longdesc><p>The <code>.jquery</code> property is assigned to the jQuery prototype, commonly referred to by its alias <code>$.fn</code>. It is a string containing the version number of <code>jQuery</code>, such as "1.5.0" or "1.4.4".</p>
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/abefhanahjellfbchdmkjdcchkogijhk/1.6_0/api.xml:                <longdesc><p>Many JavaScript libraries use <code> $</code> as a function or variable name, just as jQuery does. In jQuery's case, <code> $</code> is just an alias for <code>jQuery</code>, so all functionality is available without using <code> $</code>. If we need to use another JavaScript library alongside jQuery, we can return control of <code> $</code> back to the other library with a call to <code>$.noConflict()</code>:</p>
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/abefhanahjellfbchdmkjdcchkogijhk/1.6_0/api.xml:<p>This technique is especially effective in conjunction with the .ready() method's ability to alias the jQuery object, as within callback passed to .ready() we can use $ if we wish without fear of conflicts later:</p>
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/abefhanahjellfbchdmkjdcchkogijhk/1.6_0/api.xml:                    <desc>Reverts the $ alias and then creates and executes a function to provide the $ as a jQuery alias inside the functions scope. Inside the function the original $ object is not available. This works well for most plugins that don't rely on any other library.  
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/abefhanahjellfbchdmkjdcchkogijhk/1.6_0/api.xml:    // more code using $ as alias to jQuery
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/abefhanahjellfbchdmkjdcchkogijhk/1.6_0/api.xml:// other code using $ as an alias to the other library]]></code>
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/abefhanahjellfbchdmkjdcchkogijhk/1.6_0/api.xml:// other code using $ as an alias to the other library]]></code>
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/abefhanahjellfbchdmkjdcchkogijhk/1.6_0/api.xml:                    <desc>Creates a different alias instead of jQuery to use in the rest of the script.</desc>
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/abefhanahjellfbchdmkjdcchkogijhk/1.6_0/api.xml:    // Your code using failsafe $ alias here...
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/gbkffbkamcejhkcaocmkdeiiccpmjfdi/1.0.0_0/created-tabs/prettify/prettify.js:la=x({keywords:"break continue do else for if return while auto case char const default double enum extern float goto int long register short signed sizeof static struct switch typedef union unsigned void volatile catch class delete false import new operator private protected public this throw true try typeof alignof align_union asm axiom bool concept concept_map const_cast constexpr decltype dynamic_cast explicit export friend inline late_check mutable namespace nullptr reinterpret_cast static_assert static_cast template typeid typename using virtual wchar_t where break continue do else for if return while auto case char const default double enum extern float goto int long register short signed sizeof static struct switch typedef union unsigned void volatile catch class delete false import new operator private protected public this throw true try typeof abstract boolean byte extends final finally implements import instanceof null native package strictfp super synchronized throws transient as base by checked decimal delegate descending event fixed foreach from group implicit in interface internal into is lock object out override orderby params partial readonly ref sbyte sealed stackalloc string select uint ulong unchecked unsafe ushort var break continue do else for if return while auto case char const default double enum extern float goto int long register short signed sizeof static struct switch typedef union unsigned void volatile catch class delete false import new operator private protected public this throw true try typeof debugger eval export function get null set undefined var with Infinity NaN caller delete die do dump elsif eval exit foreach for goto if import last local my next no our print package redo require sub undef unless until use wantarray while BEGIN END break continue do else for if return while and as assert class def del elif except exec finally from global import in is lambda nonlocal not or pass print raise try with yield False True None break continue do else for if return while alias and begin case class def defined elsif end ensure false in module next nil not or redo rescue retry self super then true undef unless until when yield BEGIN END break continue do else for if return while case done elif esac eval fi function in local set then until ",
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/gbkffbkamcejhkcaocmkdeiiccpmjfdi/1.0.0_0/created-tabs/prettify/prettify.js:u(x({keywords:"caller delete die do dump elsif eval exit foreach for goto if import last local my next no our print package redo require sub undef unless until use wantarray while BEGIN END ",hashComments:true,multiLineStrings:true,regexLiterals:true}),["perl","pl","pm"]);u(x({keywords:"break continue do else for if return while alias and begin case class def defined elsif end ensure false in module next nil not or redo rescue retry self super then true undef unless until when yield BEGIN END ",hashComments:true,
Binary file /home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/pabfempgigicdjjlccdgnbmeggkbjdhd/2.0.6_0/st.xcf matches
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/bbamfloeabgknfklmgbpjcgofcokhpia/0.4_0/lib/prettify/prettify.js:la=x({keywords:"break continue do else for if return while auto case char const default double enum extern float goto int long register short signed sizeof static struct switch typedef union unsigned void volatile catch class delete false import new operator private protected public this throw true try typeof alignof align_union asm axiom bool concept concept_map const_cast constexpr decltype dynamic_cast explicit export friend inline late_check mutable namespace nullptr reinterpret_cast static_assert static_cast template typeid typename using virtual wchar_t where break continue do else for if return while auto case char const default double enum extern float goto int long register short signed sizeof static struct switch typedef union unsigned void volatile catch class delete false import new operator private protected public this throw true try typeof abstract boolean byte extends final finally implements import instanceof null native package strictfp super synchronized throws transient as base by checked decimal delegate descending event fixed foreach from group implicit in interface internal into is lock object out override orderby params partial readonly ref sbyte sealed stackalloc string select uint ulong unchecked unsafe ushort var break continue do else for if return while auto case char const default double enum extern float goto int long register short signed sizeof static struct switch typedef union unsigned void volatile catch class delete false import new operator private protected public this throw true try typeof debugger eval export function get null set undefined var with Infinity NaN caller delete die do dump elsif eval exit foreach for goto if import last local my next no our print package redo require sub undef unless until use wantarray while BEGIN END break continue do else for if return while and as assert class def del elif except exec finally from global import in is lambda nonlocal not or pass print raise try with yield False True None break continue do else for if return while alias and begin case class def defined elsif end ensure false in module next nil not or redo rescue retry self super then true undef unless until when yield BEGIN END break continue do else for if return while case done elif esac eval fi function in local set then until ",
/home/bani/Dropbox/tools/zsync/config/google-chrome/Default/Extensions/bbamfloeabgknfklmgbpjcgofcokhpia/0.4_0/lib/prettify/prettify.js:u(x({keywords:"caller delete die do dump elsif eval exit foreach for goto if import last local my next no our print package redo require sub undef unless until use wantarray while BEGIN END ",hashComments:true,multiLineStrings:true,regexLiterals:true}),["perl","pl","pm"]);u(x({keywords:"break continue do else for if return while alias and begin case class def defined elsif end ensure false in module next nil not or redo rescue retry self super then true undef unless until when yield BEGIN END ",hashComments:true,
/home/bani/Dropbox/tools/zsync/config/google-chrome/Profile 1/Extensions/onhbegdkgonhlokobjefolhpoidcnida/1.5.6_0/js/lib/knockout.js:ko.exportSymbol('ko.computed', ko.dependentObservable); // Make "ko.computed" an alias for "ko.dependentObservable"
Binary file /home/bani/Dropbox/tools/Blender/blender/blender matches
/home/bani/Dropbox/tools/Blender/blender/2.65/scripts/addons/render_povray/__init__.py:            name="Antialias Depth", description="Depth of pixel for sampling",
/home/bani/Dropbox/tools/Blender/blender/2.65/scripts/addons/render_povray/__init__.py:            name="Antialias Threshold", description="Tolerance for sub-pixels",
/home/bani/Dropbox/tools/Blender/blender/2.65/scripts/addons/render_povray/__init__.py:            name="Antialias Gamma",
/home/bani/Dropbox/tools/Blender/blender/2.65/scripts/addons/render_povray/__init__.py:            description="POV-Ray compares gamma-adjusted values for super sampling. Antialias " \
/home/bani/Dropbox/tools/Blender/blender/2.65/scripts/addons/render_povray/update_files.py:            name="Antialias Depth", description="Depth of pixel for sampling",
/home/bani/Dropbox/tools/Blender/blender/2.65/scripts/addons/render_povray/update_files.py:            name="Antialias Threshold", description="Tolerance for sub-pixels",
/home/bani/Dropbox/tools/Blender/blender/2.65/scripts/addons/render_povray/update_files.py:            name="Antialias Gamma", description="POV-Ray compares gamma-adjusted values for super sampling. Antialias Gamma sets the Gamma before comparison",
Binary file /home/bani/Dropbox/tools/Blender/blender/2.65/scripts/addons/render_povray/__pycache__/update_files.cpython-33.pyc matches
Binary file /home/bani/Dropbox/tools/Blender/blender/2.65/scripts/addons/render_povray/__pycache__/__init__.cpython-33.pyc matches
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/pydoc_data/topics.py: 'debugger': '\n``pdb`` --- The Python Debugger\n*******************************\n\nThe module ``pdb`` defines an interactive source code debugger for\nPython programs.  It supports setting (conditional) breakpoints and\nsingle stepping at the source line level, inspection of stack frames,\nsource code listing, and evaluation of arbitrary Python code in the\ncontext of any stack frame.  It also supports post-mortem debugging\nand can be called under program control.\n\nThe debugger is extensible -- it is actually defined as the class\n``Pdb``. This is currently undocumented but easily understood by\nreading the source.  The extension interface uses the modules ``bdb``\nand ``cmd``.\n\nThe debugger\'s prompt is ``(Pdb)``. Typical usage to run a program\nunder control of the debugger is:\n\n   >>> import pdb\n   >>> import mymodule\n   >>> pdb.run(\'mymodule.test()\')\n   > <string>(0)?()\n   (Pdb) continue\n   > <string>(1)?()\n   (Pdb) continue\n   NameError: \'spam\'\n   > <string>(1)?()\n   (Pdb)\n\nChanged in version 3.3: Tab-completion via the ``readline`` module is\navailable for commands and command arguments, e.g. the current global\nand local names are offered as arguments of the ``print`` command.\n\n``pdb.py`` can also be invoked as a script to debug other scripts.\nFor example:\n\n   python3 -m pdb myscript.py\n\nWhen invoked as a script, pdb will automatically enter post-mortem\ndebugging if the program being debugged exits abnormally.  After post-\nmortem debugging (or after normal exit of the program), pdb will\nrestart the program.  Automatic restarting preserves pdb\'s state (such\nas breakpoints) and in most cases is more useful than quitting the\ndebugger upon program\'s exit.\n\nNew in version 3.2: ``pdb.py`` now accepts a ``-c`` option that\nexecutes commands as if given in a ``.pdbrc`` file, see *Debugger\nCommands*.\n\nThe typical usage to break into the debugger from a running program is\nto insert\n\n   import pdb; pdb.set_trace()\n\nat the location you want to break into the debugger.  You can then\nstep through the code following this statement, and continue running\nwithout the debugger using the ``continue`` command.\n\nThe typical usage to inspect a crashed program is:\n\n   >>> import pdb\n   >>> import mymodule\n   >>> mymodule.test()\n   Traceback (most recent call last):\n     File "<stdin>", line 1, in ?\n     File "./mymodule.py", line 4, in test\n       test2()\n     File "./mymodule.py", line 3, in test2\n       print(spam)\n   NameError: spam\n   >>> pdb.pm()\n   > ./mymodule.py(3)test2()\n   -> print(spam)\n   (Pdb)\n\nThe module defines the following functions; each enters the debugger\nin a slightly different way:\n\npdb.run(statement, globals=None, locals=None)\n\n   Execute the *statement* (given as a string or a code object) under\n   debugger control.  The debugger prompt appears before any code is\n   executed; you can set breakpoints and type ``continue``, or you can\n   step through the statement using ``step`` or ``next`` (all these\n   commands are explained below).  The optional *globals* and *locals*\n   arguments specify the environment in which the code is executed; by\n   default the dictionary of the module ``__main__`` is used.  (See\n   the explanation of the built-in ``exec()`` or ``eval()``\n   functions.)\n\npdb.runeval(expression, globals=None, locals=None)\n\n   Evaluate the *expression* (given as a string or a code object)\n   under debugger control.  When ``runeval()`` returns, it returns the\n   value of the expression.  Otherwise this function is similar to\n   ``run()``.\n\npdb.runcall(function, *args, **kwds)\n\n   Call the *function* (a function or method object, not a string)\n   with the given arguments.  When ``runcall()`` returns, it returns\n   whatever the function call returned.  The debugger prompt appears\n   as soon as the function is entered.\n\npdb.set_trace()\n\n   Enter the debugger at the calling stack frame.  This is useful to\n   hard-code a breakpoint at a given point in a program, even if the\n   code is not otherwise being debugged (e.g. when an assertion\n   fails).\n\npdb.post_mortem(traceback=None)\n\n   Enter post-mortem debugging of the given *traceback* object.  If no\n   *traceback* is given, it uses the one of the exception that is\n   currently being handled (an exception must be being handled if the\n   default is to be used).\n\npdb.pm()\n\n   Enter post-mortem debugging of the traceback found in\n   ``sys.last_traceback``.\n\nThe ``run*`` functions and ``set_trace()`` are aliases for\ninstantiating the ``Pdb`` class and calling the method of the same\nname.  If you want to access further features, you have to do this\nyourself:\n\nclass class pdb.Pdb(completekey=\'tab\', stdin=None, stdout=None, skip=None, nosigint=False)\n\n   ``Pdb`` is the debugger class.\n\n   The *completekey*, *stdin* and *stdout* arguments are passed to the\n   underlying ``cmd.Cmd`` class; see the description there.\n\n   The *skip* argument, if given, must be an iterable of glob-style\n   module name patterns.  The debugger will not step into frames that\n   originate in a module that matches one of these patterns. [1]\n\n   By default, Pdb sets a handler for the SIGINT signal (which is sent\n   when the user presses Ctrl-C on the console) when you give a\n   ``continue`` command. This allows you to break into the debugger\n   again by pressing Ctrl-C.  If you want Pdb not to touch the SIGINT\n   handler, set *nosigint* tot true.\n\n   Example call to enable tracing with *skip*:\n\n      import pdb; pdb.Pdb(skip=[\'django.*\']).set_trace()\n\n   New in version 3.1: The *skip* argument.\n\n   New in version 3.2: The *nosigint* argument.  Previously, a SIGINT\n   handler was never set by Pdb.\n\n   run(statement, globals=None, locals=None)\n   runeval(expression, globals=None, locals=None)\n   runcall(function, *args, **kwds)\n   set_trace()\n\n      See the documentation for the functions explained above.\n\n\nDebugger Commands\n=================\n\nThe commands recognized by the debugger are listed below.  Most\ncommands can be abbreviated to one or two letters as indicated; e.g.\n``h(elp)`` means that either ``h`` or ``help`` can be used to enter\nthe help command (but not ``he`` or ``hel``, nor ``H`` or ``Help`` or\n``HELP``).  Arguments to commands must be separated by whitespace\n(spaces or tabs).  Optional arguments are enclosed in square brackets\n(``[]``) in the command syntax; the square brackets must not be typed.\nAlternatives in the command syntax are separated by a vertical bar\n(``|``).\n\nEntering a blank line repeats the last command entered.  Exception: if\nthe last command was a ``list`` command, the next 11 lines are listed.\n\nCommands that the debugger doesn\'t recognize are assumed to be Python\nstatements and are executed in the context of the program being\ndebugged.  Python statements can also be prefixed with an exclamation\npoint (``!``).  This is a powerful way to inspect the program being\ndebugged; it is even possible to change a variable or call a function.\nWhen an exception occurs in such a statement, the exception name is\nprinted but the debugger\'s state is not changed.\n\nThe debugger supports *aliases*.  Aliases can have parameters which\nallows one a certain level of adaptability to the context under\nexamination.\n\nMultiple commands may be entered on a single line, separated by\n``;;``.  (A single ``;`` is not used as it is the separator for\nmultiple commands in a line that is passed to the Python parser.)  No\nintelligence is applied to separating the commands; the input is split\nat the first ``;;`` pair, even if it is in the middle of a quoted\nstring.\n\nIf a file ``.pdbrc`` exists in the user\'s home directory or in the\ncurrent directory, it is read in and executed as if it had been typed\nat the debugger prompt.  This is particularly useful for aliases.  If\nboth files exist, the one in the home directory is read first and\naliases defined there can be overridden by the local file.\n\nChanged in version 3.2: ``.pdbrc`` can now contain commands that\ncontinue debugging, such as ``continue`` or ``next``.  Previously,\nthese commands had no effect.\n\nh(elp) [command]\n\n   Without argument, print the list of available commands.  With a\n   *command* as argument, print help about that command.  ``help pdb``\n   displays the full documentation (the docstring of the ``pdb``\n   module).  Since the *command* argument must be an identifier,\n   ``help exec`` must be entered to get help on the ``!`` command.\n\nw(here)\n\n   Print a stack trace, with the most recent frame at the bottom.  An\n   arrow indicates the current frame, which determines the context of\n   most commands.\n\nd(own) [count]\n\n   Move the current frame *count* (default one) levels down in the\n   stack trace (to a newer frame).\n\nu(p) [count]\n\n   Move the current frame *count* (default one) levels up in the stack\n   trace (to an older frame).\n\nb(reak) [([filename:]lineno | function) [, condition]]\n\n   With a *lineno* argument, set a break there in the current file.\n   With a *function* argument, set a break at the first executable\n   statement within that function.  The line number may be prefixed\n   with a filename and a colon, to specify a breakpoint in another\n   file (probably one that hasn\'t been loaded yet).  The file is\n   searched on ``sys.path``.  Note that each breakpoint is assigned a\n   number to which all the other breakpoint commands refer.\n\n   If a second argument is present, it is an expression which must\n   evaluate to true before the breakpoint is honored.\n\n   Without argument, list all breaks, including for each breakpoint,\n   the number of times that breakpoint has been hit, the current\n   ignore count, and the associated condition if any.\n\ntbreak [([filename:]lineno | function) [, condition]]\n\n   Temporary breakpoint, which is removed automatically when it is\n   first hit. The arguments are the same as for ``break``.\n\ncl(ear) [filename:lineno | bpnumber [bpnumber ...]]\n\n   With a *filename:lineno* argument, clear all the breakpoints at\n   this line. With a space separated list of breakpoint numbers, clear\n   those breakpoints. Without argument, clear all breaks (but first\n   ask confirmation).\n\ndisable [bpnumber [bpnumber ...]]\n\n   Disable the breakpoints given as a space separated list of\n   breakpoint numbers.  Disabling a breakpoint means it cannot cause\n   the program to stop execution, but unlike clearing a breakpoint, it\n   remains in the list of breakpoints and can be (re-)enabled.\n\nenable [bpnumber [bpnumber ...]]\n\n   Enable the breakpoints specified.\n\nignore bpnumber [count]\n\n   Set the ignore count for the given breakpoint number.  If count is\n   omitted, the ignore count is set to 0.  A breakpoint becomes active\n   when the ignore count is zero.  When non-zero, the count is\n   decremented each time the breakpoint is reached and the breakpoint\n   is not disabled and any associated condition evaluates to true.\n\ncondition bpnumber [condition]\n\n   Set a new *condition* for the breakpoint, an expression which must\n   evaluate to true before the breakpoint is honored.  If *condition*\n   is absent, any existing condition is removed; i.e., the breakpoint\n   is made unconditional.\n\ncommands [bpnumber]\n\n   Specify a list of commands for breakpoint number *bpnumber*.  The\n   commands themselves appear on the following lines.  Type a line\n   containing just ``end`` to terminate the commands. An example:\n\n      (Pdb) commands 1\n      (com) print some_variable\n      (com) end\n      (Pdb)\n\n   To remove all commands from a breakpoint, type commands and follow\n   it immediately with ``end``; that is, give no commands.\n\n   With no *bpnumber* argument, commands refers to the last breakpoint\n   set.\n\n   You can use breakpoint commands to start your program up again.\n   Simply use the continue command, or step, or any other command that\n   resumes execution.\n\n   Specifying any command resuming execution (currently continue,\n   step, next, return, jump, quit and their abbreviations) terminates\n   the command list (as if that command was immediately followed by\n   end). This is because any time you resume execution (even with a\n   simple next or step), you may encounter another breakpoint--which\n   could have its own command list, leading to ambiguities about which\n   list to execute.\n\n   If you use the \'silent\' command in the command list, the usual\n   message about stopping at a breakpoint is not printed.  This may be\n   desirable for breakpoints that are to print a specific message and\n   then continue.  If none of the other commands print anything, you\n   see no sign that the breakpoint was reached.\n\ns(tep)\n\n   Execute the current line, stop at the first possible occasion\n   (either in a function that is called or on the next line in the\n   current function).\n\nn(ext)\n\n   Continue execution until the next line in the current function is\n   reached or it returns.  (The difference between ``next`` and\n   ``step`` is that ``step`` stops inside a called function, while\n   ``next`` executes called functions at (nearly) full speed, only\n   stopping at the next line in the current function.)\n\nunt(il) [lineno]\n\n   Without argument, continue execution until the line with a number\n   greater than the current one is reached.\n\n   With a line number, continue execution until a line with a number\n   greater or equal to that is reached.  In both cases, also stop when\n   the current frame returns.\n\n   Changed in version 3.2: Allow giving an explicit line number.\n\nr(eturn)\n\n   Continue execution until the current function returns.\n\nc(ont(inue))\n\n   Continue execution, only stop when a breakpoint is encountered.\n\nj(ump) lineno\n\n   Set the next line that will be executed.  Only available in the\n   bottom-most frame.  This lets you jump back and execute code again,\n   or jump forward to skip code that you don\'t want to run.\n\n   It should be noted that not all jumps are allowed -- for instance\n   it is not possible to jump into the middle of a ``for`` loop or out\n   of a ``finally`` clause.\n\nl(ist) [first[, last]]\n\n   List source code for the current file.  Without arguments, list 11\n   lines around the current line or continue the previous listing.\n   With ``.`` as argument, list 11 lines around the current line.\n   With one argument, list 11 lines around at that line.  With two\n   arguments, list the given range; if the second argument is less\n   than the first, it is interpreted as a count.\n\n   The current line in the current frame is indicated by ``->``.  If\n   an exception is being debugged, the line where the exception was\n   originally raised or propagated is indicated by ``>>``, if it\n   differs from the current line.\n\n   New in version 3.2: The ``>>`` marker.\n\nll | longlist\n\n   List all source code for the current function or frame.\n   Interesting lines are marked as for ``list``.\n\n   New in version 3.2.\n\na(rgs)\n\n   Print the argument list of the current function.\n\np(rint) expression\n\n   Evaluate the *expression* in the current context and print its\n   value.\n\npp expression\n\n   Like the ``print`` command, except the value of the expression is\n   pretty-printed using the ``pprint`` module.\n\nwhatis expression\n\n   Print the type of the *expression*.\n\nsource expression\n\n   Try to get source code for the given object and display it.\n\n   New in version 3.2.\n\ndisplay [expression]\n\n   Display the value of the expression if it changed, each time\n   execution stops in the current frame.\n\n   Without expression, list all display expressions for the current\n   frame.\n\n   New in version 3.2.\n\nundisplay [expression]\n\n   Do not display the expression any more in the current frame.\n   Without expression, clear all display expressions for the current\n   frame.\n\n   New in version 3.2.\n\ninteract\n\n   Start an interative interpreter (using the ``code`` module) whose\n   global namespace contains all the (global and local) names found in\n   the current scope.\n\n   New in version 3.2.\n\nalias [name [command]]\n\n   Create an alias called *name* that executes *command*.  The command\n   must *not* be enclosed in quotes.  Replaceable parameters can be\n   indicated by ``%1``, ``%2``, and so on, while ``%*`` is replaced by\n   all the parameters. If no command is given, the current alias for\n   *name* is shown. If no arguments are given, all aliases are listed.\n\n   Aliases may be nested and can contain anything that can be legally\n   typed at the pdb prompt.  Note that internal pdb commands *can* be\n   overridden by aliases.  Such a command is then hidden until the\n   alias is removed.  Aliasing is recursively applied to the first\n   word of the command line; all other words in the line are left\n   alone.\n\n   As an example, here are two useful aliases (especially when placed\n   in the ``.pdbrc`` file):\n\n      # Print instance variables (usage "pi classInst")\n      alias pi for k in %1.__dict__.keys(): print("%1.",k,"=",%1.__dict__[k])\n      # Print instance variables in self\n      alias ps pi self\n\nunalias name\n\n   Delete the specified alias.\n\n! statement\n\n   Execute the (one-line) *statement* in the context of the current\n   stack frame. The exclamation point can be omitted unless the first\n   word of the statement resembles a debugger command.  To set a\n   global variable, you can prefix the assignment command with a\n   ``global`` statement on the same line, e.g.:\n\n      (Pdb) global list_options; list_options = [\'-l\']\n      (Pdb)\n\nrun [args ...]\nrestart [args ...]\n\n   Restart the debugged Python program.  If an argument is supplied,\n   it is split with ``shlex`` and the result is used as the new\n   ``sys.argv``. History, breakpoints, actions and debugger options\n   are preserved. ``restart`` is an alias for ``run``.\n\nq(uit)\n\n   Quit from the debugger.  The program being executed is aborted.\n\n-[ Footnotes ]-\n\n[1] Whether a frame is considered to originate in a certain module is\n    determined by the ``__name__`` in the frame globals.\n',
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/locale.py:        alias engine. A ValueError is raised in case the locale name
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/locale.py:# The following data was extracted from the locale.alias file which
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/locale.py:# The local_encoding_alias table maps lowercase encoding alias names
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/locale.py:locale_encoding_alias = {
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/locale.py:# The locale_alias table maps lowercase alias names to C locale names
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/locale.py:# Updated alias mapping to most recent locale.alias file
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/locale.py:# Updated alias mapping to most recent locale.alias file
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/locale.py:# Updated alias mapping to most recent locale.alias file
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/locale.py:locale_alias = {
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/ctypes/__init__.py:    # if int and long have the same size, make c_int an alias for c_long
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/ctypes/__init__.py:    # if long and long long have the same size, make c_longlong an alias for c_long
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/threading.py:# alias for the PEP 8 compliant names
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/urllib/parse.py:# For backwards compatibility, alias _NetlocResultMixinStr
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/os2emxpath.py:# alias exists to lexists
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/posixpath.py:this module as os.path.  The "os.path" name is an alias for this
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/posixpath.py:platform, and is an alias to another module (e.g. macpath, ntpath).
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/configparser.py:    """ConfigParser alias for backwards compatibility purposes."""
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/configparser.py:            "in Python 3.2. This alias will be removed in future versions."
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/platform.py:#    0.3.0 - added system alias support
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/encodings/aliases.py:    # codec and alias it to latin_1 instead.
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/encodings/__init__.py:    # First try to find an alias for the normalized encoding
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/encodings/__init__.py:        for alias in codecaliases:
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/encodings/__init__.py:            if alias not in _aliases:
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/email/charset.py:    alias is the alias name, e.g. latin-1
Binary file /home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/email/__pycache__/charset.cpython-33.pyc matches
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/smtpd.py:# - alias files
Binary file /home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/__pycache__/posixpath.cpython-33.pyc matches
Binary file /home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/__pycache__/locale.cpython-33.pyc matches
Binary file /home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/__pycache__/base64.cpython-33.pyc matches
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/base64.py:    """Legacy alias of encodebytes()."""
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/base64.py:    """Legacy alias of decodebytes()."""
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/pdb.py:have parameters (see the alias help entry) which allows one a certain
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/pdb.py:        """Handle alias expansion and ';;' separator."""
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/pdb.py:        # unless it's an alias command
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/pdb.py:        context of most commands.  'bt' is an alias for this command.
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/pdb.py:        are preserved.  "restart" is an alias for "run".
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/pdb.py:    # make "print" an alias of "p" since print isn't a Python statement anymore
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/pdb.py:        """alias [name [command [parameter parameter ...] ]]
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/pdb.py:        Create an alias called 'name' that executes 'command'.  The
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/pdb.py:        current alias for name is shown. If no name is given, all
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/pdb.py:        are then hidden until the alias is removed.  Aliasing is
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/pdb.py:        alias pi for k in %1.__dict__.keys(): print "%1.",k,"=",%1.__dict__[k]
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/pdb.py:        alias ps pi self
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/pdb.py:            for alias in keys:
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/pdb.py:        """unalias name
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/argparse.py:        for alias in aliases:
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/xml/etree/cElementTree.py:# Deprecated alias for xml.etree.ElementTree
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/xml/dom/minidom.py:    # nodeValue is an alias for data
/home/bani/Dropbox/tools/Blender/blender/2.65/python/lib/python3.3/xml/dom/minidom.py:    # nodeName is an alias for target
Binary file /home/bani/Dropbox/tools/Blender/blender/blenderplayer matches
/home/bani/Dropbox/tools/freeplane-1.2.20/doc/freeplane.mm:      <font face="SansSerif, sans-serif" color="#000000"><span style="color: #000000; font-family: SansSerif, sans-serif">To install Freeplane on Mac OS X first use the built in Software Update feature to ensure that you have all the latest available updates, especially Java. Software Update is located under the Apple logo menu in the top left-hand corner of the screen. Then download a Mac-specific version of Freeplane. The .dmg version is easiest to install, though a .zip version may also be available. When the download is complete, the file may be automatically mounted (or un-zipped) depending on your Web browser settings. Otherwise either double-click on the downloaded .dmg file to &quot;mount&quot; it, or double-click on the downloaded .zip file to un-zip it. Now you should see a Freeplane application icon, which you can drag to your Applications folder. Then you may optionally create an alias (short-cut) on the Desktop, and/or on the Dock. To run Freeplane, either double-click on its application icon (in the Applications folder) or on its Desktop short-cut, or click once on its icon in the Dock. The Freeplane Wiki has Macintosh page with more information.</span></font>
/home/bani/Dropbox/tools/freeplane-1.2.20/doc/freeplane.mm:<node TEXT="Antialias Edges" ID="ID_1654348959" CREATED="1311483457645" MODIFIED="1311483550591">
/home/bani/Dropbox/tools/freeplane-1.2.20/doc/freeplane.mm:<node TEXT="Antialias all" ID="ID_627671109" CREATED="1311483468403" MODIFIED="1311483542121">
/home/bani/Dropbox/tools/freeplane-1.2.20/doc/freeplane_it.mm:      Per installare Freeplane con il sistema operativo <b>Mac OS X</b>, la prima cosa &#232; assicurarsi di avere tutti gli ultimi aggiornamenti disponibili, in particolare Java. L'aggiornamento Software si trova sotto il menu logo Apple in alto a sinistra dello schermo.<br/><br/>Quindi scaricare una versione per Mac specifica di Freeplane. La versione Dmg &#232; pi&#249; facile da installare, attraverso un file .zip disponibile. Quando il download &#232; completato, il file pu&#242; essere montato automaticamente (o decompresso) a seconda delle impostazioni del browser web. In caso contrario, fare doppio clic sul file. Dmg scaricato per &quot;montare&quot;, o fare doppio clic sul file. Zip scaricato per scompattarlo.<br/><br/>Ora si dovrebbe vedere una icona dell'applicazione Freeplane, che &#232; possibile trascinare nella cartella Applicazioni. Poi si pu&#242; opzionalmente creare un alias (collegamento) sul desktop, e / o nel Dock. Per eseguire Freeplane, fare doppio clic sulla sua icona dell'applicazione (nella cartella Applicazioni) o sul suo collegamento sul desktop, oppure fare clic una volta sulla sua icona nel Dock. Il wiki di Freeplane ha una pagina per Macintosh, con ulteriori informazioni.
/home/bani/Dropbox/tools/freeplane-1.2.20/doc/history_en.txt:* Antialias and selection option changes are now directly applied.
/home/bani/Dropbox/10th/Command-line interface:Unlike a button or menu item in a GUI, a command line is typically self-documenting, stating exactly what the user wants done. In addition, command lines usually include many defaults that can be changed to customize the results. Useful command lines can be saved by assigning a character string or alias to represent the full command, or several commands can be grouped to perform a more complex sequence – for instance, compile the program, install it, and run it — creating a single entity, called a command procedure or script which itself can be treated as a command. These advantages mean that a user must figure out a complex command or series of commands only once, because they can be saved, to be used again.
/home/bani/Dropbox/Inbox/__tazjelz/backupz/workflow/5_Do/Shell/You can also make....txt:alias LANshare='python -c "import SimpleHTTPServer; SimpleHTTPServer.test();"'
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_bashrc:  alias ls="ls --color=auto"
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_bashrc:  alias ll="ls --color=auto -l"
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_bashrc:  alias grep='grep --color=auto'
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_bashrc:  alias fgrep='fgrep --color=auto'
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_bashrc:  alias egrep='egrep --color=auto'
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_bashrc:  alias ls="ls -F"
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_bashrc:  alias ll="ls -lF"
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_bashrc:alias vim="$vim"
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/_vim/_vim/_vim/bundle/snipmate/doc/snipMate.txt:< SnipMate scopes are akin to filetypes.  Setting a scope alias as shown above
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/_vim/_vim/_vim/bundle/snippets/snippets/chef.snippets:		${6:#}reference ${7} # (Git only) alias for revision
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/_vim/_vim/_vim/bundle/snippets/snippets/chef.snippets:		${6:#}reference ${7} # (Git only) alias for revision
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/_vim/_vim/_vim/bundle/snippets/snippets/chef.snippets:		${6:#}repo ${7} # alias for repository
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/_vim/_vim/_vim/bundle/snippets/snippets/chef.snippets:		${10:#}branch ${11} # alias for revision
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/_vim/_vim/_vim/bundle/snippets/snippets/chef.snippets:		${30:#}git_ssh_wrapper ${31} # alias for ssh_wrapper
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/_vim/bundle/snipmate/doc/snipMate.txt:< SnipMate scopes are akin to filetypes.  Setting a scope alias as shown above
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/_vim/bundle/snippets/snippets/chef.snippets:		${6:#}reference ${7} # (Git only) alias for revision
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/_vim/bundle/snippets/snippets/chef.snippets:		${6:#}reference ${7} # (Git only) alias for revision
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/_vim/bundle/snippets/snippets/chef.snippets:		${6:#}repo ${7} # alias for repository
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/_vim/bundle/snippets/snippets/chef.snippets:		${10:#}branch ${11} # alias for revision
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/_vim/bundle/snippets/snippets/chef.snippets:		${30:#}git_ssh_wrapper ${31} # alias for ssh_wrapper
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/bundle/snipmate/doc/snipMate.txt:< SnipMate scopes are akin to filetypes.  Setting a scope alias as shown above
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/bundle/snippets/snippets/chef.snippets:		${6:#}reference ${7} # (Git only) alias for revision
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/bundle/snippets/snippets/chef.snippets:		${6:#}reference ${7} # (Git only) alias for revision
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/bundle/snippets/snippets/chef.snippets:		${6:#}repo ${7} # alias for repository
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/bundle/snippets/snippets/chef.snippets:		${10:#}branch ${11} # alias for revision
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/_vim/bundle/snippets/snippets/chef.snippets:		${30:#}git_ssh_wrapper ${31} # alias for ssh_wrapper
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/bundle/snipmate/doc/snipMate.txt:< SnipMate scopes are akin to filetypes.  Setting a scope alias as shown above
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/bundle/snippets/snippets/chef.snippets:		${6:#}reference ${7} # (Git only) alias for revision
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/bundle/snippets/snippets/chef.snippets:		${6:#}reference ${7} # (Git only) alias for revision
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/bundle/snippets/snippets/chef.snippets:		${6:#}repo ${7} # alias for repository
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/bundle/snippets/snippets/chef.snippets:		${10:#}branch ${11} # alias for revision
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/bundle/snippets/snippets/chef.snippets:		${30:#}git_ssh_wrapper ${31} # alias for ssh_wrapper
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/bundle/ropevim/ftplugin/python/libs/rope/base/worder.py:            alias = self._find_word_end(as_ + 1)
/home/bani/Dropbox/Inbox/__dotfiles/dotfiles/_vim/bundle/ropevim/ftplugin/python/libs/rope/base/worder.py:            return self.raw[start:alias + 1]
/home/bani/Dropbox/Inbox/__inboxz/ak/py/Keyboard/evdevxfree86 keycodes.py:    alias <MENU> = <COMP>;
/home/bani/Dropbox/Inbox/__inboxz/ak/py/Keyboard/evdevxfree86 keycodes.py:    alias <LMTA> = <LWIN>;
/home/bani/Dropbox/Inbox/__inboxz/ak/py/Keyboard/evdevxfree86 keycodes.py:    alias <RMTA> = <RWIN>;
/home/bani/Dropbox/Inbox/__inboxz/ak/py/Keyboard/evdevxfree86 keycodes.py:    alias <ALGR> = <RALT>;
/home/bani/Dropbox/Inbox/__inboxz/ak/py/web2py/web2py:	# and leave 'force-reload' as an alias for 'restart'.
/home/bani/Dropbox/Inbox/__inboxz/ak/py/my scrap/Python_syntax_highlighter/index.html:<p>If you want to lookup a built-in lexer by its alias or a filename, you can use
/home/bani/Dropbox/Inbox/__inboxz/ak/py/my scrap/05_The_Views/index.html:<table><tbody><tr valign="top"><td style="width: 40px; text-align: right;"><pre style="font-size: 11px; font-family: Bitstream Vera Sans Mono,monospace; background-color: transparent; margin: 0pt; padding: 5px; border: medium none; color: rgb(160, 160, 160);">1.<br>2.</pre></td><td><pre style="font-size: 11px; font-family: Bitstream Vera Sans Mono,monospace; background-color: transparent; margin: 0pt; padding: 5px; border: medium none; overflow: auto;"><span style="font-weight: bold;">&gt;&gt;&gt; </span><span style="color: rgb(24, 83, 105); font-weight: bold;">print </span><a href="http://www.web2py.com/book/default/docstring/OL" style="text-decoration: none; color: rgb(255, 92, 31);">OL</a><span style="font-weight: bold;">(</span><span style="color: rgb(255, 153, 102);">'&lt;hello&gt;'</span><span style="font-weight: bold;">, </span><a href="http://www.web2py.com/book/default/docstring/XML" style="text-decoration: none; color: rgb(255, 92, 31);">XML</a><span style="font-weight: bold;">(</span><span style="color: rgb(255, 153, 102);">'&lt;b&gt;world&lt;/b&gt;'</span><span style="font-weight: bold;">), </span>_class<span style="font-weight: bold;">=</span><span style="color: rgb(255, 153, 102);">'test'</span><span style="font-weight: bold;">, </span>_id<span style="font-weight: bold;">=</span><span style="color: red;">0</span><span style="font-weight: bold;">)<br>&lt;</span>ol id<span style="font-weight: bold;">=</span><span style="color: rgb(255, 153, 102);">"0" </span><span style="color: rgb(24, 83, 105); font-weight: bold;">class</span><span style="font-weight: bold;">=</span><span style="color: rgb(255, 153, 102);">"test"</span><span style="font-weight: bold;">&gt;&lt;</span>li<span style="font-weight: bold;">&gt;&amp;</span>lt;hello<span style="font-weight: bold;">&amp;</span>gt;<span style="font-weight: bold;">&lt;/</span>li<span style="font-weight: bold;">&gt;&lt;</span>li<span style="font-weight: bold;">&gt;&lt;</span>b<span style="font-weight: bold;">&gt;</span>world<span style="font-weight: bold;">&lt;/</span>b<span style="font-weight: bold;">&gt;&lt;/</span>li<span style="font-weight: bold;">&gt;&lt;/</span>ol<span style="font-weight: bold;">&gt;</span></pre></td></tr></tbody></table><h4><code class="">ON</code></h4><p>This is here for backward compatibility and it is simply an alias for <code class="">True</code>. It is used exclusively for checkboxes and deprecated since <code class="">True</code> is more Pythonic.</p><p></p><div class="inxx">ON</div>
/home/bani/Dropbox/Inbox/__inboxz/ak/py/my scrap/06_The_Database_Abstraction_Layer/index.html:<table><tbody><tr valign="top"><td style="width: 40px; text-align: right;"><pre style="font-size: 11px; font-family: Bitstream Vera Sans Mono,monospace; background-color: transparent; margin: 0pt; padding: 5px; border: medium none; color: rgb(160, 160, 160);">1.<br>2.<br>3.<br>4.<br>5.<br>6.<br>7.<br>8.<br>9.<br>10.<br>11.<br>12.<br>13.<br>14.<br>15.<br>16.</pre></td><td><pre style="font-size: 11px; font-family: Bitstream Vera Sans Mono,monospace; background-color: transparent; margin: 0pt; padding: 5px; border: medium none; overflow: auto;"><span style="font-weight: bold;">&gt;&gt;&gt; </span>Father <span style="font-weight: bold;">= </span>db<span style="font-weight: bold;">.</span>person<span style="font-weight: bold;">.</span>with_alias<span style="font-weight: bold;">(</span><span style="color: rgb(255, 153, 102);">'father'</span><span style="font-weight: bold;">)<br>&gt;&gt;&gt; </span>Mother <span style="font-weight: bold;">= </span>db<span style="font-weight: bold;">.</span>person<span style="font-weight: bold;">.</span>with_alias<span style="font-weight: bold;">(</span><span style="color: rgb(255, 153, 102);">'mother'</span><span style="font-weight: bold;">)<br>&gt;&gt;&gt; </span>db<span style="font-weight: bold;">.</span>person<span style="font-weight: bold;">.</span>insert<span style="font-weight: bold;">(</span>name<span style="font-weight: bold;">=</span><span style="color: rgb(255, 153, 102);">'Massimo'</span><span style="font-weight: bold;">)<br></span><span style="color: red;">1<br></span><span style="font-weight: bold;">&gt;&gt;&gt; </span>db<span style="font-weight: bold;">.</span>person<span style="font-weight: bold;">.</span>insert<span style="font-weight: bold;">(</span>name<span style="font-weight: bold;">=</span><span style="color: rgb(255, 153, 102);">'Claudia'</span><span style="font-weight: bold;">)<br></span><span style="color: red;">2<br></span><span style="font-weight: bold;">&gt;&gt;&gt; </span>db<span style="font-weight: bold;">.</span>person<span style="font-weight: bold;">.</span>insert<span style="font-weight: bold;">(</span>name<span style="font-weight: bold;">=</span><span style="color: rgb(255, 153, 102);">'Marco'</span><span style="font-weight: bold;">, </span>father_id<span style="font-weight: bold;">=</span><span style="color: red;">1</span><span style="font-weight: bold;">, </span>mother_id<span style="font-weight: bold;">=</span><span style="color: red;">2</span><span style="font-weight: bold;">)<br></span><span style="color: red;">3<br></span><span style="font-weight: bold;">&gt;&gt;&gt; </span>rows <span style="font-weight: bold;">= </span>db<span style="font-weight: bold;">().</span>select<span style="font-weight: bold;">(</span>db<span style="font-weight: bold;">.</span>person<span style="font-weight: bold;">.</span>name<span style="font-weight: bold;">, </span>Father<span style="font-weight: bold;">.</span>name<span style="font-weight: bold;">, </span>Mother<span style="font-weight: bold;">.</span>name<span style="font-weight: bold;">,<br>      </span>left<span style="font-weight: bold;">=(</span>Father<span style="font-weight: bold;">.</span>on<span style="font-weight: bold;">(</span>Father<span style="font-weight: bold;">.</span>id<span style="font-weight: bold;">==</span>db<span style="font-weight: bold;">.</span>person<span style="font-weight: bold;">.</span>father_id<span style="font-weight: bold;">),<br>            </span>Mother<span style="font-weight: bold;">.</span>on<span style="font-weight: bold;">(</span>Mother<span style="font-weight: bold;">.</span>id<span style="font-weight: bold;">==</span>db<span style="font-weight: bold;">.</span>person<span style="font-weight: bold;">.</span>mother_id<span style="font-weight: bold;">)))<br>&gt;&gt;&gt; </span><span style="color: rgb(24, 83, 105); font-weight: bold;">for </span>row <span style="color: rgb(24, 83, 105); font-weight: bold;">in </span>rows<span style="font-weight: bold;">:<br>        </span><span style="color: rgb(24, 83, 105); font-weight: bold;">print </span>row<span style="font-weight: bold;">.</span>person<span style="font-weight: bold;">.</span>name<span style="font-weight: bold;">, </span>row<span style="font-weight: bold;">.</span>father<span style="font-weight: bold;">.</span>name<span style="font-weight: bold;">, </span>row<span style="font-weight: bold;">.</span>mother<span style="font-weight: bold;">.</span>name<br>Massimo <span style="color: rgb(24, 83, 105); font-weight: bold;">None None<br></span>Claudia <span style="color: rgb(24, 83, 105); font-weight: bold;">None None<br></span>Marco Massimo Claudia</pre></td></tr></tbody></table><p>Notice that we have chosen to make a distinction between:</p><ul><li>"father_id": the field name used in the table "person";</li><li>"father": the alias we want to use for the table referenced by the above field; this is communicated to the database;</li><li>"Father": the variable used by web2py to refer to that alias.</li></ul><p>The difference is subtle, and there is nothing wrong in using the same name for the three of them:
/home/bani/Dropbox/Inbox/__inboxz/ak/py/my scrap/07_Forms_and_Validators/index.html:</p><table><tbody><tr valign="top"><td style="width: 40px; text-align: right;"><pre style="font-size: 11px; font-family: Bitstream Vera Sans Mono,monospace; background-color: transparent; margin: 0pt; padding: 5px; border: medium none; color: rgb(160, 160, 160);">1.</pre></td><td><pre style="font-size: 11px; font-family: Bitstream Vera Sans Mono,monospace; background-color: transparent; margin: 0pt; padding: 5px; border: medium none; overflow: auto;">requires <span style="font-weight: bold;">= </span><a href="http://www.web2py.com/book/default/docstring/IS_UPPER" style="text-decoration: none; color: rgb(255, 92, 31);">IS_UPPER</a><span style="font-weight: bold;">()</span></pre></td></tr></tbody></table><h4><code class="">IS_NULL_OR</code></h4><div class="inxx">IS_NULL_OR</div><p>Deprecated, an alias for <code class="">IS_EMPTY_OR</code> described below.</p><h4><code class="">IS_EMPTY_OR</code></h4><div class="inxx">IS_EMPTY_OR</div><p>Sometimes you need to allow empty values on a field along with other requirements. For example a field may be a date but it can also be empty.
/home/bani/Dropbox/Inbox/__inboxz/ak/py/py stff/snippets/Python/cache.rdf:                   NS1:content="Navigation index modules | next | previous | Python v2.7.1 documentation » Python Frequently Asked Questions » Programming FAQ¶ Contents Programming FAQ General Questions Is there a source code level debugger with breakpoints, single-stepping, etc.? Is there a tool to help find bugs or perform static analysis? How can I create a stand-alone binary from a Python script? Are there coding standards or a style guide for Python programs? My program is too slow. How do I speed it up? Core Language Why am I getting an UnboundLocalError when the variable has a value? What are the rules for local and global variables in Python? How do I share global variables across modules? What are the “best practices” for using import in a module? How can I pass optional or keyword parameters from one function to another? How do I write a function with output parameters (call by reference)? How do you make a higher order function in Python? How do I copy an object in Python? How can I find the methods or attributes of an object? How can my code discover the name of an object? What’s up with the comma operator’s precedence? Is there an equivalent of C’s “?:” ternary operator? Is it possible to write obfuscated one-liners in Python? Numbers and strings How do I specify hexadecimal and octal integers? Why does -22 // 10 return -3? How do I convert a string to a number? How do I convert a number to a string? How do I modify a string in place? How do I use strings to call functions/methods? Is there an equivalent to Perl’s chomp() for removing trailing newlines from strings? Is there a scanf() or sscanf() equivalent? What does ‘UnicodeError: ASCII [decoding,encoding] error: ordinal not in range(128)’ mean? Sequences (Tuples/Lists) How do I convert between tuples and lists? What’s a negative index? How do I iterate over a sequence in reverse order? How do you remove duplicates from a list? How do you make an array in Python? How do I create a multidimensional list? How do I apply a method to a sequence of objects? Dictionaries How can I get a dictionary to display its keys in a consistent order? I want to do a complicated sort: can you do a Schwartzian Transform in Python? How can I sort one list by values from another list? Objects What is a class? What is a method? What is self? How do I check if an object is an instance of a given class or of a subclass of it? What is delegation? How do I call a method defined in a base class from a derived class that overrides it? How can I organize my code to make it easier to change the base class? How do I create static class data and static class methods? How can I overload constructors (or methods) in Python? I try to use __spam and I get an error about _SomeClassName__spam. My class defines __del__ but it is not called when I delete the object. How do I get a list of all instances of a given class? Modules How do I create a .pyc file? How do I find the current module name? How can I have modules that mutually import each other? __import__(‘x.y.z’) returns &lt;module ‘x’&gt;; how do I get z? When I edit an imported module and reimport it, the changes don’t show up. Why does this happen? General Questions¶ Is there a source code level debugger with breakpoints, single-stepping, etc.?¶ Yes. The pdb module is a simple but adequate console-mode debugger for Python. It is part of the standard Python library, and is documented in the Library Reference Manual. You can also write your own debugger by using the code for pdb as an example. The IDLE interactive development environment, which is part of the standard Python distribution (normally available as Tools/scripts/idle), includes a graphical debugger. There is documentation for the IDLE debugger at http://www.python.org/idle/doc/idle2.html#Debugger. PythonWin is a Python IDE that includes a GUI debugger based on pdb. The Pythonwin debugger colors breakpoints and has quite a few cool features such as debugging non-Pythonwin programs. Pythonwin is available as part of the Python for Windows Extensions project and as a part of the ActivePython distribution (see http://www.activestate.com/Products/ActivePython/index.html). Boa Constructor is an IDE and GUI builder that uses wxWidgets. It offers visual frame creation and manipulation, an object inspector, many views on the source like object browsers, inheritance hierarchies, doc string generated html documentation, an advanced debugger, integrated help, and Zope support. Eric is an IDE built on PyQt and the Scintilla editing component. Pydb is a version of the standard Python debugger pdb, modified for use with DDD (Data Display Debugger), a popular graphical debugger front end. Pydb can be found at http://bashdb.sourceforge.net/pydb/ and DDD can be found at http://www.gnu.org/software/ddd. There are a number of commercial Python IDEs that include graphical debuggers. They include: Wing IDE (http://wingware.com/) Komodo IDE (http://www.activestate.com/Products/Komodo) Is there a tool to help find bugs or perform static analysis?¶ Yes. PyChecker is a static analysis tool that finds bugs in Python source code and warns about code complexity and style. You can get PyChecker from http://pychecker.sf.net. Pylint is another tool that checks if a module satisfies a coding standard, and also makes it possible to write plug-ins to add a custom feature. In addition to the bug checking that PyChecker performs, Pylint offers some additional features such as checking line length, whether variable names are well-formed according to your coding standard, whether declared interfaces are fully implemented, and more. http://www.logilab.org/card/pylint_manual provides a full list of Pylint’s features. How can I create a stand-alone binary from a Python script?¶ You don’t need the ability to compile Python to C code if all you want is a stand-alone program that users can download and run without having to install the Python distribution first. There are a number of tools that determine the set of modules required by a program and bind these modules together with a Python binary to produce a single executable. One is to use the freeze tool, which is included in the Python source tree as Tools/freeze. It converts Python byte code to C arrays; a C compiler you can embed all your modules into a new program, which is then linked with the standard Python modules. It works by scanning your source recursively for import statements (in both forms) and looking for the modules in the standard Python path as well as in the source directory (for built-in modules). It then turns the bytecode for modules written in Python into C code (array initializers that can be turned into code objects using the marshal module) and creates a custom-made config file that only contains those built-in modules which are actually used in the program. It then compiles the generated C code and links it with the rest of the Python interpreter to form a self-contained binary which acts exactly like your script. Obviously, freeze requires a C compiler. There are several other utilities which don’t. One is Thomas Heller’s py2exe (Windows only) at http://www.py2exe.org/ Another is Christian Tismer’s SQFREEZE which appends the byte code to a specially-prepared Python interpreter that can find the byte code in the executable. Other tools include Fredrik Lundh’s Squeeze and Anthony Tuininga’s cx_Freeze. Are there coding standards or a style guide for Python programs?¶ Yes. The coding style required for standard library modules is documented as PEP 8. My program is too slow. How do I speed it up?¶ That’s a tough one, in general. There are many tricks to speed up Python code; consider rewriting parts in C as a last resort. In some cases it’s possible to automatically translate Python to C or x86 assembly language, meaning that you don’t have to modify your code to gain increased speed. Pyrex can compile a slightly modified version of Python code into a C extension, and can be used on many different platforms. Psyco is a just-in-time compiler that translates Python code into x86 assembly language. If you can use it, Psyco can provide dramatic speedups for critical functions. The rest of this answer will discuss various tricks for squeezing a bit more speed out of Python code. Never apply any optimization tricks unless you know you need them, after profiling has indicated that a particular function is the heavily executed hot spot in the code. Optimizations almost always make the code less clear, and you shouldn’t pay the costs of reduced clarity (increased development time, greater likelihood of bugs) unless the resulting performance benefit is worth it. There is a page on the wiki devoted to performance tips. Guido van Rossum has written up an anecdote related to optimization at http://www.python.org/doc/essays/list2str.html. One thing to notice is that function and (especially) method calls are rather expensive; if you have designed a purely OO interface with lots of tiny functions that don’t do much more than get or set an instance variable or call another method, you might consider using a more direct way such as directly accessing instance variables. Also see the standard module profile which makes it possible to find out where your program is spending most of its time (if you have some patience – the profiling itself can slow your program down by an order of magnitude). Remember that many standard optimization heuristics you may know from other programming experience may well apply to Python. For example it may be faster to send output to output devices using larger writes rather than smaller ones in order to reduce the overhead of kernel system calls. Thus CGI scripts that write all output in “one shot” may be faster than those that write lots of small pieces of output. Also, be sure to use Python’s core features where appropriate. For example, slicing allows programs to chop up lists and other sequence objects in a single tick of the interpreter’s mainloop using highly optimized C implementations. Thus to get the same effect as: L2 = [] for i in range[3]: L2.append(L1[i]) it is much shorter and far faster to use L2 = list(L1[:3]) # &quot;list&quot; is redundant if L1 is a list. Note that the functionally-oriented built-in functions such as map(), zip(), and friends can be a convenient accelerator for loops that perform a single task. For example to pair the elements of two lists together: &gt;&gt;&gt; zip([1, 2, 3], [4, 5, 6]) [(1, 4), (2, 5), (3, 6)] or to compute a number of sines: &gt;&gt;&gt; map(math.sin, (1, 2, 3, 4)) [0.841470984808, 0.909297426826, 0.14112000806, -0.756802495308] The operation completes very quickly in such cases. Other examples include the join() and split() methods of string objects. For example if s1..s7 are large (10K+) strings then &quot;&quot;.join([s1,s2,s3,s4,s5,s6,s7]) may be far faster than the more obvious s1+s2+s3+s4+s5+s6+s7, since the “summation” will compute many subexpressions, whereas join() does all the copying in one pass. For manipulating strings, use the replace() and the format() methods on string objects. Use regular expressions only when you’re not dealing with constant string patterns. You may still use the old % operations string % tuple and string % dictionary. Be sure to use the list.sort() built-in method to do sorting, and see the sorting mini-HOWTO for examples of moderately advanced usage. list.sort() beats other techniques for sorting in all but the most extreme circumstances. Another common trick is to “push loops into functions or methods.” For example suppose you have a program that runs slowly and you use the profiler to determine that a Python function ff() is being called lots of times. If you notice that ff(): def ff(x): ... # do something with x computing result... return result tends to be called in loops like: list = map(ff, oldlist) or: for x in sequence: value = ff(x) ... # do something with value... then you can often eliminate function call overhead by rewriting ff() to: def ffseq(seq): resultseq = [] for x in seq: ... # do something with x computing result... resultseq.append(result) return resultseq and rewrite the two examples to list = ffseq(oldlist) and to: for value in ffseq(sequence): ... # do something with value... Single calls to ff(x) translate to ffseq([x])[0] with little penalty. Of course this technique is not always appropriate and there are other variants which you can figure out. You can gain some performance by explicitly storing the results of a function or method lookup into a local variable. A loop like: for key in token: dict[key] = dict.get(key, 0) + 1 resolves dict.get every iteration. If the method isn’t going to change, a slightly faster implementation is: dict_get = dict.get # look up the method once for key in token: dict[key] = dict_get(key, 0) + 1 Default arguments can be used to determine values once, at compile time instead of at run time. This can only be done for functions or objects which will not be changed during program execution, such as replacing def degree_sin(deg): return math.sin(deg * math.pi / 180.0) with def degree_sin(deg, factor=math.pi/180.0, sin=math.sin): return sin(deg * factor) Because this trick uses default arguments for terms which should not be changed, it should only be used when you are not concerned with presenting a possibly confusing API to your users. Core Language¶ Why am I getting an UnboundLocalError when the variable has a value?¶ It can be a surprise to get the UnboundLocalError in previously working code when it is modified by adding an assignment statement somewhere in the body of a function. This code: &gt;&gt;&gt; x = 10 &gt;&gt;&gt; def bar(): ... print x &gt;&gt;&gt; bar() 10 works, but this code: &gt;&gt;&gt; x = 10 &gt;&gt;&gt; def foo(): ... print x ... x += 1 results in an UnboundLocalError: &gt;&gt;&gt; foo() Traceback (most recent call last): ... UnboundLocalError: local variable 'x' referenced before assignment This is because when you make an assignment to a variable in a scope, that variable becomes local to that scope and shadows any similarly named variable in the outer scope. Since the last statement in foo assigns a new value to x, the compiler recognizes it as a local variable. Consequently when the earlier print x attempts to print the uninitialized local variable and an error results. In the example above you can access the outer scope variable by declaring it global: &gt;&gt;&gt; x = 10 &gt;&gt;&gt; def foobar(): ... global x ... print x ... x += 1 &gt;&gt;&gt; foobar() 10 This explicit declaration is required in order to remind you that (unlike the superficially analogous situation with class and instance variables) you are actually modifying the value of the variable in the outer scope: &gt;&gt;&gt; print x 11 What are the rules for local and global variables in Python?¶ In Python, variables that are only referenced inside a function are implicitly global. If a variable is assigned a new value anywhere within the function’s body, it’s assumed to be a local. If a variable is ever assigned a new value inside the function, the variable is implicitly local, and you need to explicitly declare it as ‘global’. Though a bit surprising at first, a moment’s consideration explains this. On one hand, requiring global for assigned variables provides a bar against unintended side-effects. On the other hand, if global was required for all global references, you’d be using global all the time. You’d have to declare as global every reference to a built-in function or to a component of an imported module. This clutter would defeat the usefulness of the global declaration for identifying side-effects. How do I share global variables across modules?¶ The canonical way to share information across modules within a single program is to create a special module (often called config or cfg). Just import the config module in all modules of your application; the module then becomes available as a global name. Because there is only one instance of each module, any changes made to the module object get reflected everywhere. For example: config.py: x = 0 # Default value of the 'x' configuration setting mod.py: import config config.x = 1 main.py: import config import mod print config.x Note that using a module is also the basis for implementing the Singleton design pattern, for the same reason. What are the “best practices” for using import in a module?¶ In general, don’t use from modulename import *. Doing so clutters the importer’s namespace. Some people avoid this idiom even with the few modules that were designed to be imported in this manner. Modules designed in this manner include Tkinter, and threading. Import modules at the top of a file. Doing so makes it clear what other modules your code requires and avoids questions of whether the module name is in scope. Using one import per line makes it easy to add and delete module imports, but using multiple imports per line uses less screen space. It’s good practice if you import modules in the following order: standard library modules – e.g. sys, os, getopt, re third-party library modules (anything installed in Python’s site-packages directory) – e.g. mx.DateTime, ZODB, PIL.Image, etc. locally-developed modules Never use relative package imports. If you’re writing code that’s in the package.sub.m1 module and want to import package.sub.m2, do not just write import m2, even though it’s legal. Write from package.sub import m2 instead. Relative imports can lead to a module being initialized twice, leading to confusing bugs. See PEP 328 for details. It is sometimes necessary to move imports to a function or class to avoid problems with circular imports. Gordon McMillan says: Circular imports are fine where both modules use the “import &lt;module&gt;” form of import. They fail when the 2nd module wants to grab a name out of the first (“from module import name”) and the import is at the top level. That’s because names in the 1st are not yet available, because the first module is busy importing the 2nd. In this case, if the second module is only used in one function, then the import can easily be moved into that function. By the time the import is called, the first module will have finished initializing, and the second module can do its import. It may also be necessary to move imports out of the top level of code if some of the modules are platform-specific. In that case, it may not even be possible to import all of the modules at the top of the file. In this case, importing the correct modules in the corresponding platform-specific code is a good option. Only move imports into a local scope, such as inside a function definition, if it’s necessary to solve a problem such as avoiding a circular import or are trying to reduce the initialization time of a module. This technique is especially helpful if many of the imports are unnecessary depending on how the program executes. You may also want to move imports into a function if the modules are only ever used in that function. Note that loading a module the first time may be expensive because of the one time initialization of the module, but loading a module multiple times is virtually free, costing only a couple of dictionary lookups. Even if the module name has gone out of scope, the module is probably available in sys.modules. If only instances of a specific class use a module, then it is reasonable to import the module in the class’s __init__ method and then assign the module to an instance variable so that the module is always available (via that instance variable) during the life of the object. Note that to delay an import until the class is instantiated, the import must be inside a method. Putting the import inside the class but outside of any method still causes the import to occur when the module is initialized. How can I pass optional or keyword parameters from one function to another?¶ Collect the arguments using the * and ** specifiers in the function’s parameter list; this gives you the positional arguments as a tuple and the keyword arguments as a dictionary. You can then pass these arguments when calling another function by using * and **: def f(x, *args, **kwargs): ... kwargs['width'] = '14.3c' ... g(x, *args, **kwargs) In the unlikely case that you care about Python versions older than 2.0, use apply(): def f(x, *args, **kwargs): ... kwargs['width'] = '14.3c' ... apply(g, (x,)+args, kwargs) How do I write a function with output parameters (call by reference)?¶ Remember that arguments are passed by assignment in Python. Since assignment just creates references to objects, there’s no alias between an argument name in the caller and callee, and so no call-by-reference per se. You can achieve the desired effect in a number of ways. By returning a tuple of the results: def func2(a, b): a = 'new-value' # a and b are local names b = b + 1 # assigned to new objects return a, b # return new values x, y = 'old-value', 99 x, y = func2(x, y) print x, y # output: new-value 100 This is almost always the clearest solution. By using global variables. This isn’t thread-safe, and is not recommended. By passing a mutable (changeable in-place) object: def func1(a): a[0] = 'new-value' # 'a' references a mutable list a[1] = a[1] + 1 # changes a shared object args = ['old-value', 99] func1(args) print args[0], args[1] # output: new-value 100 By passing in a dictionary that gets mutated: def func3(args): args['a'] = 'new-value' # args is a mutable dictionary args['b'] = args['b'] + 1 # change it in-place args = {'a':' old-value', 'b': 99} func3(args) print args['a'], args['b'] Or bundle up values in a class instance: class callByRef: def __init__(self, **args): for (key, value) in args.items(): setattr(self, key, value) def func4(args): args.a = 'new-value' # args is a mutable callByRef args.b = args.b + 1 # change object in-place args = callByRef(a='old-value', b=99) func4(args) print args.a, args.b There’s almost never a good reason to get this complicated. Your best choice is to return a tuple containing the multiple results. How do you make a higher order function in Python?¶ You have two choices: you can use nested scopes or you can use callable objects. For example, suppose you wanted to define linear(a,b) which returns a function f(x) that computes the value a*x+b. Using nested scopes: def linear(a, b): def result(x): return a * x + b return result Or using a callable object: class linear: def __init__(self, a, b): self.a, self.b = a, b def __call__(self, x): return self.a * x + self.b In both cases, taxes = linear(0.3, 2) gives a callable object where taxes(10e6) == 0.3 * 10e6 + 2. The callable object approach has the disadvantage that it is a bit slower and results in slightly longer code. However, note that a collection of callables can share their signature via inheritance: class exponential(linear): # __init__ inherited def __call__(self, x): return self.a * (x ** self.b) Object can encapsulate state for several methods: class counter: value = 0 def set(self, x): self.value = x def up(self): self.value = self.value + 1 def down(self): self.value = self.value - 1 count = counter() inc, dec, reset = count.up, count.down, count.set Here inc(), dec() and reset() act like functions which share the same counting variable. How do I copy an object in Python?¶ In general, try copy.copy() or copy.deepcopy() for the general case. Not all objects can be copied, but most can. Some objects can be copied more easily. Dictionaries have a copy() method: newdict = olddict.copy() Sequences can be copied by slicing: new_l = l[:] How can I find the methods or attributes of an object?¶ For an instance x of a user-defined class, dir(x) returns an alphabetized list of the names containing the instance attributes and methods and attributes defined by its class. How can my code discover the name of an object?¶ Generally speaking, it can’t, because objects don’t really have names. Essentially, assignment always binds a name to a value; The same is true of def and class statements, but in that case the value is a callable. Consider the following code: class A: pass B = A a = B() b = a print b &lt;__main__.A instance at 0x16D07CC&gt; print a &lt;__main__.A instance at 0x16D07CC&gt; Arguably the class has a name: even though it is bound to two names and invoked through the name B the created instance is still reported as an instance of class A. However, it is impossible to say whether the instance’s name is a or b, since both names are bound to the same value. Generally speaking it should not be necessary for your code to “know the names” of particular values. Unless you are deliberately writing introspective programs, this is usually an indication that a change of approach might be beneficial. In comp.lang.python, Fredrik Lundh once gave an excellent analogy in answer to this question: The same way as you get the name of that cat you found on your porch: the cat (object) itself cannot tell you its name, and it doesn’t really care – so the only way to find out what it’s called is to ask all your neighbours (namespaces) if it’s their cat (object)... ....and don’t be surprised if you’ll find that it’s known by many names, or no name at all! What’s up with the comma operator’s precedence?¶ Comma is not an operator in Python. Consider this session: &gt;&gt;&gt; &quot;a&quot; in &quot;b&quot;, &quot;a&quot; (False, 'a') Since the comma is not an operator, but a separator between expressions the above is evaluated as if you had entered: &gt;&gt;&gt; (&quot;a&quot; in &quot;b&quot;), &quot;a&quot; not: &gt;&gt;&gt; &quot;a&quot; in (&quot;b&quot;, &quot;a&quot;) The same is true of the various assignment operators (=, += etc). They are not truly operators but syntactic delimiters in assignment statements. Is there an equivalent of C’s “?:” ternary operator?¶ Yes, this feature was added in Python 2.5. The syntax would be as follows: [on_true] if [expression] else [on_false] x, y = 50, 25 small = x if x &lt; y else y For versions previous to 2.5 the answer would be ‘No’. In many cases you can mimic a ? b : c with a and b or c, but there’s a flaw: if b is zero (or empty, or None – anything that tests false) then c will be selected instead. In many cases you can prove by looking at the code that this can’t happen (e.g. because b is a constant or has a type that can never be false), but in general this can be a problem. Tim Peters (who wishes it was Steve Majewski) suggested the following solution: (a and [b] or [c])[0]. Because [b] is a singleton list it is never false, so the wrong path is never taken; then applying [0] to the whole thing gets the b or c that you really wanted. Ugly, but it gets you there in the rare cases where it is really inconvenient to rewrite your code using ‘if’. The best course is usually to write a simple if...else statement. Another solution is to implement the ?: operator as a function: def q(cond, on_true, on_false): if cond: if not isfunction(on_true): return on_true else: return on_true() else: if not isfunction(on_false): return on_false else: return on_false() In most cases you’ll pass b and c directly: q(a, b, c). To avoid evaluating b or c when they shouldn’t be, encapsulate them within a lambda function, e.g.: q(a, lambda: b, lambda: c). It has been asked why Python has no if-then-else expression. There are several answers: many languages do just fine without one; it can easily lead to less readable code; no sufficiently “Pythonic” syntax has been discovered; a search of the standard library found remarkably few places where using an if-then-else expression would make the code more understandable. In 2002, PEP 308 was written proposing several possible syntaxes and the community was asked to vote on the issue. The vote was inconclusive. Most people liked one of the syntaxes, but also hated other syntaxes; many votes implied that people preferred no ternary operator rather than having a syntax they hated. Is it possible to write obfuscated one-liners in Python?¶ Yes. Usually this is done by nesting lambda within lambda. See the following three examples, due to Ulf Bartelt: # Primes &lt; 1000 print filter(None,map(lambda y:y*reduce(lambda x,y:x*y!=0, map(lambda x,y=y:y%x,range(2,int(pow(y,0.5)+1))),1),range(2,1000))) # First 10 Fibonacci numbers print map(lambda x,f=lambda x,f:(f(x-1,f)+f(x-2,f)) if x&gt;1 else 1: f(x,f), range(10)) # Mandelbrot set print (lambda Ru,Ro,Iu,Io,IM,Sx,Sy:reduce(lambda x,y:x+y,map(lambda y, Iu=Iu,Io=Io,Ru=Ru,Ro=Ro,Sy=Sy,L=lambda yc,Iu=Iu,Io=Io,Ru=Ru,Ro=Ro,i=IM, Sx=Sx,Sy=Sy:reduce(lambda x,y:x+y,map(lambda x,xc=Ru,yc=yc,Ru=Ru,Ro=Ro, i=i,Sx=Sx,F=lambda xc,yc,x,y,k,f=lambda xc,yc,x,y,k,f:(k&lt;=0)or (x*x+y*y &gt;=4.0) or 1+f(xc,yc,x*x-y*y+xc,2.0*x*y+yc,k-1,f):f(xc,yc,x,y,k,f):chr( 64+F(Ru+x*(Ro-Ru)/Sx,yc,0,0,i)),range(Sx))):L(Iu+y*(Io-Iu)/Sy),range(Sy ))))(-2.1, 0.7, -1.2, 1.2, 30, 80, 24) # \___ ___/ \___ ___/ | | |__ lines on screen # V V | |______ columns on screen # | | |__________ maximum of &quot;iterations&quot; # | |_________________ range on y axis # |____________________________ range on x axis Don’t try this at home, kids! Numbers and strings¶ How do I specify hexadecimal and octal integers?¶ To specify an octal digit, precede the octal value with a zero, and then a lower or uppercase “o”. For example, to set the variable “a” to the octal value “10” (8 in decimal), type: &gt;&gt;&gt; a = 0o10 &gt;&gt;&gt; a 8 Hexadecimal is just as easy. Simply precede the hexadecimal number with a zero, and then a lower or uppercase “x”. Hexadecimal digits can be specified in lower or uppercase. For example, in the Python interpreter: &gt;&gt;&gt; a = 0xa5 &gt;&gt;&gt; a 165 &gt;&gt;&gt; b = 0XB2 &gt;&gt;&gt; b 178 Why does -22 // 10 return -3?¶ It’s primarily driven by the desire that i % j have the same sign as j. If you want that, and also want: i == (i // j) * j + (i % j) then integer division has to return the floor. C also requires that identity to hold, and then compilers that truncate i // j need to make i % j have the same sign as i. There are few real use cases for i % j when j is negative. When j is positive, there are many, and in virtually all of them it’s more useful for i % j to be &gt;= 0. If the clock says 10 now, what did it say 200 hours ago? -190 % 12 == 2 is useful; -190 % 12 == -10 is a bug waiting to bite. Note On Python 2, a / b returns the same as a // b if __future__.division is not in effect. This is also known as “classic” division. How do I convert a string to a number?¶ For integers, use the built-in int() type constructor, e.g. int('144') == 144. Similarly, float() converts to floating-point, e.g. float('144') == 144.0. By default, these interpret the number as decimal, so that int('0144') == 144 and int('0x144') raises ValueError. int(string, base) takes the base to convert from as a second optional argument, so int('0x144', 16) == 324. If the base is specified as 0, the number is interpreted using Python’s rules: a leading ‘0’ indicates octal, and ‘0x’ indicates a hex number. Do not use the built-in function eval() if all you need is to convert strings to numbers. eval() will be significantly slower and it presents a security risk: someone could pass you a Python expression that might have unwanted side effects. For example, someone could pass __import__('os').system(&quot;rm -rf $HOME&quot;) which would erase your home directory. eval() also has the effect of interpreting numbers as Python expressions, so that e.g. eval('09') gives a syntax error because Python regards numbers starting with ‘0’ as octal (base 8). How do I convert a number to a string?¶ To convert, e.g., the number 144 to the string ‘144’, use the built-in type constructor str(). If you want a hexadecimal or octal representation, use the built-in functions hex() or oct(). For fancy formatting, see the Format String Syntax section, e.g. &quot;{:04d}&quot;.format(144) yields '0144' and &quot;{:.3f}&quot;.format(1/3) yields '0.333'. You may also use the % operator on strings. See the library reference manual for details. How do I modify a string in place?¶ You can’t, because strings are immutable. If you need an object with this ability, try converting the string to a list or use the array module: &gt;&gt;&gt; s = &quot;Hello, world&quot; &gt;&gt;&gt; a = list(s) &gt;&gt;&gt; print a ['H', 'e', 'l', 'l', 'o', ',', ' ', 'w', 'o', 'r', 'l', 'd'] &gt;&gt;&gt; a[7:] = list(&quot;there!&quot;) &gt;&gt;&gt; ''.join(a) 'Hello, there!' &gt;&gt;&gt; import array &gt;&gt;&gt; a = array.array('c', s) &gt;&gt;&gt; print a array('c', 'Hello, world') &gt;&gt;&gt; a[0] = 'y' ; print a array('c', 'yello world') &gt;&gt;&gt; a.tostring() 'yello, world' How do I use strings to call functions/methods?¶ There are various techniques. The best is to use a dictionary that maps strings to functions. The primary advantage of this technique is that the strings do not need to match the names of the functions. This is also the primary technique used to emulate a case construct: def a(): pass def b(): pass dispatch = {'go': a, 'stop': b} # Note lack of parens for funcs dispatch[get_input()]() # Note trailing parens to call function Use the built-in function getattr(): import foo getattr(foo, 'bar')() Note that getattr() works on any object, including classes, class instances, modules, and so on. This is used in several places in the standard library, like this: class Foo: def do_foo(self): ... def do_bar(self): ... f = getattr(foo_instance, 'do_' + opname) f() Use locals() or eval() to resolve the function name: def myFunc(): print &quot;hello&quot; fname = &quot;myFunc&quot; f = locals()[fname] f() f = eval(fname) f() Note: Using eval() is slow and dangerous. If you don’t have absolute control over the contents of the string, someone could pass a string that resulted in an arbitrary function being executed. Is there an equivalent to Perl’s chomp() for removing trailing newlines from strings?¶ Starting with Python 2.2, you can use S.rstrip(&quot;\r\n&quot;) to remove all occurrences of any line terminator from the end of the string S without removing other trailing whitespace. If the string S represents more than one line, with several empty lines at the end, the line terminators for all the blank lines will be removed: &gt;&gt;&gt; lines = (&quot;line 1 \r\n&quot; ... &quot;\r\n&quot; ... &quot;\r\n&quot;) &gt;&gt;&gt; lines.rstrip(&quot;\n\r&quot;) 'line 1 ' Since this is typically only desired when reading text one line at a time, using S.rstrip() this way works well. For older versions of Python, there are two partial substitutes: If you want to remove all trailing whitespace, use the rstrip() method of string objects. This removes all trailing whitespace, not just a single newline. Otherwise, if there is only one line in the string S, use S.splitlines()[0]. Is there a scanf() or sscanf() equivalent?¶ Not as such. For simple input parsing, the easiest approach is usually to split the line into whitespace-delimited words using the split() method of string objects and then convert decimal strings to numeric values using int() or float(). split() supports an optional “sep” parameter which is useful if the line uses something other than whitespace as a separator. For more complicated input parsing, regular expressions are more powerful than C’s sscanf() and better suited for the task. What does ‘UnicodeError: ASCII [decoding,encoding] error: ordinal not in range(128)’ mean?¶ This error indicates that your Python installation can handle only 7-bit ASCII strings. There are a couple ways to fix or work around the problem. If your programs must handle data in arbitrary character set encodings, the environment the application runs in will generally identify the encoding of the data it is handing you. You need to convert the input to Unicode data using that encoding. For example, a program that handles email or web input will typically find character set encoding information in Content-Type headers. This can then be used to properly convert input data to Unicode. Assuming the string referred to by value is encoded as UTF-8: value = unicode(value, &quot;utf-8&quot;) will return a Unicode object. If the data is not correctly encoded as UTF-8, the above call will raise a UnicodeError exception. If you only want strings converted to Unicode which have non-ASCII data, you can try converting them first assuming an ASCII encoding, and then generate Unicode objects if that fails: try: x = unicode(value, &quot;ascii&quot;) except UnicodeError: value = unicode(value, &quot;utf-8&quot;) else: # value was valid ASCII data pass It’s possible to set a default encoding in a file called sitecustomize.py that’s part of the Python library. However, this isn’t recommended because changing the Python-wide default encoding may cause third-party extension modules to fail. Note that on Windows, there is an encoding known as “mbcs”, which uses an encoding specific to your current locale. In many cases, and particularly when working with COM, this may be an appropriate default encoding to use. Sequences (Tuples/Lists)¶ How do I convert between tuples and lists?¶ The type constructor tuple(seq) converts any sequence (actually, any iterable) into a tuple with the same items in the same order. For example, tuple([1, 2, 3]) yields (1, 2, 3) and tuple('abc') yields ('a', 'b', 'c'). If the argument is a tuple, it does not make a copy but returns the same object, so it is cheap to call tuple() when you aren’t sure that an object is already a tuple. The type constructor list(seq) converts any sequence or iterable into a list with the same items in the same order. For example, list((1, 2, 3)) yields [1, 2, 3] and list('abc') yields ['a', 'b', 'c']. If the argument is a list, it makes a copy just like seq[:] would. What’s a negative index?¶ Python sequences are indexed with positive numbers and negative numbers. For positive numbers 0 is the first index 1 is the second index and so forth. For negative indices -1 is the last index and -2 is the penultimate (next to last) index and so forth. Think of seq[-n] as the same as seq[len(seq)-n]. Using negative indices can be very convenient. For example S[:-1] is all of the string except for its last character, which is useful for removing the trailing newline from a string. How do I iterate over a sequence in reverse order?¶ Use the reversed() built-in function, which is new in Python 2.4: for x in reversed(sequence): ... # do something with x... This won’t touch your original sequence, but build a new copy with reversed order to iterate over. With Python 2.3, you can use an extended slice syntax: for x in sequence[::-1]: ... # do something with x... How do you remove duplicates from a list?¶ See the Python Cookbook for a long discussion of many ways to do this: http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/52560 If you don’t mind reordering the list, sort it and then scan from the end of the list, deleting duplicates as you go: if mylist: mylist.sort() last = mylist[-1] for i in range(len(mylist)-2, -1, -1): if last == mylist[i]: del mylist[i] else: last = mylist[i] If all elements of the list may be used as dictionary keys (i.e. they are all hashable) this is often faster d = {} for x in mylist: d[x] = 1 mylist = list(d.keys()) In Python 2.5 and later, the following is possible instead: mylist = list(set(mylist)) This converts the list into a set, thereby removing duplicates, and then back into a list. How do you make an array in Python?¶ Use a list: [&quot;this&quot;, 1, &quot;is&quot;, &quot;an&quot;, &quot;array&quot;] Lists are equivalent to C or Pascal arrays in their time complexity; the primary difference is that a Python list can contain objects of many different types. The array module also provides methods for creating arrays of fixed types with compact representations, but they are slower to index than lists. Also note that the Numeric extensions and others define array-like structures with various characteristics as well. To get Lisp-style linked lists, you can emulate cons cells using tuples: lisp_list = (&quot;like&quot;, (&quot;this&quot;, (&quot;example&quot;, None) ) ) If mutability is desired, you could use lists instead of tuples. Here the analogue of lisp car is lisp_list[0] and the analogue of cdr is lisp_list[1]. Only do this if you’re sure you really need to, because it’s usually a lot slower than using Python lists. How do I create a multidimensional list?¶ You probably tried to make a multidimensional array like this: A = [[None] * 2] * 3 This looks correct if you print it: &gt;&gt;&gt; A [[None, None], [None, None], [None, None]] But when you assign a value, it shows up in multiple places: &gt;&gt;&gt; A[0][0] = 5 &gt;&gt;&gt; A [[5, None], [5, None], [5, None]] The reason is that replicating a list with * doesn’t create copies, it only creates references to the existing objects. The *3 creates a list containing 3 references to the same list of length two. Changes to one row will show in all rows, which is almost certainly not what you want. The suggested approach is to create a list of the desired length first and then fill in each element with a newly created list: A = [None] * 3 for i in range(3): A[i] = [None] * 2 This generates a list containing 3 different lists of length two. You can also use a list comprehension: w, h = 2, 3 A = [[None] * w for i in range(h)] Or, you can use an extension that provides a matrix datatype; Numeric Python is the best known. How do I apply a method to a sequence of objects?¶ Use a list comprehension: result = [obj.method() for obj in mylist] More generically, you can try the following function: def method_map(objects, method, arguments): &quot;&quot;&quot;method_map([a,b], &quot;meth&quot;, (1,2)) gives [a.meth(1,2), b.meth(1,2)]&quot;&quot;&quot; nobjects = len(objects) methods = map(getattr, objects, [method]*nobjects) return map(apply, methods, [arguments]*nobjects) Dictionaries¶ How can I get a dictionary to display its keys in a consistent order?¶ You can’t. Dictionaries store their keys in an unpredictable order, so the display order of a dictionary’s elements will be similarly unpredictable. This can be frustrating if you want to save a printable version to a file, make some changes and then compare it with some other printed dictionary. In this case, use the pprint module to pretty-print the dictionary; the items will be presented in order sorted by the key. A more complicated solution is to subclass dict to create a SortedDict class that prints itself in a predictable order. Here’s one simpleminded implementation of such a class: class SortedDict(dict): def __repr__(self): keys = sorted(self.keys()) result = (&quot;{!r}: {!r}&quot;.format(k, self[k]) for k in keys) return &quot;{{{}}}&quot;.format(&quot;, &quot;.join(result)) __str__ = __repr__ This will work for many common situations you might encounter, though it’s far from a perfect solution. The largest flaw is that if some values in the dictionary are also dictionaries, their values won’t be presented in any particular order. I want to do a complicated sort: can you do a Schwartzian Transform in Python?¶ The technique, attributed to Randal Schwartz of the Perl community, sorts the elements of a list by a metric which maps each element to its “sort value”. In Python, just use the key argument for the sort() method: Isorted = L[:] Isorted.sort(key=lambda s: int(s[10:15])) The key argument is new in Python 2.4, for older versions this kind of sorting is quite simple to do with list comprehensions. To sort a list of strings by their uppercase values: tmp1 = [(x.upper(), x) for x in L] # Schwartzian transform tmp1.sort() Usorted = [x[1] for x in tmp1] To sort by the integer value of a subfield extending from positions 10-15 in each string: tmp2 = [(int(s[10:15]), s) for s in L] # Schwartzian transform tmp2.sort() Isorted = [x[1] for x in tmp2] Note that Isorted may also be computed by def intfield(s): return int(s[10:15]) def Icmp(s1, s2): return cmp(intfield(s1), intfield(s2)) Isorted = L[:] Isorted.sort(Icmp) but since this method calls intfield() many times for each element of L, it is slower than the Schwartzian Transform. How can I sort one list by values from another list?¶ Merge them into a single list of tuples, sort the resulting list, and then pick out the element you want. &gt;&gt;&gt; list1 = [&quot;what&quot;, &quot;I'm&quot;, &quot;sorting&quot;, &quot;by&quot;] &gt;&gt;&gt; list2 = [&quot;something&quot;, &quot;else&quot;, &quot;to&quot;, &quot;sort&quot;] &gt;&gt;&gt; pairs = zip(list1, list2) &gt;&gt;&gt; pairs [('what', 'something'), (&quot;I'm&quot;, 'else'), ('sorting', 'to'), ('by', 'sort')] &gt;&gt;&gt; pairs.sort() &gt;&gt;&gt; result = [ x[1] for x in pairs ] &gt;&gt;&gt; result ['else', 'sort', 'to', 'something'] An alternative for the last step is: &gt;&gt;&gt; result = [] &gt;&gt;&gt; for p in pairs: result.append(p[1]) If you find this more legible, you might prefer to use this instead of the final list comprehension. However, it is almost twice as slow for long lists. Why? First, the append() operation has to reallocate memory, and while it uses some tricks to avoid doing that each time, it still has to do it occasionally, and that costs quite a bit. Second, the expression “result.append” requires an extra attribute lookup, and third, there’s a speed reduction from having to make all those function calls. Objects¶ What is a class?¶ A class is the particular object type created by executing a class statement. Class objects are used as templates to create instance objects, which embody both the data (attributes) and code (methods) specific to a datatype. A class can be based on one or more other classes, called its base class(es). It then inherits the attributes and methods of its base classes. This allows an object model to be successively refined by inheritance. You might have a generic Mailbox class that provides basic accessor methods for a mailbox, and subclasses such as MboxMailbox, MaildirMailbox, OutlookMailbox that handle various specific mailbox formats. What is a method?¶ A method is a function on some object x that you normally call as x.name(arguments...). Methods are defined as functions inside the class definition: class C: def meth (self, arg): return arg * 2 + self.attribute What is self?¶ Self is merely a conventional name for the first argument of a method. A method defined as meth(self, a, b, c) should be called as x.meth(a, b, c) for some instance x of the class in which the definition occurs; the called method will think it is called as meth(x, a, b, c). See also Why must ‘self’ be used explicitly in method definitions and calls?. How do I check if an object is an instance of a given class or of a subclass of it?¶ Use the built-in function isinstance(obj, cls). You can check if an object is an instance of any of a number of classes by providing a tuple instead of a single class, e.g. isinstance(obj, (class1, class2, ...)), and can also check whether an object is one of Python’s built-in types, e.g. isinstance(obj, str) or isinstance(obj, (int, long, float, complex)). Note that most programs do not use isinstance() on user-defined classes very often. If you are developing the classes yourself, a more proper object-oriented style is to define methods on the classes that encapsulate a particular behaviour, instead of checking the object’s class and doing a different thing based on what class it is. For example, if you have a function that does something: def search(obj): if isinstance(obj, Mailbox): # ... code to search a mailbox elif isinstance(obj, Document): # ... code to search a document elif ... A better approach is to define a search() method on all the classes and just call it: class Mailbox: def search(self): # ... code to search a mailbox class Document: def search(self): # ... code to search a document obj.search() What is delegation?¶ Delegation is an object oriented technique (also called a design pattern). Let’s say you have an object x and want to change the behaviour of just one of its methods. You can create a new class that provides a new implementation of the method you’re interested in changing and delegates all other methods to the corresponding method of x. Python programmers can easily implement delegation. For example, the following class implements a class that behaves like a file but converts all written data to uppercase: class UpperOut: def __init__(self, outfile): self._outfile = outfile def write(self, s): self._outfile.write(s.upper()) def __getattr__(self, name): return getattr(self._outfile, name) Here the UpperOut class redefines the write() method to convert the argument string to uppercase before calling the underlying self.__outfile.write() method. All other methods are delegated to the underlying self.__outfile object. The delegation is accomplished via the __getattr__ method; consult the language reference for more information about controlling attribute access. Note that for more general cases delegation can get trickier. When attributes must be set as well as retrieved, the class must define a __setattr__() method too, and it must do so carefully. The basic implementation of __setattr__() is roughly equivalent to the following: class X: ... def __setattr__(self, name, value): self.__dict__[name] = value ... Most __setattr__() implementations must modify self.__dict__ to store local state for self without causing an infinite recursion. How do I call a method defined in a base class from a derived class that overrides it?¶ If you’re using new-style classes, use the built-in super() function: class Derived(Base): def meth (self): super(Derived, self).meth() If you’re using classic classes: For a class definition such as class Derived(Base): ... you can call method meth() defined in Base (or one of Base‘s base classes) as Base.meth(self, arguments...). Here, Base.meth is an unbound method, so you need to provide the self argument. How can I organize my code to make it easier to change the base class?¶ You could define an alias for the base class, assign the real base class to it before your class definition, and use the alias throughout your class. Then all you have to change is the value assigned to the alias. Incidentally, this trick is also handy if you want to decide dynamically (e.g. depending on availability of resources) which base class to use. Example: BaseAlias = &lt;real base class&gt; class Derived(BaseAlias): def meth(self): BaseAlias.meth(self) ... How do I create static class data and static class methods?¶ Both static data and static methods (in the sense of C++ or Java) are supported in Python. For static data, simply define a class attribute. To assign a new value to the attribute, you have to explicitly use the class name in the assignment: class C: count = 0 # number of times C.__init__ called def __init__(self): C.count = C.count + 1 def getcount(self): return C.count # or return self.count c.count also refers to C.count for any c such that isinstance(c, C) holds, unless overridden by c itself or by some class on the base-class search path from c.__class__ back to C. Caution: within a method of C, an assignment like self.count = 42 creates a new and unrelated instance named “count” in self‘s own dict. Rebinding of a class-static data name must always specify the class whether inside a method or not: C.count = 314 Static methods are possible since Python 2.2: class C: def static(arg1, arg2, arg3): # No 'self' parameter! ... static = staticmethod(static) With Python 2.4’s decorators, this can also be written as class C: @staticmethod def static(arg1, arg2, arg3): # No 'self' parameter! ... However, a far more straightforward way to get the effect of a static method is via a simple module-level function: def getcount(): return C.count If your code is structured so as to define one class (or tightly related class hierarchy) per module, this supplies the desired encapsulation. How can I overload constructors (or methods) in Python?¶ This answer actually applies to all methods, but the question usually comes up first in the context of constructors. In C++ you’d write class C { C() { cout &lt;&lt; &quot;No arguments\n&quot;; } C(int i) { cout &lt;&lt; &quot;Argument is &quot; &lt;&lt; i &lt;&lt; &quot;\n&quot;; } } In Python you have to write a single constructor that catches all cases using default arguments. For example: class C: def __init__(self, i=None): if i is None: print &quot;No arguments&quot; else: print &quot;Argument is&quot;, i This is not entirely equivalent, but close enough in practice. You could also try a variable-length argument list, e.g. def __init__(self, *args): ... The same approach works for all method definitions. I try to use __spam and I get an error about _SomeClassName__spam.¶ Variable names with double leading underscores are “mangled” to provide a simple but effective way to define class private variables. Any identifier of the form __spam (at least two leading underscores, at most one trailing underscore) is textually replaced with _classname__spam, where classname is the current class name with any leading underscores stripped. This doesn’t guarantee privacy: an outside user can still deliberately access the “_classname__spam” attribute, and private values are visible in the object’s __dict__. Many Python programmers never bother to use private variable names at all. My class defines __del__ but it is not called when I delete the object.¶ There are several possible reasons for this. The del statement does not necessarily call __del__() – it simply decrements the object’s reference count, and if this reaches zero __del__() is called. If your data structures contain circular links (e.g. a tree where each child has a parent reference and each parent has a list of children) the reference counts will never go back to zero. Once in a while Python runs an algorithm to detect such cycles, but the garbage collector might run some time after the last reference to your data structure vanishes, so your __del__() method may be called at an inconvenient and random time. This is inconvenient if you’re trying to reproduce a problem. Worse, the order in which object’s __del__() methods are executed is arbitrary. You can run gc.collect() to force a collection, but there are pathological cases where objects will never be collected. Despite the cycle collector, it’s still a good idea to define an explicit close() method on objects to be called whenever you’re done with them. The close() method can then remove attributes that refer to subobjecs. Don’t call __del__() directly – __del__() should call close() and close() should make sure that it can be called more than once for the same object. Another way to avoid cyclical references is to use the weakref module, which allows you to point to objects without incrementing their reference count. Tree data structures, for instance, should use weak references for their parent and sibling references (if they need them!). If the object has ever been a local variable in a function that caught an expression in an except clause, chances are that a reference to the object still exists in that function’s stack frame as contained in the stack trace. Normally, calling sys.exc_clear() will take care of this by clearing the last recorded exception. Finally, if your __del__() method raises an exception, a warning message is printed to sys.stderr. How do I get a list of all instances of a given class?¶ Python does not keep track of all instances of a class (or of a built-in type). You can program the class’s constructor to keep track of all instances by keeping a list of weak references to each instance. Modules¶ How do I create a .pyc file?¶ When a module is imported for the first time (or when the source is more recent than the current compiled file) a .pyc file containing the compiled code should be created in the same directory as the .py file. One reason that a .pyc file may not be created is permissions problems with the directory. This can happen, for example, if you develop as one user but run as another, such as if you are testing with a web server. Creation of a .pyc file is automatic if you’re importing a module and Python has the ability (permissions, free space, etc...) to write the compiled module back to the directory. Running Python on a top level script is not considered an import and no .pyc will be created. For example, if you have a top-level module abc.py that imports another module xyz.py, when you run abc, xyz.pyc will be created since xyz is imported, but no abc.pyc file will be created since abc.py isn’t being imported. If you need to create abc.pyc – that is, to create a .pyc file for a module that is not imported – you can, using the py_compile and compileall modules. The py_compile module can manually compile any module. One way is to use the compile() function in that module interactively: &gt;&gt;&gt; import py_compile &gt;&gt;&gt; py_compile.compile('abc.py') This will write the .pyc to the same location as abc.py (or you can override that with the optional parameter cfile). You can also automatically compile all files in a directory or directories using the compileall module. You can do it from the shell prompt by running compileall.py and providing the path of a directory containing Python files to compile: python -m compileall . How do I find the current module name?¶ A module can find out its own module name by looking at the predefined global variable __name__. If this has the value '__main__', the program is running as a script. Many modules that are usually used by importing them also provide a command-line interface or a self-test, and only execute this code after checking __name__: def main(): print 'Running test...' ... if __name__ == '__main__': main() How can I have modules that mutually import each other?¶ Suppose you have the following modules: foo.py: from bar import bar_var foo_var = 1 bar.py: from foo import foo_var bar_var = 2 The problem is that the interpreter will perform the following steps: main imports foo Empty globals for foo are created foo is compiled and starts executing foo imports bar Empty globals for bar are created bar is compiled and starts executing bar imports foo (which is a no-op since there already is a module named foo) bar.foo_var = foo.foo_var The last step fails, because Python isn’t done with interpreting foo yet and the global symbol dictionary for foo is still empty. The same thing happens when you use import foo, and then try to access foo.foo_var in global code. There are (at least) three possible workarounds for this problem. Guido van Rossum recommends avoiding all uses of from &lt;module&gt; import ..., and placing all code inside functions. Initializations of global variables and class variables should use constants or built-in functions only. This means everything from an imported module is referenced as &lt;module&gt;.&lt;name&gt;. Jim Roskind suggests performing steps in the following order in each module: exports (globals, functions, and classes that don’t need imported base classes) import statements active code (including globals that are initialized from imported values). van Rossum doesn’t like this approach much because the imports appear in a strange place, but it does work. Matthias Urlichs recommends restructuring your code so that the recursive import is not necessary in the first place. These solutions are not mutually exclusive. __import__(‘x.y.z’) returns &lt;module ‘x’&gt;; how do I get z?¶ Try: __import__('x.y.z').y.z For more realistic situations, you may have to do something like m = __import__(s) for i in s.split(&quot;.&quot;)[1:]: m = getattr(m, i) See importlib for a convenience function called import_module(). When I edit an imported module and reimport it, the changes don’t show up. Why does this happen?¶ For reasons of efficiency as well as consistency, Python only reads the module file on the first time a module is imported. If it didn’t, in a program consisting of many modules where each one imports the same basic module, the basic module would be parsed and re-parsed many times. To force rereading of a changed module, do this: import modname reload(modname) Warning: this technique is not 100% fool-proof. In particular, modules containing statements like from modname import some_objects will continue to work with the old version of the imported objects. If the module contains class definitions, existing class instances will not be updated to use the new class definition. This can result in the following paradoxical behaviour: &gt;&gt;&gt; import cls &gt;&gt;&gt; c = cls.C() # Create an instance of C &gt;&gt;&gt; reload(cls) &lt;module 'cls' from 'cls.pyc'&gt; &gt;&gt;&gt; isinstance(c, cls.C) # isinstance is false?!? False The nature of the problem is made clear if you print out the class objects: &gt;&gt;&gt; c.__class__ &lt;class cls.C at 0x7352a0&gt; &gt;&gt;&gt; cls.C &lt;class cls.C at 0x4198d0&gt; Table Of Contents Programming FAQ General Questions Core Language Numbers and strings Sequences (Tuples/Lists) Dictionaries Objects Modules Previous topic General Python FAQ Next topic Design and History FAQ This Page Report a Bug Show Source Quick search Enter search terms or a module, class or function name. Navigation index modules | next | previous | Python v2.7.1 documentation » Python Frequently Asked Questions » © Copyright 1990-2011, Python Software Foundation. The Python Software Foundation is a non-profit corporation. Please donate. Last updated on Apr 27, 2011. Found a bug? Created using Sphinx 0.6.7. "
/home/bani/Dropbox/Inbox/__inboxz/ak/py/py stff/web2py___init_d_startup:	# and leave 'force-reload' as an alias for 'restart'.
/home/bani/Dropbox/Inbox/__inboxz/ak/w.json:                                "phrase": "You can also make this command more simpler by adding this line to .bashrc or .bash_aliases in your home folder(Ctrl+H to view hidden files).\n\nalias LANshare='python -c \"import SimpleHTTPServer; SimpleHTTPServer.test();\"'", 
/home/bani/Dropbox/Inbox/__inboxz/ak/autokey.json0.71.2:                                    "phrase": "You can also make this command more simpler by adding this line to .bashrc or .bash_aliases in your home folder(Ctrl+H to view hidden files).\n\nalias LANshare='python -c \"import SimpleHTTPServer; SimpleHTTPServer.test();\"'", 
/home/bani/Dropbox/Inbox/__inboxz/ak/inbox/mm/freeplane-1.1.3_10/doc/freeplane.mm:<node TEXT="To install Freeplane on Mac OS X first use the built in Software Update feature to ensure that you have all the latest available updates, especially Java. Software Update is located under the Apple logo menu in the top left-hand corner of the screen. &#xa;&#xa;Then download a Mac-specific version of Freeplane. The .dmg version is easiest to install, though a .zip version may also be available. When the download is complete, the file may be automatically mounted (or un-zipped) depending on your Web browser settings. Otherwise either double-click on the downloaded .dmg file to &quot;mount&quot; it, or double-click on the downloaded .zip file to un-zip it. &#xa;&#xa;Now you should see a Freeplane application icon, which you can drag to your Applications folder. Then you may optionally create an alias (shortcut) on the Desktop, and/or on the Dock. To run Freeplane, either double-click on its application icon (in the Applications folder) or on its Desktop shortcut, or click once on its icon in the Dock. The Freeplane Wiki has Macintosh page with more information." ID="_Freeplane_Link_1808511462" CREATED="1270892460641" MODIFIED="1271864546275"/>
/home/bani/Dropbox/Inbox/__inboxz/ak/inbox/mm/freeplane-1.1.3_10/doc/freeplane_nl.mm:<node TEXT="To install Freeplane on Mac OS X first use the built in Software Update feature to ensure that you have all the latest available updates, especially Java. Software Update is located under the Apple logo menu in the top left-hand corner of the screen. &#xa;&#xa;Then download a Mac-specific version of Freeplane. The .dmg version is easiest to install, though a .zip version may also be available. When the download is complete, the file may be automatically mounted (or un-zipped) depending on your Web browser settings. Otherwise either double-click on the downloaded .dmg file to &quot;mount&quot; it, or double-click on the downloaded .zip file to un-zip it. &#xa;&#xa;Now you should see a Freeplane application icon, which you can drag to your Applications folder. Then you may optionally create an alias (shortcut) on the Desktop, and/or on the Dock. To run Freeplane, either double-click on its application icon (in the Applications folder) or on its Desktop shortcut, or click once on its icon in the Dock. The Freeplane Wiki has Macintosh page with more information." ID="_Freeplane_Link_1808511462" CREATED="1270892460641" MODIFIED="1271864546275"/>
/home/bani/Dropbox/Inbox/__inboxz/ak/inbox/mm/freeplane-1.1.3_10/doc/freeplane_it.mm:      Per installare Freeplane con il sistema operativo <b>Mac OS X</b>, la prima cosa &#232; assicurarsi di avere tutti gli ultimi aggiornamenti disponibili, in particolare Java. L'aggiornamento Software si trova sotto il menu logo Apple in alto a sinistra dello schermo.<br/><br/>Quindi scaricare una versione per Mac specifica di Freeplane. La versione Dmg &#232; pi&#249; facile da installare, attraverso un file .zip disponibile. Quando il download &#232; completato, il file pu&#242; essere montato automaticamente (o decompresso) a seconda delle impostazioni del browser web. In caso contrario, fare doppio clic sul file. Dmg scaricato per &quot;montare&quot;, o fare doppio clic sul file. Zip scaricato per scompattarlo.<br/><br/>Ora si dovrebbe vedere una icona dell'applicazione Freeplane, che &#232; possibile trascinare nella cartella Applicazioni. Poi si pu&#242; opzionalmente creare un alias (collegamento) sul desktop, e / o nel Dock. Per eseguire Freeplane, fare doppio clic sulla sua icona dell'applicazione (nella cartella Applicazioni) o sul suo collegamento sul desktop, oppure fare clic una volta sulla sua icona nel Dock. Il wiki di Freeplane ha una pagina per Macintosh, con ulteriori informazioni.
/home/bani/Dropbox/Inbox/__inboxz/ak/inbox/mm/freeplane-1.1.3_10/doc/history_en.txt:* Antialias and selection option changes are now directly applied.
/home/bani/Dropbox/Inbox/__inboxz/ak/inbox/cache.rdf:                   NS1:content="Navigation index modules | next | previous | Python v2.7.1 documentation » Python Frequently Asked Questions » Programming FAQ¶ Contents Programming FAQ General Questions Is there a source code level debugger with breakpoints, single-stepping, etc.? Is there a tool to help find bugs or perform static analysis? How can I create a stand-alone binary from a Python script? Are there coding standards or a style guide for Python programs? My program is too slow. How do I speed it up? Core Language Why am I getting an UnboundLocalError when the variable has a value? What are the rules for local and global variables in Python? How do I share global variables across modules? What are the “best practices” for using import in a module? How can I pass optional or keyword parameters from one function to another? How do I write a function with output parameters (call by reference)? How do you make a higher order function in Python? How do I copy an object in Python? How can I find the methods or attributes of an object? How can my code discover the name of an object? What’s up with the comma operator’s precedence? Is there an equivalent of C’s “?:” ternary operator? Is it possible to write obfuscated one-liners in Python? Numbers and strings How do I specify hexadecimal and octal integers? Why does -22 // 10 return -3? How do I convert a string to a number? How do I convert a number to a string? How do I modify a string in place? How do I use strings to call functions/methods? Is there an equivalent to Perl’s chomp() for removing trailing newlines from strings? Is there a scanf() or sscanf() equivalent? What does ‘UnicodeError: ASCII [decoding,encoding] error: ordinal not in range(128)’ mean? Sequences (Tuples/Lists) How do I convert between tuples and lists? What’s a negative index? How do I iterate over a sequence in reverse order? How do you remove duplicates from a list? How do you make an array in Python? How do I create a multidimensional list? How do I apply a method to a sequence of objects? Dictionaries How can I get a dictionary to display its keys in a consistent order? I want to do a complicated sort: can you do a Schwartzian Transform in Python? How can I sort one list by values from another list? Objects What is a class? What is a method? What is self? How do I check if an object is an instance of a given class or of a subclass of it? What is delegation? How do I call a method defined in a base class from a derived class that overrides it? How can I organize my code to make it easier to change the base class? How do I create static class data and static class methods? How can I overload constructors (or methods) in Python? I try to use __spam and I get an error about _SomeClassName__spam. My class defines __del__ but it is not called when I delete the object. How do I get a list of all instances of a given class? Modules How do I create a .pyc file? How do I find the current module name? How can I have modules that mutually import each other? __import__(‘x.y.z’) returns &lt;module ‘x’&gt;; how do I get z? When I edit an imported module and reimport it, the changes don’t show up. Why does this happen? General Questions¶ Is there a source code level debugger with breakpoints, single-stepping, etc.?¶ Yes. The pdb module is a simple but adequate console-mode debugger for Python. It is part of the standard Python library, and is documented in the Library Reference Manual. You can also write your own debugger by using the code for pdb as an example. The IDLE interactive development environment, which is part of the standard Python distribution (normally available as Tools/scripts/idle), includes a graphical debugger. There is documentation for the IDLE debugger at http://www.python.org/idle/doc/idle2.html#Debugger. PythonWin is a Python IDE that includes a GUI debugger based on pdb. The Pythonwin debugger colors breakpoints and has quite a few cool features such as debugging non-Pythonwin programs. Pythonwin is available as part of the Python for Windows Extensions project and as a part of the ActivePython distribution (see http://www.activestate.com/Products/ActivePython/index.html). Boa Constructor is an IDE and GUI builder that uses wxWidgets. It offers visual frame creation and manipulation, an object inspector, many views on the source like object browsers, inheritance hierarchies, doc string generated html documentation, an advanced debugger, integrated help, and Zope support. Eric is an IDE built on PyQt and the Scintilla editing component. Pydb is a version of the standard Python debugger pdb, modified for use with DDD (Data Display Debugger), a popular graphical debugger front end. Pydb can be found at http://bashdb.sourceforge.net/pydb/ and DDD can be found at http://www.gnu.org/software/ddd. There are a number of commercial Python IDEs that include graphical debuggers. They include: Wing IDE (http://wingware.com/) Komodo IDE (http://www.activestate.com/Products/Komodo) Is there a tool to help find bugs or perform static analysis?¶ Yes. PyChecker is a static analysis tool that finds bugs in Python source code and warns about code complexity and style. You can get PyChecker from http://pychecker.sf.net. Pylint is another tool that checks if a module satisfies a coding standard, and also makes it possible to write plug-ins to add a custom feature. In addition to the bug checking that PyChecker performs, Pylint offers some additional features such as checking line length, whether variable names are well-formed according to your coding standard, whether declared interfaces are fully implemented, and more. http://www.logilab.org/card/pylint_manual provides a full list of Pylint’s features. How can I create a stand-alone binary from a Python script?¶ You don’t need the ability to compile Python to C code if all you want is a stand-alone program that users can download and run without having to install the Python distribution first. There are a number of tools that determine the set of modules required by a program and bind these modules together with a Python binary to produce a single executable. One is to use the freeze tool, which is included in the Python source tree as Tools/freeze. It converts Python byte code to C arrays; a C compiler you can embed all your modules into a new program, which is then linked with the standard Python modules. It works by scanning your source recursively for import statements (in both forms) and looking for the modules in the standard Python path as well as in the source directory (for built-in modules). It then turns the bytecode for modules written in Python into C code (array initializers that can be turned into code objects using the marshal module) and creates a custom-made config file that only contains those built-in modules which are actually used in the program. It then compiles the generated C code and links it with the rest of the Python interpreter to form a self-contained binary which acts exactly like your script. Obviously, freeze requires a C compiler. There are several other utilities which don’t. One is Thomas Heller’s py2exe (Windows only) at http://www.py2exe.org/ Another is Christian Tismer’s SQFREEZE which appends the byte code to a specially-prepared Python interpreter that can find the byte code in the executable. Other tools include Fredrik Lundh’s Squeeze and Anthony Tuininga’s cx_Freeze. Are there coding standards or a style guide for Python programs?¶ Yes. The coding style required for standard library modules is documented as PEP 8. My program is too slow. How do I speed it up?¶ That’s a tough one, in general. There are many tricks to speed up Python code; consider rewriting parts in C as a last resort. In some cases it’s possible to automatically translate Python to C or x86 assembly language, meaning that you don’t have to modify your code to gain increased speed. Pyrex can compile a slightly modified version of Python code into a C extension, and can be used on many different platforms. Psyco is a just-in-time compiler that translates Python code into x86 assembly language. If you can use it, Psyco can provide dramatic speedups for critical functions. The rest of this answer will discuss various tricks for squeezing a bit more speed out of Python code. Never apply any optimization tricks unless you know you need them, after profiling has indicated that a particular function is the heavily executed hot spot in the code. Optimizations almost always make the code less clear, and you shouldn’t pay the costs of reduced clarity (increased development time, greater likelihood of bugs) unless the resulting performance benefit is worth it. There is a page on the wiki devoted to performance tips. Guido van Rossum has written up an anecdote related to optimization at http://www.python.org/doc/essays/list2str.html. One thing to notice is that function and (especially) method calls are rather expensive; if you have designed a purely OO interface with lots of tiny functions that don’t do much more than get or set an instance variable or call another method, you might consider using a more direct way such as directly accessing instance variables. Also see the standard module profile which makes it possible to find out where your program is spending most of its time (if you have some patience – the profiling itself can slow your program down by an order of magnitude). Remember that many standard optimization heuristics you may know from other programming experience may well apply to Python. For example it may be faster to send output to output devices using larger writes rather than smaller ones in order to reduce the overhead of kernel system calls. Thus CGI scripts that write all output in “one shot” may be faster than those that write lots of small pieces of output. Also, be sure to use Python’s core features where appropriate. For example, slicing allows programs to chop up lists and other sequence objects in a single tick of the interpreter’s mainloop using highly optimized C implementations. Thus to get the same effect as: L2 = [] for i in range[3]: L2.append(L1[i]) it is much shorter and far faster to use L2 = list(L1[:3]) # &quot;list&quot; is redundant if L1 is a list. Note that the functionally-oriented built-in functions such as map(), zip(), and friends can be a convenient accelerator for loops that perform a single task. For example to pair the elements of two lists together: &gt;&gt;&gt; zip([1, 2, 3], [4, 5, 6]) [(1, 4), (2, 5), (3, 6)] or to compute a number of sines: &gt;&gt;&gt; map(math.sin, (1, 2, 3, 4)) [0.841470984808, 0.909297426826, 0.14112000806, -0.756802495308] The operation completes very quickly in such cases. Other examples include the join() and split() methods of string objects. For example if s1..s7 are large (10K+) strings then &quot;&quot;.join([s1,s2,s3,s4,s5,s6,s7]) may be far faster than the more obvious s1+s2+s3+s4+s5+s6+s7, since the “summation” will compute many subexpressions, whereas join() does all the copying in one pass. For manipulating strings, use the replace() and the format() methods on string objects. Use regular expressions only when you’re not dealing with constant string patterns. You may still use the old % operations string % tuple and string % dictionary. Be sure to use the list.sort() built-in method to do sorting, and see the sorting mini-HOWTO for examples of moderately advanced usage. list.sort() beats other techniques for sorting in all but the most extreme circumstances. Another common trick is to “push loops into functions or methods.” For example suppose you have a program that runs slowly and you use the profiler to determine that a Python function ff() is being called lots of times. If you notice that ff(): def ff(x): ... # do something with x computing result... return result tends to be called in loops like: list = map(ff, oldlist) or: for x in sequence: value = ff(x) ... # do something with value... then you can often eliminate function call overhead by rewriting ff() to: def ffseq(seq): resultseq = [] for x in seq: ... # do something with x computing result... resultseq.append(result) return resultseq and rewrite the two examples to list = ffseq(oldlist) and to: for value in ffseq(sequence): ... # do something with value... Single calls to ff(x) translate to ffseq([x])[0] with little penalty. Of course this technique is not always appropriate and there are other variants which you can figure out. You can gain some performance by explicitly storing the results of a function or method lookup into a local variable. A loop like: for key in token: dict[key] = dict.get(key, 0) + 1 resolves dict.get every iteration. If the method isn’t going to change, a slightly faster implementation is: dict_get = dict.get # look up the method once for key in token: dict[key] = dict_get(key, 0) + 1 Default arguments can be used to determine values once, at compile time instead of at run time. This can only be done for functions or objects which will not be changed during program execution, such as replacing def degree_sin(deg): return math.sin(deg * math.pi / 180.0) with def degree_sin(deg, factor=math.pi/180.0, sin=math.sin): return sin(deg * factor) Because this trick uses default arguments for terms which should not be changed, it should only be used when you are not concerned with presenting a possibly confusing API to your users. Core Language¶ Why am I getting an UnboundLocalError when the variable has a value?¶ It can be a surprise to get the UnboundLocalError in previously working code when it is modified by adding an assignment statement somewhere in the body of a function. This code: &gt;&gt;&gt; x = 10 &gt;&gt;&gt; def bar(): ... print x &gt;&gt;&gt; bar() 10 works, but this code: &gt;&gt;&gt; x = 10 &gt;&gt;&gt; def foo(): ... print x ... x += 1 results in an UnboundLocalError: &gt;&gt;&gt; foo() Traceback (most recent call last): ... UnboundLocalError: local variable 'x' referenced before assignment This is because when you make an assignment to a variable in a scope, that variable becomes local to that scope and shadows any similarly named variable in the outer scope. Since the last statement in foo assigns a new value to x, the compiler recognizes it as a local variable. Consequently when the earlier print x attempts to print the uninitialized local variable and an error results. In the example above you can access the outer scope variable by declaring it global: &gt;&gt;&gt; x = 10 &gt;&gt;&gt; def foobar(): ... global x ... print x ... x += 1 &gt;&gt;&gt; foobar() 10 This explicit declaration is required in order to remind you that (unlike the superficially analogous situation with class and instance variables) you are actually modifying the value of the variable in the outer scope: &gt;&gt;&gt; print x 11 What are the rules for local and global variables in Python?¶ In Python, variables that are only referenced inside a function are implicitly global. If a variable is assigned a new value anywhere within the function’s body, it’s assumed to be a local. If a variable is ever assigned a new value inside the function, the variable is implicitly local, and you need to explicitly declare it as ‘global’. Though a bit surprising at first, a moment’s consideration explains this. On one hand, requiring global for assigned variables provides a bar against unintended side-effects. On the other hand, if global was required for all global references, you’d be using global all the time. You’d have to declare as global every reference to a built-in function or to a component of an imported module. This clutter would defeat the usefulness of the global declaration for identifying side-effects. How do I share global variables across modules?¶ The canonical way to share information across modules within a single program is to create a special module (often called config or cfg). Just import the config module in all modules of your application; the module then becomes available as a global name. Because there is only one instance of each module, any changes made to the module object get reflected everywhere. For example: config.py: x = 0 # Default value of the 'x' configuration setting mod.py: import config config.x = 1 main.py: import config import mod print config.x Note that using a module is also the basis for implementing the Singleton design pattern, for the same reason. What are the “best practices” for using import in a module?¶ In general, don’t use from modulename import *. Doing so clutters the importer’s namespace. Some people avoid this idiom even with the few modules that were designed to be imported in this manner. Modules designed in this manner include Tkinter, and threading. Import modules at the top of a file. Doing so makes it clear what other modules your code requires and avoids questions of whether the module name is in scope. Using one import per line makes it easy to add and delete module imports, but using multiple imports per line uses less screen space. It’s good practice if you import modules in the following order: standard library modules – e.g. sys, os, getopt, re third-party library modules (anything installed in Python’s site-packages directory) – e.g. mx.DateTime, ZODB, PIL.Image, etc. locally-developed modules Never use relative package imports. If you’re writing code that’s in the package.sub.m1 module and want to import package.sub.m2, do not just write import m2, even though it’s legal. Write from package.sub import m2 instead. Relative imports can lead to a module being initialized twice, leading to confusing bugs. See PEP 328 for details. It is sometimes necessary to move imports to a function or class to avoid problems with circular imports. Gordon McMillan says: Circular imports are fine where both modules use the “import &lt;module&gt;” form of import. They fail when the 2nd module wants to grab a name out of the first (“from module import name”) and the import is at the top level. That’s because names in the 1st are not yet available, because the first module is busy importing the 2nd. In this case, if the second module is only used in one function, then the import can easily be moved into that function. By the time the import is called, the first module will have finished initializing, and the second module can do its import. It may also be necessary to move imports out of the top level of code if some of the modules are platform-specific. In that case, it may not even be possible to import all of the modules at the top of the file. In this case, importing the correct modules in the corresponding platform-specific code is a good option. Only move imports into a local scope, such as inside a function definition, if it’s necessary to solve a problem such as avoiding a circular import or are trying to reduce the initialization time of a module. This technique is especially helpful if many of the imports are unnecessary depending on how the program executes. You may also want to move imports into a function if the modules are only ever used in that function. Note that loading a module the first time may be expensive because of the one time initialization of the module, but loading a module multiple times is virtually free, costing only a couple of dictionary lookups. Even if the module name has gone out of scope, the module is probably available in sys.modules. If only instances of a specific class use a module, then it is reasonable to import the module in the class’s __init__ method and then assign the module to an instance variable so that the module is always available (via that instance variable) during the life of the object. Note that to delay an import until the class is instantiated, the import must be inside a method. Putting the import inside the class but outside of any method still causes the import to occur when the module is initialized. How can I pass optional or keyword parameters from one function to another?¶ Collect the arguments using the * and ** specifiers in the function’s parameter list; this gives you the positional arguments as a tuple and the keyword arguments as a dictionary. You can then pass these arguments when calling another function by using * and **: def f(x, *args, **kwargs): ... kwargs['width'] = '14.3c' ... g(x, *args, **kwargs) In the unlikely case that you care about Python versions older than 2.0, use apply(): def f(x, *args, **kwargs): ... kwargs['width'] = '14.3c' ... apply(g, (x,)+args, kwargs) How do I write a function with output parameters (call by reference)?¶ Remember that arguments are passed by assignment in Python. Since assignment just creates references to objects, there’s no alias between an argument name in the caller and callee, and so no call-by-reference per se. You can achieve the desired effect in a number of ways. By returning a tuple of the results: def func2(a, b): a = 'new-value' # a and b are local names b = b + 1 # assigned to new objects return a, b # return new values x, y = 'old-value', 99 x, y = func2(x, y) print x, y # output: new-value 100 This is almost always the clearest solution. By using global variables. This isn’t thread-safe, and is not recommended. By passing a mutable (changeable in-place) object: def func1(a): a[0] = 'new-value' # 'a' references a mutable list a[1] = a[1] + 1 # changes a shared object args = ['old-value', 99] func1(args) print args[0], args[1] # output: new-value 100 By passing in a dictionary that gets mutated: def func3(args): args['a'] = 'new-value' # args is a mutable dictionary args['b'] = args['b'] + 1 # change it in-place args = {'a':' old-value', 'b': 99} func3(args) print args['a'], args['b'] Or bundle up values in a class instance: class callByRef: def __init__(self, **args): for (key, value) in args.items(): setattr(self, key, value) def func4(args): args.a = 'new-value' # args is a mutable callByRef args.b = args.b + 1 # change object in-place args = callByRef(a='old-value', b=99) func4(args) print args.a, args.b There’s almost never a good reason to get this complicated. Your best choice is to return a tuple containing the multiple results. How do you make a higher order function in Python?¶ You have two choices: you can use nested scopes or you can use callable objects. For example, suppose you wanted to define linear(a,b) which returns a function f(x) that computes the value a*x+b. Using nested scopes: def linear(a, b): def result(x): return a * x + b return result Or using a callable object: class linear: def __init__(self, a, b): self.a, self.b = a, b def __call__(self, x): return self.a * x + self.b In both cases, taxes = linear(0.3, 2) gives a callable object where taxes(10e6) == 0.3 * 10e6 + 2. The callable object approach has the disadvantage that it is a bit slower and results in slightly longer code. However, note that a collection of callables can share their signature via inheritance: class exponential(linear): # __init__ inherited def __call__(self, x): return self.a * (x ** self.b) Object can encapsulate state for several methods: class counter: value = 0 def set(self, x): self.value = x def up(self): self.value = self.value + 1 def down(self): self.value = self.value - 1 count = counter() inc, dec, reset = count.up, count.down, count.set Here inc(), dec() and reset() act like functions which share the same counting variable. How do I copy an object in Python?¶ In general, try copy.copy() or copy.deepcopy() for the general case. Not all objects can be copied, but most can. Some objects can be copied more easily. Dictionaries have a copy() method: newdict = olddict.copy() Sequences can be copied by slicing: new_l = l[:] How can I find the methods or attributes of an object?¶ For an instance x of a user-defined class, dir(x) returns an alphabetized list of the names containing the instance attributes and methods and attributes defined by its class. How can my code discover the name of an object?¶ Generally speaking, it can’t, because objects don’t really have names. Essentially, assignment always binds a name to a value; The same is true of def and class statements, but in that case the value is a callable. Consider the following code: class A: pass B = A a = B() b = a print b &lt;__main__.A instance at 0x16D07CC&gt; print a &lt;__main__.A instance at 0x16D07CC&gt; Arguably the class has a name: even though it is bound to two names and invoked through the name B the created instance is still reported as an instance of class A. However, it is impossible to say whether the instance’s name is a or b, since both names are bound to the same value. Generally speaking it should not be necessary for your code to “know the names” of particular values. Unless you are deliberately writing introspective programs, this is usually an indication that a change of approach might be beneficial. In comp.lang.python, Fredrik Lundh once gave an excellent analogy in answer to this question: The same way as you get the name of that cat you found on your porch: the cat (object) itself cannot tell you its name, and it doesn’t really care – so the only way to find out what it’s called is to ask all your neighbours (namespaces) if it’s their cat (object)... ....and don’t be surprised if you’ll find that it’s known by many names, or no name at all! What’s up with the comma operator’s precedence?¶ Comma is not an operator in Python. Consider this session: &gt;&gt;&gt; &quot;a&quot; in &quot;b&quot;, &quot;a&quot; (False, 'a') Since the comma is not an operator, but a separator between expressions the above is evaluated as if you had entered: &gt;&gt;&gt; (&quot;a&quot; in &quot;b&quot;), &quot;a&quot; not: &gt;&gt;&gt; &quot;a&quot; in (&quot;b&quot;, &quot;a&quot;) The same is true of the various assignment operators (=, += etc). They are not truly operators but syntactic delimiters in assignment statements. Is there an equivalent of C’s “?:” ternary operator?¶ Yes, this feature was added in Python 2.5. The syntax would be as follows: [on_true] if [expression] else [on_false] x, y = 50, 25 small = x if x &lt; y else y For versions previous to 2.5 the answer would be ‘No’. In many cases you can mimic a ? b : c with a and b or c, but there’s a flaw: if b is zero (or empty, or None – anything that tests false) then c will be selected instead. In many cases you can prove by looking at the code that this can’t happen (e.g. because b is a constant or has a type that can never be false), but in general this can be a problem. Tim Peters (who wishes it was Steve Majewski) suggested the following solution: (a and [b] or [c])[0]. Because [b] is a singleton list it is never false, so the wrong path is never taken; then applying [0] to the whole thing gets the b or c that you really wanted. Ugly, but it gets you there in the rare cases where it is really inconvenient to rewrite your code using ‘if’. The best course is usually to write a simple if...else statement. Another solution is to implement the ?: operator as a function: def q(cond, on_true, on_false): if cond: if not isfunction(on_true): return on_true else: return on_true() else: if not isfunction(on_false): return on_false else: return on_false() In most cases you’ll pass b and c directly: q(a, b, c). To avoid evaluating b or c when they shouldn’t be, encapsulate them within a lambda function, e.g.: q(a, lambda: b, lambda: c). It has been asked why Python has no if-then-else expression. There are several answers: many languages do just fine without one; it can easily lead to less readable code; no sufficiently “Pythonic” syntax has been discovered; a search of the standard library found remarkably few places where using an if-then-else expression would make the code more understandable. In 2002, PEP 308 was written proposing several possible syntaxes and the community was asked to vote on the issue. The vote was inconclusive. Most people liked one of the syntaxes, but also hated other syntaxes; many votes implied that people preferred no ternary operator rather than having a syntax they hated. Is it possible to write obfuscated one-liners in Python?¶ Yes. Usually this is done by nesting lambda within lambda. See the following three examples, due to Ulf Bartelt: # Primes &lt; 1000 print filter(None,map(lambda y:y*reduce(lambda x,y:x*y!=0, map(lambda x,y=y:y%x,range(2,int(pow(y,0.5)+1))),1),range(2,1000))) # First 10 Fibonacci numbers print map(lambda x,f=lambda x,f:(f(x-1,f)+f(x-2,f)) if x&gt;1 else 1: f(x,f), range(10)) # Mandelbrot set print (lambda Ru,Ro,Iu,Io,IM,Sx,Sy:reduce(lambda x,y:x+y,map(lambda y, Iu=Iu,Io=Io,Ru=Ru,Ro=Ro,Sy=Sy,L=lambda yc,Iu=Iu,Io=Io,Ru=Ru,Ro=Ro,i=IM, Sx=Sx,Sy=Sy:reduce(lambda x,y:x+y,map(lambda x,xc=Ru,yc=yc,Ru=Ru,Ro=Ro, i=i,Sx=Sx,F=lambda xc,yc,x,y,k,f=lambda xc,yc,x,y,k,f:(k&lt;=0)or (x*x+y*y &gt;=4.0) or 1+f(xc,yc,x*x-y*y+xc,2.0*x*y+yc,k-1,f):f(xc,yc,x,y,k,f):chr( 64+F(Ru+x*(Ro-Ru)/Sx,yc,0,0,i)),range(Sx))):L(Iu+y*(Io-Iu)/Sy),range(Sy ))))(-2.1, 0.7, -1.2, 1.2, 30, 80, 24) # \___ ___/ \___ ___/ | | |__ lines on screen # V V | |______ columns on screen # | | |__________ maximum of &quot;iterations&quot; # | |_________________ range on y axis # |____________________________ range on x axis Don’t try this at home, kids! Numbers and strings¶ How do I specify hexadecimal and octal integers?¶ To specify an octal digit, precede the octal value with a zero, and then a lower or uppercase “o”. For example, to set the variable “a” to the octal value “10” (8 in decimal), type: &gt;&gt;&gt; a = 0o10 &gt;&gt;&gt; a 8 Hexadecimal is just as easy. Simply precede the hexadecimal number with a zero, and then a lower or uppercase “x”. Hexadecimal digits can be specified in lower or uppercase. For example, in the Python interpreter: &gt;&gt;&gt; a = 0xa5 &gt;&gt;&gt; a 165 &gt;&gt;&gt; b = 0XB2 &gt;&gt;&gt; b 178 Why does -22 // 10 return -3?¶ It’s primarily driven by the desire that i % j have the same sign as j. If you want that, and also want: i == (i // j) * j + (i % j) then integer division has to return the floor. C also requires that identity to hold, and then compilers that truncate i // j need to make i % j have the same sign as i. There are few real use cases for i % j when j is negative. When j is positive, there are many, and in virtually all of them it’s more useful for i % j to be &gt;= 0. If the clock says 10 now, what did it say 200 hours ago? -190 % 12 == 2 is useful; -190 % 12 == -10 is a bug waiting to bite. Note On Python 2, a / b returns the same as a // b if __future__.division is not in effect. This is also known as “classic” division. How do I convert a string to a number?¶ For integers, use the built-in int() type constructor, e.g. int('144') == 144. Similarly, float() converts to floating-point, e.g. float('144') == 144.0. By default, these interpret the number as decimal, so that int('0144') == 144 and int('0x144') raises ValueError. int(string, base) takes the base to convert from as a second optional argument, so int('0x144', 16) == 324. If the base is specified as 0, the number is interpreted using Python’s rules: a leading ‘0’ indicates octal, and ‘0x’ indicates a hex number. Do not use the built-in function eval() if all you need is to convert strings to numbers. eval() will be significantly slower and it presents a security risk: someone could pass you a Python expression that might have unwanted side effects. For example, someone could pass __import__('os').system(&quot;rm -rf $HOME&quot;) which would erase your home directory. eval() also has the effect of interpreting numbers as Python expressions, so that e.g. eval('09') gives a syntax error because Python regards numbers starting with ‘0’ as octal (base 8). How do I convert a number to a string?¶ To convert, e.g., the number 144 to the string ‘144’, use the built-in type constructor str(). If you want a hexadecimal or octal representation, use the built-in functions hex() or oct(). For fancy formatting, see the Format String Syntax section, e.g. &quot;{:04d}&quot;.format(144) yields '0144' and &quot;{:.3f}&quot;.format(1/3) yields '0.333'. You may also use the % operator on strings. See the library reference manual for details. How do I modify a string in place?¶ You can’t, because strings are immutable. If you need an object with this ability, try converting the string to a list or use the array module: &gt;&gt;&gt; s = &quot;Hello, world&quot; &gt;&gt;&gt; a = list(s) &gt;&gt;&gt; print a ['H', 'e', 'l', 'l', 'o', ',', ' ', 'w', 'o', 'r', 'l', 'd'] &gt;&gt;&gt; a[7:] = list(&quot;there!&quot;) &gt;&gt;&gt; ''.join(a) 'Hello, there!' &gt;&gt;&gt; import array &gt;&gt;&gt; a = array.array('c', s) &gt;&gt;&gt; print a array('c', 'Hello, world') &gt;&gt;&gt; a[0] = 'y' ; print a array('c', 'yello world') &gt;&gt;&gt; a.tostring() 'yello, world' How do I use strings to call functions/methods?¶ There are various techniques. The best is to use a dictionary that maps strings to functions. The primary advantage of this technique is that the strings do not need to match the names of the functions. This is also the primary technique used to emulate a case construct: def a(): pass def b(): pass dispatch = {'go': a, 'stop': b} # Note lack of parens for funcs dispatch[get_input()]() # Note trailing parens to call function Use the built-in function getattr(): import foo getattr(foo, 'bar')() Note that getattr() works on any object, including classes, class instances, modules, and so on. This is used in several places in the standard library, like this: class Foo: def do_foo(self): ... def do_bar(self): ... f = getattr(foo_instance, 'do_' + opname) f() Use locals() or eval() to resolve the function name: def myFunc(): print &quot;hello&quot; fname = &quot;myFunc&quot; f = locals()[fname] f() f = eval(fname) f() Note: Using eval() is slow and dangerous. If you don’t have absolute control over the contents of the string, someone could pass a string that resulted in an arbitrary function being executed. Is there an equivalent to Perl’s chomp() for removing trailing newlines from strings?¶ Starting with Python 2.2, you can use S.rstrip(&quot;\r\n&quot;) to remove all occurrences of any line terminator from the end of the string S without removing other trailing whitespace. If the string S represents more than one line, with several empty lines at the end, the line terminators for all the blank lines will be removed: &gt;&gt;&gt; lines = (&quot;line 1 \r\n&quot; ... &quot;\r\n&quot; ... &quot;\r\n&quot;) &gt;&gt;&gt; lines.rstrip(&quot;\n\r&quot;) 'line 1 ' Since this is typically only desired when reading text one line at a time, using S.rstrip() this way works well. For older versions of Python, there are two partial substitutes: If you want to remove all trailing whitespace, use the rstrip() method of string objects. This removes all trailing whitespace, not just a single newline. Otherwise, if there is only one line in the string S, use S.splitlines()[0]. Is there a scanf() or sscanf() equivalent?¶ Not as such. For simple input parsing, the easiest approach is usually to split the line into whitespace-delimited words using the split() method of string objects and then convert decimal strings to numeric values using int() or float(). split() supports an optional “sep” parameter which is useful if the line uses something other than whitespace as a separator. For more complicated input parsing, regular expressions are more powerful than C’s sscanf() and better suited for the task. What does ‘UnicodeError: ASCII [decoding,encoding] error: ordinal not in range(128)’ mean?¶ This error indicates that your Python installation can handle only 7-bit ASCII strings. There are a couple ways to fix or work around the problem. If your programs must handle data in arbitrary character set encodings, the environment the application runs in will generally identify the encoding of the data it is handing you. You need to convert the input to Unicode data using that encoding. For example, a program that handles email or web input will typically find character set encoding information in Content-Type headers. This can then be used to properly convert input data to Unicode. Assuming the string referred to by value is encoded as UTF-8: value = unicode(value, &quot;utf-8&quot;) will return a Unicode object. If the data is not correctly encoded as UTF-8, the above call will raise a UnicodeError exception. If you only want strings converted to Unicode which have non-ASCII data, you can try converting them first assuming an ASCII encoding, and then generate Unicode objects if that fails: try: x = unicode(value, &quot;ascii&quot;) except UnicodeError: value = unicode(value, &quot;utf-8&quot;) else: # value was valid ASCII data pass It’s possible to set a default encoding in a file called sitecustomize.py that’s part of the Python library. However, this isn’t recommended because changing the Python-wide default encoding may cause third-party extension modules to fail. Note that on Windows, there is an encoding known as “mbcs”, which uses an encoding specific to your current locale. In many cases, and particularly when working with COM, this may be an appropriate default encoding to use. Sequences (Tuples/Lists)¶ How do I convert between tuples and lists?¶ The type constructor tuple(seq) converts any sequence (actually, any iterable) into a tuple with the same items in the same order. For example, tuple([1, 2, 3]) yields (1, 2, 3) and tuple('abc') yields ('a', 'b', 'c'). If the argument is a tuple, it does not make a copy but returns the same object, so it is cheap to call tuple() when you aren’t sure that an object is already a tuple. The type constructor list(seq) converts any sequence or iterable into a list with the same items in the same order. For example, list((1, 2, 3)) yields [1, 2, 3] and list('abc') yields ['a', 'b', 'c']. If the argument is a list, it makes a copy just like seq[:] would. What’s a negative index?¶ Python sequences are indexed with positive numbers and negative numbers. For positive numbers 0 is the first index 1 is the second index and so forth. For negative indices -1 is the last index and -2 is the penultimate (next to last) index and so forth. Think of seq[-n] as the same as seq[len(seq)-n]. Using negative indices can be very convenient. For example S[:-1] is all of the string except for its last character, which is useful for removing the trailing newline from a string. How do I iterate over a sequence in reverse order?¶ Use the reversed() built-in function, which is new in Python 2.4: for x in reversed(sequence): ... # do something with x... This won’t touch your original sequence, but build a new copy with reversed order to iterate over. With Python 2.3, you can use an extended slice syntax: for x in sequence[::-1]: ... # do something with x... How do you remove duplicates from a list?¶ See the Python Cookbook for a long discussion of many ways to do this: http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/52560 If you don’t mind reordering the list, sort it and then scan from the end of the list, deleting duplicates as you go: if mylist: mylist.sort() last = mylist[-1] for i in range(len(mylist)-2, -1, -1): if last == mylist[i]: del mylist[i] else: last = mylist[i] If all elements of the list may be used as dictionary keys (i.e. they are all hashable) this is often faster d = {} for x in mylist: d[x] = 1 mylist = list(d.keys()) In Python 2.5 and later, the following is possible instead: mylist = list(set(mylist)) This converts the list into a set, thereby removing duplicates, and then back into a list. How do you make an array in Python?¶ Use a list: [&quot;this&quot;, 1, &quot;is&quot;, &quot;an&quot;, &quot;array&quot;] Lists are equivalent to C or Pascal arrays in their time complexity; the primary difference is that a Python list can contain objects of many different types. The array module also provides methods for creating arrays of fixed types with compact representations, but they are slower to index than lists. Also note that the Numeric extensions and others define array-like structures with various characteristics as well. To get Lisp-style linked lists, you can emulate cons cells using tuples: lisp_list = (&quot;like&quot;, (&quot;this&quot;, (&quot;example&quot;, None) ) ) If mutability is desired, you could use lists instead of tuples. Here the analogue of lisp car is lisp_list[0] and the analogue of cdr is lisp_list[1]. Only do this if you’re sure you really need to, because it’s usually a lot slower than using Python lists. How do I create a multidimensional list?¶ You probably tried to make a multidimensional array like this: A = [[None] * 2] * 3 This looks correct if you print it: &gt;&gt;&gt; A [[None, None], [None, None], [None, None]] But when you assign a value, it shows up in multiple places: &gt;&gt;&gt; A[0][0] = 5 &gt;&gt;&gt; A [[5, None], [5, None], [5, None]] The reason is that replicating a list with * doesn’t create copies, it only creates references to the existing objects. The *3 creates a list containing 3 references to the same list of length two. Changes to one row will show in all rows, which is almost certainly not what you want. The suggested approach is to create a list of the desired length first and then fill in each element with a newly created list: A = [None] * 3 for i in range(3): A[i] = [None] * 2 This generates a list containing 3 different lists of length two. You can also use a list comprehension: w, h = 2, 3 A = [[None] * w for i in range(h)] Or, you can use an extension that provides a matrix datatype; Numeric Python is the best known. How do I apply a method to a sequence of objects?¶ Use a list comprehension: result = [obj.method() for obj in mylist] More generically, you can try the following function: def method_map(objects, method, arguments): &quot;&quot;&quot;method_map([a,b], &quot;meth&quot;, (1,2)) gives [a.meth(1,2), b.meth(1,2)]&quot;&quot;&quot; nobjects = len(objects) methods = map(getattr, objects, [method]*nobjects) return map(apply, methods, [arguments]*nobjects) Dictionaries¶ How can I get a dictionary to display its keys in a consistent order?¶ You can’t. Dictionaries store their keys in an unpredictable order, so the display order of a dictionary’s elements will be similarly unpredictable. This can be frustrating if you want to save a printable version to a file, make some changes and then compare it with some other printed dictionary. In this case, use the pprint module to pretty-print the dictionary; the items will be presented in order sorted by the key. A more complicated solution is to subclass dict to create a SortedDict class that prints itself in a predictable order. Here’s one simpleminded implementation of such a class: class SortedDict(dict): def __repr__(self): keys = sorted(self.keys()) result = (&quot;{!r}: {!r}&quot;.format(k, self[k]) for k in keys) return &quot;{{{}}}&quot;.format(&quot;, &quot;.join(result)) __str__ = __repr__ This will work for many common situations you might encounter, though it’s far from a perfect solution. The largest flaw is that if some values in the dictionary are also dictionaries, their values won’t be presented in any particular order. I want to do a complicated sort: can you do a Schwartzian Transform in Python?¶ The technique, attributed to Randal Schwartz of the Perl community, sorts the elements of a list by a metric which maps each element to its “sort value”. In Python, just use the key argument for the sort() method: Isorted = L[:] Isorted.sort(key=lambda s: int(s[10:15])) The key argument is new in Python 2.4, for older versions this kind of sorting is quite simple to do with list comprehensions. To sort a list of strings by their uppercase values: tmp1 = [(x.upper(), x) for x in L] # Schwartzian transform tmp1.sort() Usorted = [x[1] for x in tmp1] To sort by the integer value of a subfield extending from positions 10-15 in each string: tmp2 = [(int(s[10:15]), s) for s in L] # Schwartzian transform tmp2.sort() Isorted = [x[1] for x in tmp2] Note that Isorted may also be computed by def intfield(s): return int(s[10:15]) def Icmp(s1, s2): return cmp(intfield(s1), intfield(s2)) Isorted = L[:] Isorted.sort(Icmp) but since this method calls intfield() many times for each element of L, it is slower than the Schwartzian Transform. How can I sort one list by values from another list?¶ Merge them into a single list of tuples, sort the resulting list, and then pick out the element you want. &gt;&gt;&gt; list1 = [&quot;what&quot;, &quot;I'm&quot;, &quot;sorting&quot;, &quot;by&quot;] &gt;&gt;&gt; list2 = [&quot;something&quot;, &quot;else&quot;, &quot;to&quot;, &quot;sort&quot;] &gt;&gt;&gt; pairs = zip(list1, list2) &gt;&gt;&gt; pairs [('what', 'something'), (&quot;I'm&quot;, 'else'), ('sorting', 'to'), ('by', 'sort')] &gt;&gt;&gt; pairs.sort() &gt;&gt;&gt; result = [ x[1] for x in pairs ] &gt;&gt;&gt; result ['else', 'sort', 'to', 'something'] An alternative for the last step is: &gt;&gt;&gt; result = [] &gt;&gt;&gt; for p in pairs: result.append(p[1]) If you find this more legible, you might prefer to use this instead of the final list comprehension. However, it is almost twice as slow for long lists. Why? First, the append() operation has to reallocate memory, and while it uses some tricks to avoid doing that each time, it still has to do it occasionally, and that costs quite a bit. Second, the expression “result.append” requires an extra attribute lookup, and third, there’s a speed reduction from having to make all those function calls. Objects¶ What is a class?¶ A class is the particular object type created by executing a class statement. Class objects are used as templates to create instance objects, which embody both the data (attributes) and code (methods) specific to a datatype. A class can be based on one or more other classes, called its base class(es). It then inherits the attributes and methods of its base classes. This allows an object model to be successively refined by inheritance. You might have a generic Mailbox class that provides basic accessor methods for a mailbox, and subclasses such as MboxMailbox, MaildirMailbox, OutlookMailbox that handle various specific mailbox formats. What is a method?¶ A method is a function on some object x that you normally call as x.name(arguments...). Methods are defined as functions inside the class definition: class C: def meth (self, arg): return arg * 2 + self.attribute What is self?¶ Self is merely a conventional name for the first argument of a method. A method defined as meth(self, a, b, c) should be called as x.meth(a, b, c) for some instance x of the class in which the definition occurs; the called method will think it is called as meth(x, a, b, c). See also Why must ‘self’ be used explicitly in method definitions and calls?. How do I check if an object is an instance of a given class or of a subclass of it?¶ Use the built-in function isinstance(obj, cls). You can check if an object is an instance of any of a number of classes by providing a tuple instead of a single class, e.g. isinstance(obj, (class1, class2, ...)), and can also check whether an object is one of Python’s built-in types, e.g. isinstance(obj, str) or isinstance(obj, (int, long, float, complex)). Note that most programs do not use isinstance() on user-defined classes very often. If you are developing the classes yourself, a more proper object-oriented style is to define methods on the classes that encapsulate a particular behaviour, instead of checking the object’s class and doing a different thing based on what class it is. For example, if you have a function that does something: def search(obj): if isinstance(obj, Mailbox): # ... code to search a mailbox elif isinstance(obj, Document): # ... code to search a document elif ... A better approach is to define a search() method on all the classes and just call it: class Mailbox: def search(self): # ... code to search a mailbox class Document: def search(self): # ... code to search a document obj.search() What is delegation?¶ Delegation is an object oriented technique (also called a design pattern). Let’s say you have an object x and want to change the behaviour of just one of its methods. You can create a new class that provides a new implementation of the method you’re interested in changing and delegates all other methods to the corresponding method of x. Python programmers can easily implement delegation. For example, the following class implements a class that behaves like a file but converts all written data to uppercase: class UpperOut: def __init__(self, outfile): self._outfile = outfile def write(self, s): self._outfile.write(s.upper()) def __getattr__(self, name): return getattr(self._outfile, name) Here the UpperOut class redefines the write() method to convert the argument string to uppercase before calling the underlying self.__outfile.write() method. All other methods are delegated to the underlying self.__outfile object. The delegation is accomplished via the __getattr__ method; consult the language reference for more information about controlling attribute access. Note that for more general cases delegation can get trickier. When attributes must be set as well as retrieved, the class must define a __setattr__() method too, and it must do so carefully. The basic implementation of __setattr__() is roughly equivalent to the following: class X: ... def __setattr__(self, name, value): self.__dict__[name] = value ... Most __setattr__() implementations must modify self.__dict__ to store local state for self without causing an infinite recursion. How do I call a method defined in a base class from a derived class that overrides it?¶ If you’re using new-style classes, use the built-in super() function: class Derived(Base): def meth (self): super(Derived, self).meth() If you’re using classic classes: For a class definition such as class Derived(Base): ... you can call method meth() defined in Base (or one of Base‘s base classes) as Base.meth(self, arguments...). Here, Base.meth is an unbound method, so you need to provide the self argument. How can I organize my code to make it easier to change the base class?¶ You could define an alias for the base class, assign the real base class to it before your class definition, and use the alias throughout your class. Then all you have to change is the value assigned to the alias. Incidentally, this trick is also handy if you want to decide dynamically (e.g. depending on availability of resources) which base class to use. Example: BaseAlias = &lt;real base class&gt; class Derived(BaseAlias): def meth(self): BaseAlias.meth(self) ... How do I create static class data and static class methods?¶ Both static data and static methods (in the sense of C++ or Java) are supported in Python. For static data, simply define a class attribute. To assign a new value to the attribute, you have to explicitly use the class name in the assignment: class C: count = 0 # number of times C.__init__ called def __init__(self): C.count = C.count + 1 def getcount(self): return C.count # or return self.count c.count also refers to C.count for any c such that isinstance(c, C) holds, unless overridden by c itself or by some class on the base-class search path from c.__class__ back to C. Caution: within a method of C, an assignment like self.count = 42 creates a new and unrelated instance named “count” in self‘s own dict. Rebinding of a class-static data name must always specify the class whether inside a method or not: C.count = 314 Static methods are possible since Python 2.2: class C: def static(arg1, arg2, arg3): # No 'self' parameter! ... static = staticmethod(static) With Python 2.4’s decorators, this can also be written as class C: @staticmethod def static(arg1, arg2, arg3): # No 'self' parameter! ... However, a far more straightforward way to get the effect of a static method is via a simple module-level function: def getcount(): return C.count If your code is structured so as to define one class (or tightly related class hierarchy) per module, this supplies the desired encapsulation. How can I overload constructors (or methods) in Python?¶ This answer actually applies to all methods, but the question usually comes up first in the context of constructors. In C++ you’d write class C { C() { cout &lt;&lt; &quot;No arguments\n&quot;; } C(int i) { cout &lt;&lt; &quot;Argument is &quot; &lt;&lt; i &lt;&lt; &quot;\n&quot;; } } In Python you have to write a single constructor that catches all cases using default arguments. For example: class C: def __init__(self, i=None): if i is None: print &quot;No arguments&quot; else: print &quot;Argument is&quot;, i This is not entirely equivalent, but close enough in practice. You could also try a variable-length argument list, e.g. def __init__(self, *args): ... The same approach works for all method definitions. I try to use __spam and I get an error about _SomeClassName__spam.¶ Variable names with double leading underscores are “mangled” to provide a simple but effective way to define class private variables. Any identifier of the form __spam (at least two leading underscores, at most one trailing underscore) is textually replaced with _classname__spam, where classname is the current class name with any leading underscores stripped. This doesn’t guarantee privacy: an outside user can still deliberately access the “_classname__spam” attribute, and private values are visible in the object’s __dict__. Many Python programmers never bother to use private variable names at all. My class defines __del__ but it is not called when I delete the object.¶ There are several possible reasons for this. The del statement does not necessarily call __del__() – it simply decrements the object’s reference count, and if this reaches zero __del__() is called. If your data structures contain circular links (e.g. a tree where each child has a parent reference and each parent has a list of children) the reference counts will never go back to zero. Once in a while Python runs an algorithm to detect such cycles, but the garbage collector might run some time after the last reference to your data structure vanishes, so your __del__() method may be called at an inconvenient and random time. This is inconvenient if you’re trying to reproduce a problem. Worse, the order in which object’s __del__() methods are executed is arbitrary. You can run gc.collect() to force a collection, but there are pathological cases where objects will never be collected. Despite the cycle collector, it’s still a good idea to define an explicit close() method on objects to be called whenever you’re done with them. The close() method can then remove attributes that refer to subobjecs. Don’t call __del__() directly – __del__() should call close() and close() should make sure that it can be called more than once for the same object. Another way to avoid cyclical references is to use the weakref module, which allows you to point to objects without incrementing their reference count. Tree data structures, for instance, should use weak references for their parent and sibling references (if they need them!). If the object has ever been a local variable in a function that caught an expression in an except clause, chances are that a reference to the object still exists in that function’s stack frame as contained in the stack trace. Normally, calling sys.exc_clear() will take care of this by clearing the last recorded exception. Finally, if your __del__() method raises an exception, a warning message is printed to sys.stderr. How do I get a list of all instances of a given class?¶ Python does not keep track of all instances of a class (or of a built-in type). You can program the class’s constructor to keep track of all instances by keeping a list of weak references to each instance. Modules¶ How do I create a .pyc file?¶ When a module is imported for the first time (or when the source is more recent than the current compiled file) a .pyc file containing the compiled code should be created in the same directory as the .py file. One reason that a .pyc file may not be created is permissions problems with the directory. This can happen, for example, if you develop as one user but run as another, such as if you are testing with a web server. Creation of a .pyc file is automatic if you’re importing a module and Python has the ability (permissions, free space, etc...) to write the compiled module back to the directory. Running Python on a top level script is not considered an import and no .pyc will be created. For example, if you have a top-level module abc.py that imports another module xyz.py, when you run abc, xyz.pyc will be created since xyz is imported, but no abc.pyc file will be created since abc.py isn’t being imported. If you need to create abc.pyc – that is, to create a .pyc file for a module that is not imported – you can, using the py_compile and compileall modules. The py_compile module can manually compile any module. One way is to use the compile() function in that module interactively: &gt;&gt;&gt; import py_compile &gt;&gt;&gt; py_compile.compile('abc.py') This will write the .pyc to the same location as abc.py (or you can override that with the optional parameter cfile). You can also automatically compile all files in a directory or directories using the compileall module. You can do it from the shell prompt by running compileall.py and providing the path of a directory containing Python files to compile: python -m compileall . How do I find the current module name?¶ A module can find out its own module name by looking at the predefined global variable __name__. If this has the value '__main__', the program is running as a script. Many modules that are usually used by importing them also provide a command-line interface or a self-test, and only execute this code after checking __name__: def main(): print 'Running test...' ... if __name__ == '__main__': main() How can I have modules that mutually import each other?¶ Suppose you have the following modules: foo.py: from bar import bar_var foo_var = 1 bar.py: from foo import foo_var bar_var = 2 The problem is that the interpreter will perform the following steps: main imports foo Empty globals for foo are created foo is compiled and starts executing foo imports bar Empty globals for bar are created bar is compiled and starts executing bar imports foo (which is a no-op since there already is a module named foo) bar.foo_var = foo.foo_var The last step fails, because Python isn’t done with interpreting foo yet and the global symbol dictionary for foo is still empty. The same thing happens when you use import foo, and then try to access foo.foo_var in global code. There are (at least) three possible workarounds for this problem. Guido van Rossum recommends avoiding all uses of from &lt;module&gt; import ..., and placing all code inside functions. Initializations of global variables and class variables should use constants or built-in functions only. This means everything from an imported module is referenced as &lt;module&gt;.&lt;name&gt;. Jim Roskind suggests performing steps in the following order in each module: exports (globals, functions, and classes that don’t need imported base classes) import statements active code (including globals that are initialized from imported values). van Rossum doesn’t like this approach much because the imports appear in a strange place, but it does work. Matthias Urlichs recommends restructuring your code so that the recursive import is not necessary in the first place. These solutions are not mutually exclusive. __import__(‘x.y.z’) returns &lt;module ‘x’&gt;; how do I get z?¶ Try: __import__('x.y.z').y.z For more realistic situations, you may have to do something like m = __import__(s) for i in s.split(&quot;.&quot;)[1:]: m = getattr(m, i) See importlib for a convenience function called import_module(). When I edit an imported module and reimport it, the changes don’t show up. Why does this happen?¶ For reasons of efficiency as well as consistency, Python only reads the module file on the first time a module is imported. If it didn’t, in a program consisting of many modules where each one imports the same basic module, the basic module would be parsed and re-parsed many times. To force rereading of a changed module, do this: import modname reload(modname) Warning: this technique is not 100% fool-proof. In particular, modules containing statements like from modname import some_objects will continue to work with the old version of the imported objects. If the module contains class definitions, existing class instances will not be updated to use the new class definition. This can result in the following paradoxical behaviour: &gt;&gt;&gt; import cls &gt;&gt;&gt; c = cls.C() # Create an instance of C &gt;&gt;&gt; reload(cls) &lt;module 'cls' from 'cls.pyc'&gt; &gt;&gt;&gt; isinstance(c, cls.C) # isinstance is false?!? False The nature of the problem is made clear if you print out the class objects: &gt;&gt;&gt; c.__class__ &lt;class cls.C at 0x7352a0&gt; &gt;&gt;&gt; cls.C &lt;class cls.C at 0x4198d0&gt; Table Of Contents Programming FAQ General Questions Core Language Numbers and strings Sequences (Tuples/Lists) Dictionaries Objects Modules Previous topic General Python FAQ Next topic Design and History FAQ This Page Report a Bug Show Source Quick search Enter search terms or a module, class or function name. Navigation index modules | next | previous | Python v2.7.1 documentation » Python Frequently Asked Questions » © Copyright 1990-2011, Python Software Foundation. The Python Software Foundation is a non-profit corporation. Please donate. Last updated on Apr 27, 2011. Found a bug? Created using Sphinx 0.6.7. " />
/home/bani/Dropbox/Inbox/__inboxz/ak/inbox/cache.rdf:                   NS1:content="Navigation index modules | next | previous | Scrapy v0.10.4 documentation » Debugging memory leaks¶ In Scrapy, objects such as Requests, Responses and Items have a finite lifetime: they are created, used for a while, and finally destroyed. From all those objects, the Request is probably the one with the longest lifetime, as it stays waiting in the Scheduler queue until it’s time to process it. For more info see Architecture overview. As these Scrapy objects have a (rather long) lifetime, there is always the risk of accumulating them in memory without releasing them properly and thus causing what is known as a “memory leak”. To help debugging memory leaks, Scrapy provides a built-in mechanism for tracking objects references called trackref, and you can also use a third-party library called Guppy for more advanced memory debugging (see below for more info). Both mechanisms must be used from the Telnet Console. Common causes of memory leaks¶ It happens quite often (sometimes by accident, sometimes on purpose) that the Scrapy developer passes objects referenced in Requests (for example, using the meta attribute or the request callback function) and that effectively bounds the lifetime of those referenced objects to the lifetime of the Request. This is, by far, the most common cause of memory leaks in Scrapy projects, and a quite difficult one to debug for newcomers. In big projects, the spiders are typically written by different people and some of those spiders could be “leaking” and thus affecting the rest of the other (well-written) spiders when they get to run concurrently, which, in turn, affects the whole crawling process. At the same time, it’s hard to avoid the reasons that cause these leaks without restricting the power of the framework, so we have decided not to restrict the functionally but provide useful tools for debugging these leaks, which quite often consist in an answer to the question: which spider is leaking?. The leak could also come from a custom middleware, pipeline or extension that you have written, if you are not releasing the (previously allocated) resources properly. For example, if you’re allocating resources on spider_opened but not releasing them on spider_closed. Debugging memory leaks with trackref¶ trackref is a module provided by Scrapy to debug the most common cases of memory leaks. It basically tracks the references to all live Requests, Responses, Item and Selector objects. To activate the trackref module, enable the TRACK_REFS setting. It only imposes a minor performance impact, so it should be OK to use it, even in production environments. Once you have trackref enabled, you can enter the telnet console and inspect how many objects (of the classes mentioned above) are currently alive using the prefs() function which is an alias to the print_live_refs() function: telnet localhost 6023 &gt;&gt;&gt; prefs() Live References ExampleSpider 1 oldest: 15s ago HtmlResponse 10 oldest: 1s ago XPathSelector 2 oldest: 0s ago FormRequest 878 oldest: 7s ago As you can see, that report also shows the “age” of the oldest object in each class. If you do have leaks, chances are you can figure out which spider is leaking by looking at the oldest request or response. You can get the oldest object of each class using the get_oldest() function like this (from the telnet console). Which objects are tracked?¶ The objects tracked by trackrefs are all from these classes (and all its subclasses): scrapy.http.Request scrapy.http.Response scrapy.item.Item scrapy.selector.XPathSelector scrapy.spider.BaseSpider scrapy.selector.document.Libxml2Document A real example¶ Let’s see a concrete example of an hypothetical case of memory leaks. Suppose we have some spider with a line similar to this one: return Request(&quot;http://www.somenastyspider.com/product.php?pid=%d&quot; % product_id, callback=self.parse, meta={referer: response}&quot;) That line is passing a response reference inside a request which effectively ties the response lifetime to the requests’ one, and that would definitely cause memory leaks. Let’s see how we can discover which one is the nasty spider (without knowing it a-priori, of course) by using the trackref tool. After the crawler is running for a few minutes and we notice its memory usage has grown a lot, we can enter its telnet console and check the live references: &gt;&gt;&gt; prefs() Live References SomenastySpider 1 oldest: 15s ago HtmlResponse 3890 oldest: 265s ago XPathSelector 2 oldest: 0s ago Request 3878 oldest: 250s ago The fact that there are so many live responses (and that they’re so old) is definitely suspicious, as responses should have a relatively short lifetime compared to Requests. So let’s check the oldest response: &gt;&gt;&gt; from scrapy.utils.trackref import get_oldest &gt;&gt;&gt; r = get_oldest('HtmlResponse') &gt;&gt;&gt; r.url 'http://www.somenastyspider.com/product.php?pid=123' There it is. By looking at the URL of the oldest response we can see it belongs to the somenastyspider.com spider. We can now go and check the code of that spider to discover the nasty line that is generating the leaks (passing response references inside requests). If you want to iterate over all objects, instead of getting the oldest one, you can use the iter_all() function: &gt;&gt;&gt; from scrapy.utils.trackref import iter_all &gt;&gt;&gt; [r.url for r in iter_all('HtmlResponse')] ['http://www.somenastyspider.com/product.php?pid=123', 'http://www.somenastyspider.com/product.php?pid=584', ... Too many spiders?¶ If your project has too many spiders, the output of prefs() can be difficult to read. For this reason, that function has a ignore argument which can be used to ignore a particular class (and all its subclases). For example, using: &gt;&gt;&gt; from scrapy.spider import BaseSpider &gt;&gt;&gt; prefs(ignore=BaseSpider) Won’t show any live references to spiders. scrapy.utils.trackref module¶ Here are the functions available in the trackref module. class scrapy.utils.trackref.object_ref¶ Inherit from this class (instead of object) if you want to track live instances with the trackref module. scrapy.utils.trackref.print_live_refs(class_name, ignore=NoneType)¶ Print a report of live references, grouped by class name. Parameter: ignore (class or classes tuple) – if given, all objects from the specified class (or tuple of classes) will be ignored. scrapy.utils.trackref.get_oldest(class_name)¶ Return the oldest object alive with the given class name, or None if none is found. Use print_live_refs() first to get a list of all tracked live objects per class name. scrapy.utils.trackref.iter_all(class_name)¶ Return an iterator over all objects alive with the given class name, or None if none is found. Use print_live_refs() first to get a list of all tracked live objects per class name. Debugging memory leaks with Guppy¶ trackref provides a very convenient mechanism for tracking down memory leaks, but it only keeps track of the objects that are more likely to cause memory leaks (Requests, Responses, Items, and Selectors). However, there are other cases where the memory leaks could come from other (more or less obscure) objects. If this is your case, and you can’t find your leaks using trackref, you still have another resource: the Guppy library. If you use setuptools, you can install Guppy with the following command: easy_install guppy The telnet console also comes with a built-in shortcut (hpy) for accessing Guppy heap objects. Here’s an example to view all Python objects available in the heap using Guppy: &gt;&gt;&gt; x = hpy.heap() &gt;&gt;&gt; x.bytype Partition of a set of 297033 objects. Total size = 52587824 bytes. Index Count % Size % Cumulative % Type 0 22307 8 16423880 31 16423880 31 dict 1 122285 41 12441544 24 28865424 55 str 2 68346 23 5966696 11 34832120 66 tuple 3 227 0 5836528 11 40668648 77 unicode 4 2461 1 2222272 4 42890920 82 type 5 16870 6 2024400 4 44915320 85 function 6 13949 5 1673880 3 46589200 89 types.CodeType 7 13422 5 1653104 3 48242304 92 list 8 3735 1 1173680 2 49415984 94 _sre.SRE_Pattern 9 1209 0 456936 1 49872920 95 scrapy.http.headers.Headers &lt;1676 more rows. Type e.g. '_.more' to view.&gt; You can see that most space is used by dicts. Then, if you want to see from which attribute those dicts are referenced, you could do: &gt;&gt;&gt; x.bytype[0].byvia Partition of a set of 22307 objects. Total size = 16423880 bytes. Index Count % Size % Cumulative % Referred Via: 0 10982 49 9416336 57 9416336 57 '.__dict__' 1 1820 8 2681504 16 12097840 74 '.__dict__', '.func_globals' 2 3097 14 1122904 7 13220744 80 3 990 4 277200 2 13497944 82 &quot;['cookies']&quot; 4 987 4 276360 2 13774304 84 &quot;['cache']&quot; 5 985 4 275800 2 14050104 86 &quot;['meta']&quot; 6 897 4 251160 2 14301264 87 '[2]' 7 1 0 196888 1 14498152 88 &quot;['moduleDict']&quot;, &quot;['modules']&quot; 8 672 3 188160 1 14686312 89 &quot;['cb_kwargs']&quot; 9 27 0 155016 1 14841328 90 '[1]' &lt;333 more rows. Type e.g. '_.more' to view.&gt; As you can see, the Guppy module is very powerful but also requires some deep knowledge about Python internals. For more info about Guppy, refer to the Guppy documentation. Leaks without leaks¶ Sometimes, you may notice that the memory usage of your Scrapy process will only increase, but never decrease. Unfortunately, this could happen even though neither Scrapy nor your project are leaking memory. This is due to a (not so well) known problem of Python, which may not return released memory to the operating system in some cases. For more information on this issue see: Python Memory Management Python Memory Management Part 2 Python Memory Management Part 3 The improvements proposed by Evan Jones, which are detailed in this paper, got merged in Python 2.5, but this only reduces the problem, it doesn’t fix it completely. To quote the paper: Unfortunately, this patch can only free an arena if there are no more objects allocated in it anymore. This means that fragmentation is a large issue. An application could have many megabytes of free memory, scattered throughout all the arenas, but it will be unable to free any of it. This is a problem experienced by all memory allocators. The only way to solve it is to move to a compacting garbage collector, which is able to move objects in memory. This would require significant changes to the Python interpreter. This problem will be fixed in future Scrapy releases, where we plan to adopt a new process model and run spiders in a pool of recyclable sub-processes. Table Of Contents Debugging memory leaks Common causes of memory leaks Debugging memory leaks with trackref Which objects are tracked? A real example Too many spiders? scrapy.utils.trackref module Debugging memory leaks with Guppy Leaks without leaks Previous topic Using Firebug for scraping Next topic Downloading Item Images This Page Show Source Quick search Enter search terms or a module, class or function name. Navigation index modules | next | previous | Scrapy v0.10.4 documentation » © Copyright 2008-2010, Insophia. Last updated on Dec 15, 2010. Created using Sphinx 0.6.1. " />
/home/bani/Dropbox/Inbox/__inboxz/ak/inbox/cache.rdf:                   NS1:content="Navigation index modules | next | previous | Python v3.1.3 documentation » What’s New in Python » What’s New In Python 3.0¶ Author: Guido van Rossum Release: 3.1.3 Date: November 27, 2010 This article explains the new features in Python 3.0, compared to 2.6. Python 3.0, also known as “Python 3000” or “Py3K”, is the first ever intentionally backwards incompatible Python release. There are more changes than in a typical release, and more that are important for all Python users. Nevertheless, after digesting the changes, you’ll find that Python really hasn’t changed all that much – by and large, we’re mostly fixing well-known annoyances and warts, and removing a lot of old cruft. This article doesn’t attempt to provide a complete specification of all new features, but instead tries to give a convenient overview. For full details, you should refer to the documentation for Python 3.0, and/or the many PEPs referenced in the text. If you want to understand the complete implementation and design rationale for a particular feature, PEPs usually have more details than the regular documentation; but note that PEPs usually are not kept up-to-date once a feature has been fully implemented. Due to time constraints this document is not as complete as it should have been. As always for a new release, the Misc/NEWS file in the source distribution contains a wealth of detailed information about every small thing that was changed. Common Stumbling Blocks¶ This section lists those few changes that are most likely to trip you up if you’re used to Python 2.5. Print Is A Function¶ The print statement has been replaced with a print() function, with keyword arguments to replace most of the special syntax of the old print statement (PEP 3105). Examples: Old: print &quot;The answer is&quot;, 2*2 New: print(&quot;The answer is&quot;, 2*2) Old: print x, # Trailing comma suppresses newline New: print(x, end=&quot; &quot;) # Appends a space instead of a newline Old: print # Prints a newline New: print() # You must call the function! Old: print &gt;&gt;sys.stderr, &quot;fatal error&quot; New: print(&quot;fatal error&quot;, file=sys.stderr) Old: print (x, y) # prints repr((x, y)) New: print((x, y)) # Not the same as print(x, y)! You can also customize the separator between items, e.g.: print(&quot;There are &lt;&quot;, 2**32, &quot;&gt; possibilities!&quot;, sep=&quot;&quot;) which produces: There are &lt;4294967296&gt; possibilities! Note: The print() function doesn’t support the “softspace” feature of the old print statement. For example, in Python 2.x, print &quot;A\n&quot;, &quot;B&quot; would write &quot;A\nB\n&quot;; but in Python 3.0, print(&quot;A\n&quot;, &quot;B&quot;) writes &quot;A\n B\n&quot;. Initially, you’ll be finding yourself typing the old print x a lot in interactive mode. Time to retrain your fingers to type print(x) instead! When using the 2to3 source-to-source conversion tool, all print statements are automatically converted to print() function calls, so this is mostly a non-issue for larger projects. Views And Iterators Instead Of Lists¶ Some well-known APIs no longer return lists: dict methods dict.keys(), dict.items() and dict.values() return “views” instead of lists. For example, this no longer works: k = d.keys(); k.sort(). Use k = sorted(d) instead (this works in Python 2.5 too and is just as efficient). Also, the dict.iterkeys(), dict.iteritems() and dict.itervalues() methods are no longer supported. map() and filter() return iterators. If you really need a list, a quick fix is e.g. list(map(...)), but a better fix is often to use a list comprehension (especially when the original code uses lambda), or rewriting the code so it doesn’t need a list at all. Particularly tricky is map() invoked for the side effects of the function; the correct transformation is to use a regular for loop (since creating a list would just be wasteful). range() now behaves like xrange() used to behave, except it works with values of arbitrary size. The latter no longer exists. zip() now returns an iterator. Ordering Comparisons¶ Python 3.0 has simplified the rules for ordering comparisons: The ordering comparison operators (&lt;, &lt;=, &gt;=, &gt;) raise a TypeError exception when the operands don’t have a meaningful natural ordering. Thus, expressions like 1 &lt; '', 0 &gt; None or len &lt;= len are no longer valid, and e.g. None &lt; None raises TypeError instead of returning False. A corollary is that sorting a heterogeneous list no longer makes sense – all the elements must be comparable to each other. Note that this does not apply to the == and != operators: objects of different incomparable types always compare unequal to each other. builtin.sorted() and list.sort() no longer accept the cmp argument providing a comparison function. Use the key argument instead. N.B. the key and reverse arguments are now “keyword-only”. The cmp() function should be treated as gone, and the __cmp__() special method is no longer supported. Use __lt__() for sorting, __eq__() with __hash__(), and other rich comparisons as needed. (If you really need the cmp() functionality, you could use the expression (a &gt; b) - (a &lt; b) as the equivalent for cmp(a, b).) Integers¶ PEP 0237: Essentially, long renamed to int. That is, there is only one built-in integral type, named int; but it behaves mostly like the old long type. PEP 0238: An expression like 1/2 returns a float. Use 1//2 to get the truncating behavior. (The latter syntax has existed for years, at least since Python 2.2.) The sys.maxint constant was removed, since there is no longer a limit to the value of integers. However, sys.maxsize can be used as an integer larger than any practical list or string index. It conforms to the implementation’s “natural” integer size and is typically the same as sys.maxint in previous releases on the same platform (assuming the same build options). The repr() of a long integer doesn’t include the trailing L anymore, so code that unconditionally strips that character will chop off the last digit instead. (Use str() instead.) Octal literals are no longer of the form 0720; use 0o720 instead. Text Vs. Data Instead Of Unicode Vs. 8-bit¶ Everything you thought you knew about binary data and Unicode has changed. Python 3.0 uses the concepts of text and (binary) data instead of Unicode strings and 8-bit strings. All text is Unicode; however encoded Unicode is represented as binary data. The type used to hold text is str, the type used to hold data is bytes. The biggest difference with the 2.x situation is that any attempt to mix text and data in Python 3.0 raises TypeError, whereas if you were to mix Unicode and 8-bit strings in Python 2.x, it would work if the 8-bit string happened to contain only 7-bit (ASCII) bytes, but you would get UnicodeDecodeError if it contained non-ASCII values. This value-specific behavior has caused numerous sad faces over the years. As a consequence of this change in philosophy, pretty much all code that uses Unicode, encodings or binary data most likely has to change. The change is for the better, as in the 2.x world there were numerous bugs having to do with mixing encoded and unencoded text. To be prepared in Python 2.x, start using unicode for all unencoded text, and str for binary or encoded data only. Then the 2to3 tool will do most of the work for you. You can no longer use u&quot;...&quot; literals for Unicode text. However, you must use b&quot;...&quot; literals for binary data. As the str and bytes types cannot be mixed, you must always explicitly convert between them. Use str.encode() to go from str to bytes, and bytes.decode() to go from bytes to str. You can also use bytes(s, encoding=...) and str(b, encoding=...), respectively. Like str, the bytes type is immutable. There is a separate mutable type to hold buffered binary data, bytearray. Nearly all APIs that accept bytes also accept bytearray. The mutable API is based on collections.MutableSequence. All backslashes in raw string literals are interpreted literally. This means that '\U' and '\u' escapes in raw strings are not treated specially. For example, r'\u20ac' is a string of 6 characters in Python 3.0, whereas in 2.6, ur'\u20ac' was the single “euro” character. (Of course, this change only affects raw string literals; the euro character is '\u20ac' in Python 3.0.) The builtin basestring abstract type was removed. Use str instead. The str and bytes types don’t have functionality enough in common to warrant a shared base class. The 2to3 tool (see below) replaces every occurrence of basestring with str. Files opened as text files (still the default mode for open()) always use an encoding to map between strings (in memory) and bytes (on disk). Binary files (opened with a b in the mode argument) always use bytes in memory. This means that if a file is opened using an incorrect mode or encoding, I/O will likely fail loudly, instead of silently producing incorrect data. It also means that even Unix users will have to specify the correct mode (text or binary) when opening a file. There is a platform-dependent default encoding, which on Unixy platforms can be set with the LANG environment variable (and sometimes also with some other platform-specific locale-related environment variables). In many cases, but not all, the system default is UTF-8; you should never count on this default. Any application reading or writing more than pure ASCII text should probably have a way to override the encoding. There is no longer any need for using the encoding-aware streams in the codecs module. Filenames are passed to and returned from APIs as (Unicode) strings. This can present platform-specific problems because on some platforms filenames are arbitrary byte strings. (On the other hand, on Windows filenames are natively stored as Unicode.) As a work-around, most APIs (e.g. open() and many functions in the os module) that take filenames accept bytes objects as well as strings, and a few APIs have a way to ask for a bytes return value. Thus, os.listdir() returns a list of bytes instances if the argument is a bytes instance, and os.getcwdb() returns the current working directory as a bytes instance. Note that when os.listdir() returns a list of strings, filenames that cannot be decoded properly are omitted rather than raising UnicodeError. Some system APIs like os.environ and sys.argv can also present problems when the bytes made available by the system is not interpretable using the default encoding. Setting the LANG variable and rerunning the program is probably the best approach. PEP 3138: The repr() of a string no longer escapes non-ASCII characters. It still escapes control characters and code points with non-printable status in the Unicode standard, however. PEP 3120: The default source encoding is now UTF-8. PEP 3131: Non-ASCII letters are now allowed in identifiers. (However, the standard library remains ASCII-only with the exception of contributor names in comments.) The StringIO and cStringIO modules are gone. Instead, import the io module and use io.StringIO or io.BytesIO for text and data respectively. See also the Unicode HOWTO, which was updated for Python 3.0. Overview Of Syntax Changes¶ This section gives a brief overview of every syntactic change in Python 3.0. New Syntax¶ PEP 3107: Function argument and return value annotations. This provides a standardized way of annotating a function’s parameters and return value. There are no semantics attached to such annotations except that they can be introspected at runtime using the __annotations__ attribute. The intent is to encourage experimentation through metaclasses, decorators or frameworks. PEP 3102: Keyword-only arguments. Named parameters occurring after *args in the parameter list must be specified using keyword syntax in the call. You can also use a bare * in the parameter list to indicate that you don’t accept a variable-length argument list, but you do have keyword-only arguments. Keyword arguments are allowed after the list of base classes in a class definition. This is used by the new convention for specifying a metaclass (see next section), but can be used for other purposes as well, as long as the metaclass supports it. PEP 3104: nonlocal statement. Using nonlocal x you can now assign directly to a variable in an outer (but non-global) scope. nonlocal is a new reserved word. PEP 3132: Extended Iterable Unpacking. You can now write things like a, b, *rest = some_sequence. And even *rest, a = stuff. The rest object is always a (possibly empty) list; the right-hand side may be any iterable. Example: (a, *rest, b) = range(5) This sets a to 0, b to 4, and rest to [1, 2, 3]. Dictionary comprehensions: {k: v for k, v in stuff} means the same thing as dict(stuff) but is more flexible. (This is PEP 0274 vindicated. :-) Set literals, e.g. {1, 2}. Note that {} is an empty dictionary; use set() for an empty set. Set comprehensions are also supported; e.g., {x for x in stuff} means the same thing as set(stuff) but is more flexible. New octal literals, e.g. 0o720 (already in 2.6). The old octal literals (0720) are gone. New binary literals, e.g. 0b1010 (already in 2.6), and there is a new corresponding builtin function, bin(). Bytes literals are introduced with a leading b or B, and there is a new corresponding builtin function, bytes(). Changed Syntax¶ PEP 3109 and PEP 3134: new raise statement syntax: raise [expr [from expr]]. See below. as and with are now reserved words. (Since 2.6, actually.) True, False, and None are reserved words. (2.6 partially enforced the restrictions on None already.) Change from except exc, var to except exc as var. See PEP 3110. PEP 3115: New Metaclass Syntax. Instead of: class C: __metaclass__ = M ... you must now use: class C(metaclass=M): ... The module-global __metaclass__ variable is no longer supported. (It was a crutch to make it easier to default to new-style classes without deriving every class from object.) List comprehensions no longer support the syntactic form [... for var in item1, item2, ...]. Use [... for var in (item1, item2, ...)] instead. Also note that list comprehensions have different semantics: they are closer to syntactic sugar for a generator expression inside a list() constructor, and in particular the loop control variables are no longer leaked into the surrounding scope. The ellipsis (...) can be used as an atomic expression anywhere. (Previously it was only allowed in slices.) Also, it must now be spelled as .... (Previously it could also be spelled as . . ., by a mere accident of the grammar.) Removed Syntax¶ PEP 3113: Tuple parameter unpacking removed. You can no longer write def foo(a, (b, c)): .... Use def foo(a, b_c): b, c = b_c instead. Removed backticks (use repr() instead). Removed &lt;&gt; (use != instead). Removed keyword: exec() is no longer a keyword; it remains as a function. (Fortunately the function syntax was also accepted in 2.x.) Also note that exec() no longer takes a stream argument; instead of exec(f) you can use exec(f.read()). Integer literals no longer support a trailing l or L. String literals no longer support a leading u or U. The from module import * syntax is only allowed at the module level, no longer inside functions. The only acceptable syntax for relative imports is from .[module] import name. All import forms not starting with . are interpreted as absolute imports. (PEP 0328) Classic classes are gone. Changes Already Present In Python 2.6¶ Since many users presumably make the jump straight from Python 2.5 to Python 3.0, this section reminds the reader of new features that were originally designed for Python 3.0 but that were back-ported to Python 2.6. The corresponding sections in What’s New in Python 2.6 should be consulted for longer descriptions. PEP 343: The ‘with’ statement. The with statement is now a standard feature and no longer needs to be imported from the __future__. Also check out Writing Context Managers and The contextlib module. PEP 366: Explicit Relative Imports From a Main Module. This enhances the usefulness of the -m option when the referenced module lives in a package. PEP 370: Per-user site-packages Directory. PEP 371: The multiprocessing Package. PEP 3101: Advanced String Formatting. Note: the 2.6 description mentions the format() method for both 8-bit and Unicode strings. In 3.0, only the str type (text strings with Unicode support) supports this method; the bytes type does not. The plan is to eventually make this the only API for string formatting, and to start deprecating the % operator in Python 3.1. PEP 3105: print As a Function. This is now a standard feature and no longer needs to be imported from __future__. More details were given above. PEP 3110: Exception-Handling Changes. The except exc as var syntax is now standard and except exc, var is no longer supported. (Of course, the as var part is still optional.) PEP 3112: Byte Literals. The b&quot;...&quot; string literal notation (and its variants like b'...', b&quot;&quot;&quot;...&quot;&quot;&quot;, and br&quot;...&quot;) now produces a literal of type bytes. PEP 3116: New I/O Library. The io module is now the standard way of doing file I/O, and the initial values of sys.stdin, sys.stdout and sys.stderr are now instances of io.TextIOBase. The builtin open() function is now an alias for io.open() and has additional keyword arguments encoding, errors, newline and closefd. Also note that an invalid mode argument now raises ValueError, not IOError. The binary file object underlying a text file object can be accessed as f.buffer (but beware that the text object maintains a buffer of itself in order to speed up the encoding and decoding operations). PEP 3118: Revised Buffer Protocol. The old builtin buffer() is now really gone; the new builtin memoryview() provides (mostly) similar functionality. PEP 3119: Abstract Base Classes. The abc module and the ABCs defined in the collections module plays a somewhat more prominent role in the language now, and builtin collection types like dict and list conform to the collections.MutableMapping and collections.MutableSequence ABCs, respectively. PEP 3127: Integer Literal Support and Syntax. As mentioned above, the new octal literal notation is the only one supported, and binary literals have been added. PEP 3129: Class Decorators. PEP 3141: A Type Hierarchy for Numbers. The numbers module is another new use of ABCs, defining Python’s “numeric tower”. Also note the new fractions module which implements numbers.Rational. Library Changes¶ Due to time constraints, this document does not exhaustively cover the very extensive changes to the standard library. PEP 3108 is the reference for the major changes to the library. Here’s a capsule review: Many old modules were removed. Some, like gopherlib (no longer used) and md5 (replaced by hashlib), were already deprecated by PEP 0004. Others were removed as a result of the removal of support for various platforms such as Irix, BeOS and Mac OS 9 (see PEP 0011). Some modules were also selected for removal in Python 3.0 due to lack of use or because a better replacement exists. See PEP 3108 for an exhaustive list. The bsddb3 package was removed because its presence in the core standard library has proved over time to be a particular burden for the core developers due to testing instability and Berkeley DB’s release schedule. However, the package is alive and well, externally maintained at http://www.jcea.es/programacion/pybsddb.htm. Some modules were renamed because their old name disobeyed PEP 0008, or for various other reasons. Here’s the list: Old Name New Name _winreg winreg ConfigParser configparser copy_reg copyreg Queue queue SocketServer socketserver markupbase _markupbase repr reprlib test.test_support test.support A common pattern in Python 2.x is to have one version of a module implemented in pure Python, with an optional accelerated version implemented as a C extension; for example, pickle and cPickle. This places the burden of importing the accelerated version and falling back on the pure Python version on each user of these modules. In Python 3.0, the accelerated versions are considered implementation details of the pure Python versions. Users should always import the standard version, which attempts to import the accelerated version and falls back to the pure Python version. The pickle / cPickle pair received this treatment. The profile module is on the list for 3.1. The StringIO module has been turned into a class in the io module. Some related modules have been grouped into packages, and usually the submodule names have been simplified. The resulting new packages are: dbm (anydbm, dbhash, dbm, dumbdbm, gdbm, whichdb). html (HTMLParser, htmlentitydefs). http (httplib, BaseHTTPServer, CGIHTTPServer, SimpleHTTPServer, Cookie, cookielib). tkinter (all Tkinter-related modules except turtle). The target audience of turtle doesn’t really care about tkinter. Also note that as of Python 2.6, the functionality of turtle has been greatly enhanced. urllib (urllib, urllib2, urlparse, robotparse). xmlrpc (xmlrpclib, DocXMLRPCServer, SimpleXMLRPCServer). Some other changes to standard library modules, not covered by PEP 3108: Killed sets. Use the builtin set() function. Cleanup of the sys module: removed sys.exitfunc(), sys.exc_clear(), sys.exc_type, sys.exc_value, sys.exc_traceback. (Note that sys.last_type etc. remain.) Cleanup of the array.array type: the read() and write() methods are gone; use fromfile() and tofile() instead. Also, the 'c' typecode for array is gone – use either 'b' for bytes or 'u' for Unicode characters. Cleanup of the operator module: removed sequenceIncludes() and isCallable(). Cleanup of the thread module: acquire_lock() and release_lock() are gone; use acquire() and release() instead. Cleanup of the random module: removed the jumpahead() API. The new module is gone. The functions os.tmpnam(), os.tempnam() and os.tmpfile() have been removed in favor of the tempfile module. The tokenize module has been changed to work with bytes. The main entry point is now tokenize.tokenize(), instead of generate_tokens. string.letters and its friends (string.lowercase and string.uppercase) are gone. Use string.ascii_letters etc. instead. (The reason for the removal is that string.letters and friends had locale-specific behavior, which is a bad idea for such attractively-named global “constants”.) Renamed module __builtin__ to builtins (removing the underscores, adding an ‘s’). The __builtins__ variable found in most global namespaces is unchanged. To modify a builtin, you should use builtins, not __builtins__! PEP 3101: A New Approach To String Formatting¶ A new system for built-in string formatting operations replaces the % string formatting operator. (However, the % operator is still supported; it will be deprecated in Python 3.1 and removed from the language at some later time.) Read PEP 3101 for the full scoop. Changes To Exceptions¶ The APIs for raising and catching exception have been cleaned up and new powerful features added: PEP 0352: All exceptions must be derived (directly or indirectly) from BaseException. This is the root of the exception hierarchy. This is not new as a recommendation, but the requirement to inherit from BaseException is new. (Python 2.6 still allowed classic classes to be raised, and placed no restriction on what you can catch.) As a consequence, string exceptions are finally truly and utterly dead. Almost all exceptions should actually derive from Exception; BaseException should only be used as a base class for exceptions that should only be handled at the top level, such as SystemExit or KeyboardInterrupt. The recommended idiom for handling all exceptions except for this latter category is to use except Exception. StandardError was removed. Exceptions no longer behave as sequences. Use the args attribute instead. PEP 3109: Raising exceptions. You must now use raise Exception(args) instead of raise Exception, args. Additionally, you can no longer explicitly specify a traceback; instead, if you have to do this, you can assign directly to the __traceback__ attribute (see below). PEP 3110: Catching exceptions. You must now use except SomeException as variable instead of except SomeException, variable. Moreover, the variable is explicitly deleted when the except block is left. PEP 3134: Exception chaining. There are two cases: implicit chaining and explicit chaining. Implicit chaining happens when an exception is raised in an except or finally handler block. This usually happens due to a bug in the handler block; we call this a secondary exception. In this case, the original exception (that was being handled) is saved as the __context__ attribute of the secondary exception. Explicit chaining is invoked with this syntax: raise SecondaryException() from primary_exception (where primary_exception is any expression that produces an exception object, probably an exception that was previously caught). In this case, the primary exception is stored on the __cause__ attribute of the secondary exception. The traceback printed when an unhandled exception occurs walks the chain of __cause__ and __context__ attributes and prints a separate traceback for each component of the chain, with the primary exception at the top. (Java users may recognize this behavior.) PEP 3134: Exception objects now store their traceback as the __traceback__ attribute. This means that an exception object now contains all the information pertaining to an exception, and there are fewer reasons to use sys.exc_info() (though the latter is not removed). A few exception messages are improved when Windows fails to load an extension module. For example, error code 193 is now %1 is not a valid Win32 application. Strings now deal with non-English locales. Miscellaneous Other Changes¶ Operators And Special Methods¶ != now returns the opposite of ==, unless == returns NotImplemented. The concept of “unbound methods” has been removed from the language. When referencing a method as a class attribute, you now get a plain function object. __getslice__(), __setslice__() and __delslice__() were killed. The syntax a[i:j] now translates to a.__getitem__(slice(i, j)) (or __setitem__() or __delitem__(), when used as an assignment or deletion target, respectively). PEP 3114: the standard next() method has been renamed to __next__(). The __oct__() and __hex__() special methods are removed – oct() and hex() use __index__() now to convert the argument to an integer. Removed support for __members__ and __methods__. The function attributes named func_X have been renamed to use the __X__ form, freeing up these names in the function attribute namespace for user-defined attributes. To wit, func_closure, func_code, func_defaults, func_dict, func_doc, func_globals, func_name were renamed to __closure__, __code__, __defaults__, __dict__, __doc__, __globals__, __name__, respectively. __nonzero__() is now __bool__(). Builtins¶ PEP 3135: New super(). You can now invoke super() without arguments and (assuming this is in a regular instance method defined inside a class statement) the right class and instance will automatically be chosen. With arguments, the behavior of super() is unchanged. PEP 3111: raw_input() was renamed to input(). That is, the new input() function reads a line from sys.stdin and returns it with the trailing newline stripped. It raises EOFError if the input is terminated prematurely. To get the old behavior of input(), use eval(input()). A new builtin next() was added to call the __next__() method on an object. The round() function rounding strategy and return type have changed. Exact halfway cases are now rounded to the nearest even result instead of away from zero. (For example, round(2.5) now returns 2 rather than 3.) round(x[, n])() now delegates to x.__round__([n]) instead of always returning a float. It generally returns an integer when called with a single argument and a value of the same type as x when called with two arguments. Moved intern() to sys.intern(). Removed: apply(). Instead of apply(f, args) use f(*args). Removed callable(). Instead of callable(f) you can use isinstance(f, collections.Callable). The operator.isCallable() function is also gone. Removed coerce(). This function no longer serves a purpose now that classic classes are gone. Removed execfile(). Instead of execfile(fn) use exec(open(fn).read()). Removed the file type. Use open(). There are now several different kinds of streams that open can return in the io module. Removed reduce(). Use functools.reduce() if you really need it; however, 99 percent of the time an explicit for loop is more readable. Removed reload(). Use imp.reload(). Removed. dict.has_key() – use the in operator instead. Build and C API Changes¶ Due to time constraints, here is a very incomplete list of changes to the C API. Support for several platforms was dropped, including but not limited to Mac OS 9, BeOS, RISCOS, Irix, and Tru64. PEP 3118: New Buffer API. PEP 3121: Extension Module Initialization &amp; Finalization. PEP 3123: Making PyObject_HEAD conform to standard C. No more C API support for restricted execution. PyNumber_Coerce(), PyNumber_CoerceEx(), PyMember_Get(), and PyMember_Set() C APIs are removed. New C API PyImport_ImportModuleNoBlock(), works like PyImport_ImportModule() but won’t block on the import lock (returning an error instead). Renamed the boolean conversion C-level slot and method: nb_nonzero is now nb_bool. Removed METH_OLDARGS and WITH_CYCLE_GC from the C API. Performance¶ The net result of the 3.0 generalizations is that Python 3.0 runs the pystone benchmark around 10% slower than Python 2.5. Most likely the biggest cause is the removal of special-casing for small integers. There’s room for improvement, but it will happen after 3.0 is released! Porting To Python 3.0¶ For porting existing Python 2.5 or 2.6 source code to Python 3.0, the best strategy is the following: (Prerequisite:) Start with excellent test coverage. Port to Python 2.6. This should be no more work than the average port from Python 2.x to Python 2.(x+1). Make sure all your tests pass. (Still using 2.6:) Turn on the -3 command line switch. This enables warnings about features that will be removed (or change) in 3.0. Run your test suite again, and fix code that you get warnings about until there are no warnings left, and all your tests still pass. Run the 2to3 source-to-source translator over your source code tree. (See 2to3 - Automated Python 2 to 3 code translation for more on this tool.) Run the result of the translation under Python 3.0. Manually fix up any remaining issues, fixing problems until all tests pass again. It is not recommended to try to write source code that runs unchanged under both Python 2.6 and 3.0; you’d have to use a very contorted coding style, e.g. avoiding print statements, metaclasses, and much more. If you are maintaining a library that needs to support both Python 2.6 and Python 3.0, the best approach is to modify step 3 above by editing the 2.6 version of the source code and running the 2to3 translator again, rather than editing the 3.0 version of the source code. For porting C extensions to Python 3.0, please see Porting Extension Modules to 3.0. Table Of Contents What’s New In Python 3.0 Common Stumbling Blocks Print Is A Function Views And Iterators Instead Of Lists Ordering Comparisons Integers Text Vs. Data Instead Of Unicode Vs. 8-bit Overview Of Syntax Changes New Syntax Changed Syntax Removed Syntax Changes Already Present In Python 2.6 Library Changes PEP 3101: A New Approach To String Formatting Changes To Exceptions Miscellaneous Other Changes Operators And Special Methods Builtins Build and C API Changes Performance Porting To Python 3.0 Previous topic What’s New In Python 3.1 Next topic What’s New in Python 2.6 This Page Report a Bug Show Source Quick search Enter search terms or a module, class or function name. Navigation index modules | next | previous | Python v3.1.3 documentation » What’s New in Python » © Copyright 1990-2010, Python Software Foundation. The Python Software Foundation is a non-profit corporation. Please donate. Last updated on Nov 27, 2010. Found a bug? Created using Sphinx 0.6.5. " />
/home/bani/Dropbox/Inbox/__inboxz/ak/inbox/cache.rdf:                   NS1:content="Navigation index modules | next | previous | Python v2.7.1 documentation » The Python Standard Library » 7. String Services » 7.8. codecs — Codec registry and base classes¶ This module defines base classes for standard Python codecs (encoders and decoders) and provides access to the internal Python codec registry which manages the codec and error handling lookup process. It defines the following functions: codecs.register(search_function)¶ Register a codec search function. Search functions are expected to take one argument, the encoding name in all lower case letters, and return a CodecInfo object having the following attributes: name The name of the encoding; encode The stateless encoding function; decode The stateless decoding function; incrementalencoder An incremental encoder class or factory function; incrementaldecoder An incremental decoder class or factory function; streamwriter A stream writer class or factory function; streamreader A stream reader class or factory function. The various functions or classes take the following arguments: encode and decode: These must be functions or methods which have the same interface as the encode()/decode() methods of Codec instances (see Codec Interface). The functions/methods are expected to work in a stateless mode. incrementalencoder and incrementaldecoder: These have to be factory functions providing the following interface: factory(errors='strict') The factory functions must return objects providing the interfaces defined by the base classes IncrementalEncoder and IncrementalDecoder, respectively. Incremental codecs can maintain state. streamreader and streamwriter: These have to be factory functions providing the following interface: factory(stream, errors='strict') The factory functions must return objects providing the interfaces defined by the base classes StreamWriter and StreamReader, respectively. Stream codecs can maintain state. Possible values for errors are 'strict': raise an exception in case of an encoding error 'replace': replace malformed data with a suitable replacement marker, such as '?' or '\ufffd' 'ignore': ignore malformed data and continue without further notice 'xmlcharrefreplace': replace with the appropriate XML character reference (for encoding only) 'backslashreplace': replace with backslashed escape sequences (for encoding only) as well as any other error handling name defined via register_error(). In case a search function cannot find a given encoding, it should return None. codecs.lookup(encoding)¶ Looks up the codec info in the Python codec registry and returns a CodecInfo object as defined above. Encodings are first looked up in the registry’s cache. If not found, the list of registered search functions is scanned. If no CodecInfo object is found, a LookupError is raised. Otherwise, the CodecInfo object is stored in the cache and returned to the caller. To simplify access to the various codecs, the module provides these additional functions which use lookup() for the codec lookup: codecs.getencoder(encoding)¶ Look up the codec for the given encoding and return its encoder function. Raises a LookupError in case the encoding cannot be found. codecs.getdecoder(encoding)¶ Look up the codec for the given encoding and return its decoder function. Raises a LookupError in case the encoding cannot be found. codecs.getincrementalencoder(encoding)¶ Look up the codec for the given encoding and return its incremental encoder class or factory function. Raises a LookupError in case the encoding cannot be found or the codec doesn’t support an incremental encoder. New in version 2.5. codecs.getincrementaldecoder(encoding)¶ Look up the codec for the given encoding and return its incremental decoder class or factory function. Raises a LookupError in case the encoding cannot be found or the codec doesn’t support an incremental decoder. New in version 2.5. codecs.getreader(encoding)¶ Look up the codec for the given encoding and return its StreamReader class or factory function. Raises a LookupError in case the encoding cannot be found. codecs.getwriter(encoding)¶ Look up the codec for the given encoding and return its StreamWriter class or factory function. Raises a LookupError in case the encoding cannot be found. codecs.register_error(name, error_handler)¶ Register the error handling function error_handler under the name name. error_handler will be called during encoding and decoding in case of an error, when name is specified as the errors parameter. For encoding error_handler will be called with a UnicodeEncodeError instance, which contains information about the location of the error. The error handler must either raise this or a different exception or return a tuple with a replacement for the unencodable part of the input and a position where encoding should continue. The encoder will encode the replacement and continue encoding the original input at the specified position. Negative position values will be treated as being relative to the end of the input string. If the resulting position is out of bound an IndexError will be raised. Decoding and translating works similar, except UnicodeDecodeError or UnicodeTranslateError will be passed to the handler and that the replacement from the error handler will be put into the output directly. codecs.lookup_error(name)¶ Return the error handler previously registered under the name name. Raises a LookupError in case the handler cannot be found. codecs.strict_errors(exception)¶ Implements the strict error handling: each encoding or decoding error raises a UnicodeError. codecs.replace_errors(exception)¶ Implements the replace error handling: malformed data is replaced with a suitable replacement character such as '?' in bytestrings and '\ufffd' in Unicode strings. codecs.ignore_errors(exception)¶ Implements the ignore error handling: malformed data is ignored and encoding or decoding is continued without further notice. codecs.xmlcharrefreplace_errors(exception)¶ Implements the xmlcharrefreplace error handling (for encoding only): the unencodable character is replaced by an appropriate XML character reference. codecs.backslashreplace_errors(exception)¶ Implements the backslashreplace error handling (for encoding only): the unencodable character is replaced by a backslashed escape sequence. To simplify working with encoded files or stream, the module also defines these utility functions: codecs.open(filename, mode[, encoding[, errors[, buffering]]])¶ Open an encoded file using the given mode and return a wrapped version providing transparent encoding/decoding. The default file mode is 'r' meaning to open the file in read mode. Note The wrapped version will only accept the object format defined by the codecs, i.e. Unicode objects for most built-in codecs. Output is also codec-dependent and will usually be Unicode as well. Note Files are always opened in binary mode, even if no binary mode was specified. This is done to avoid data loss due to encodings using 8-bit values. This means that no automatic conversion of '\n' is done on reading and writing. encoding specifies the encoding which is to be used for the file. errors may be given to define the error handling. It defaults to 'strict' which causes a ValueError to be raised in case an encoding error occurs. buffering has the same meaning as for the built-in open() function. It defaults to line buffered. codecs.EncodedFile(file, input[, output[, errors]])¶ Return a wrapped version of file which provides transparent encoding translation. Strings written to the wrapped file are interpreted according to the given input encoding and then written to the original file as strings using the output encoding. The intermediate encoding will usually be Unicode but depends on the specified codecs. If output is not given, it defaults to input. errors may be given to define the error handling. It defaults to 'strict', which causes ValueError to be raised in case an encoding error occurs. codecs.iterencode(iterable, encoding[, errors])¶ Uses an incremental encoder to iteratively encode the input provided by iterable. This function is a generator. errors (as well as any other keyword argument) is passed through to the incremental encoder. New in version 2.5. codecs.iterdecode(iterable, encoding[, errors])¶ Uses an incremental decoder to iteratively decode the input provided by iterable. This function is a generator. errors (as well as any other keyword argument) is passed through to the incremental decoder. New in version 2.5. The module also provides the following constants which are useful for reading and writing to platform dependent files: codecs.BOM¶ codecs.BOM_BE¶ codecs.BOM_LE¶ codecs.BOM_UTF8¶ codecs.BOM_UTF16¶ codecs.BOM_UTF16_BE¶ codecs.BOM_UTF16_LE¶ codecs.BOM_UTF32¶ codecs.BOM_UTF32_BE¶ codecs.BOM_UTF32_LE¶ These constants define various encodings of the Unicode byte order mark (BOM) used in UTF-16 and UTF-32 data streams to indicate the byte order used in the stream or file and in UTF-8 as a Unicode signature. BOM_UTF16 is either BOM_UTF16_BE or BOM_UTF16_LE depending on the platform’s native byte order, BOM is an alias for BOM_UTF16, BOM_LE for BOM_UTF16_LE and BOM_BE for BOM_UTF16_BE. The others represent the BOM in UTF-8 and UTF-32 encodings. 7.8.1. Codec Base Classes¶ The codecs module defines a set of base classes which define the interface and can also be used to easily write your own codecs for use in Python. Each codec has to define four interfaces to make it usable as codec in Python: stateless encoder, stateless decoder, stream reader and stream writer. The stream reader and writers typically reuse the stateless encoder/decoder to implement the file protocols. The Codec class defines the interface for stateless encoders/decoders. To simplify and standardize error handling, the encode() and decode() methods may implement different error handling schemes by providing the errors string argument. The following string values are defined and implemented by all standard Python codecs: Value Meaning 'strict' Raise UnicodeError (or a subclass); this is the default. 'ignore' Ignore the character and continue with the next. 'replace' Replace with a suitable replacement character; Python will use the official U+FFFD REPLACEMENT CHARACTER for the built-in Unicode codecs on decoding and ‘?’ on encoding. 'xmlcharrefreplace' Replace with the appropriate XML character reference (only for encoding). 'backslashreplace' Replace with backslashed escape sequences (only for encoding). The set of allowed values can be extended via register_error(). 7.8.1.1. Codec Objects¶ The Codec class defines these methods which also define the function interfaces of the stateless encoder and decoder: Codec.encode(input[, errors])¶ Encodes the object input and returns a tuple (output object, length consumed). While codecs are not restricted to use with Unicode, in a Unicode context, encoding converts a Unicode object to a plain string using a particular character set encoding (e.g., cp1252 or iso-8859-1). errors defines the error handling to apply. It defaults to 'strict' handling. The method may not store state in the Codec instance. Use StreamCodec for codecs which have to keep state in order to make encoding/decoding efficient. The encoder must be able to handle zero length input and return an empty object of the output object type in this situation. Codec.decode(input[, errors])¶ Decodes the object input and returns a tuple (output object, length consumed). In a Unicode context, decoding converts a plain string encoded using a particular character set encoding to a Unicode object. input must be an object which provides the bf_getreadbuf buffer slot. Python strings, buffer objects and memory mapped files are examples of objects providing this slot. errors defines the error handling to apply. It defaults to 'strict' handling. The method may not store state in the Codec instance. Use StreamCodec for codecs which have to keep state in order to make encoding/decoding efficient. The decoder must be able to handle zero length input and return an empty object of the output object type in this situation. The IncrementalEncoder and IncrementalDecoder classes provide the basic interface for incremental encoding and decoding. Encoding/decoding the input isn’t done with one call to the stateless encoder/decoder function, but with multiple calls to the encode()/decode() method of the incremental encoder/decoder. The incremental encoder/decoder keeps track of the encoding/decoding process during method calls. The joined output of calls to the encode()/decode() method is the same as if all the single inputs were joined into one, and this input was encoded/decoded with the stateless encoder/decoder. 7.8.1.2. IncrementalEncoder Objects¶ New in version 2.5. The IncrementalEncoder class is used for encoding an input in multiple steps. It defines the following methods which every incremental encoder must define in order to be compatible with the Python codec registry. class codecs.IncrementalEncoder([errors])¶ Constructor for an IncrementalEncoder instance. All incremental encoders must provide this constructor interface. They are free to add additional keyword arguments, but only the ones defined here are used by the Python codec registry. The IncrementalEncoder may implement different error handling schemes by providing the errors keyword argument. These parameters are predefined: 'strict' Raise ValueError (or a subclass); this is the default. 'ignore' Ignore the character and continue with the next. 'replace' Replace with a suitable replacement character 'xmlcharrefreplace' Replace with the appropriate XML character reference 'backslashreplace' Replace with backslashed escape sequences. The errors argument will be assigned to an attribute of the same name. Assigning to this attribute makes it possible to switch between different error handling strategies during the lifetime of the IncrementalEncoder object. The set of allowed values for the errors argument can be extended with register_error(). encode(object[, final])¶ Encodes object (taking the current state of the encoder into account) and returns the resulting encoded object. If this is the last call to encode() final must be true (the default is false). reset()¶ Reset the encoder to the initial state. 7.8.1.3. IncrementalDecoder Objects¶ The IncrementalDecoder class is used for decoding an input in multiple steps. It defines the following methods which every incremental decoder must define in order to be compatible with the Python codec registry. class codecs.IncrementalDecoder([errors])¶ Constructor for an IncrementalDecoder instance. All incremental decoders must provide this constructor interface. They are free to add additional keyword arguments, but only the ones defined here are used by the Python codec registry. The IncrementalDecoder may implement different error handling schemes by providing the errors keyword argument. These parameters are predefined: 'strict' Raise ValueError (or a subclass); this is the default. 'ignore' Ignore the character and continue with the next. 'replace' Replace with a suitable replacement character. The errors argument will be assigned to an attribute of the same name. Assigning to this attribute makes it possible to switch between different error handling strategies during the lifetime of the IncrementalDecoder object. The set of allowed values for the errors argument can be extended with register_error(). decode(object[, final])¶ Decodes object (taking the current state of the decoder into account) and returns the resulting decoded object. If this is the last call to decode() final must be true (the default is false). If final is true the decoder must decode the input completely and must flush all buffers. If this isn’t possible (e.g. because of incomplete byte sequences at the end of the input) it must initiate error handling just like in the stateless case (which might raise an exception). reset()¶ Reset the decoder to the initial state. The StreamWriter and StreamReader classes provide generic working interfaces which can be used to implement new encoding submodules very easily. See encodings.utf_8 for an example of how this is done. 7.8.1.4. StreamWriter Objects¶ The StreamWriter class is a subclass of Codec and defines the following methods which every stream writer must define in order to be compatible with the Python codec registry. class codecs.StreamWriter(stream[, errors])¶ Constructor for a StreamWriter instance. All stream writers must provide this constructor interface. They are free to add additional keyword arguments, but only the ones defined here are used by the Python codec registry. stream must be a file-like object open for writing binary data. The StreamWriter may implement different error handling schemes by providing the errors keyword argument. These parameters are predefined: 'strict' Raise ValueError (or a subclass); this is the default. 'ignore' Ignore the character and continue with the next. 'replace' Replace with a suitable replacement character 'xmlcharrefreplace' Replace with the appropriate XML character reference 'backslashreplace' Replace with backslashed escape sequences. The errors argument will be assigned to an attribute of the same name. Assigning to this attribute makes it possible to switch between different error handling strategies during the lifetime of the StreamWriter object. The set of allowed values for the errors argument can be extended with register_error(). write(object)¶ Writes the object’s contents encoded to the stream. writelines(list)¶ Writes the concatenated list of strings to the stream (possibly by reusing the write() method). reset()¶ Flushes and resets the codec buffers used for keeping state. Calling this method should ensure that the data on the output is put into a clean state that allows appending of new fresh data without having to rescan the whole stream to recover state. In addition to the above methods, the StreamWriter must also inherit all other methods and attributes from the underlying stream. 7.8.1.5. StreamReader Objects¶ The StreamReader class is a subclass of Codec and defines the following methods which every stream reader must define in order to be compatible with the Python codec registry. class codecs.StreamReader(stream[, errors])¶ Constructor for a StreamReader instance. All stream readers must provide this constructor interface. They are free to add additional keyword arguments, but only the ones defined here are used by the Python codec registry. stream must be a file-like object open for reading (binary) data. The StreamReader may implement different error handling schemes by providing the errors keyword argument. These parameters are defined: 'strict' Raise ValueError (or a subclass); this is the default. 'ignore' Ignore the character and continue with the next. 'replace' Replace with a suitable replacement character. The errors argument will be assigned to an attribute of the same name. Assigning to this attribute makes it possible to switch between different error handling strategies during the lifetime of the StreamReader object. The set of allowed values for the errors argument can be extended with register_error(). read([size[, chars[, firstline]]])¶ Decodes data from the stream and returns the resulting object. chars indicates the number of characters to read from the stream. read() will never return more than chars characters, but it might return less, if there are not enough characters available. size indicates the approximate maximum number of bytes to read from the stream for decoding purposes. The decoder can modify this setting as appropriate. The default value -1 indicates to read and decode as much as possible. size is intended to prevent having to decode huge files in one step. firstline indicates that it would be sufficient to only return the first line, if there are decoding errors on later lines. The method should use a greedy read strategy meaning that it should read as much data as is allowed within the definition of the encoding and the given size, e.g. if optional encoding endings or state markers are available on the stream, these should be read too. Changed in version 2.4: chars argument added. Changed in version 2.4.2: firstline argument added. readline([size[, keepends]])¶ Read one line from the input stream and return the decoded data. size, if given, is passed as size argument to the stream’s readline() method. If keepends is false line-endings will be stripped from the lines returned. Changed in version 2.4: keepends argument added. readlines([sizehint[, keepends]])¶ Read all lines available on the input stream and return them as a list of lines. Line-endings are implemented using the codec’s decoder method and are included in the list entries if keepends is true. sizehint, if given, is passed as the size argument to the stream’s read() method. reset()¶ Resets the codec buffers used for keeping state. Note that no stream repositioning should take place. This method is primarily intended to be able to recover from decoding errors. In addition to the above methods, the StreamReader must also inherit all other methods and attributes from the underlying stream. The next two base classes are included for convenience. They are not needed by the codec registry, but may provide useful in practice. 7.8.1.6. StreamReaderWriter Objects¶ The StreamReaderWriter allows wrapping streams which work in both read and write modes. The design is such that one can use the factory functions returned by the lookup() function to construct the instance. class codecs.StreamReaderWriter(stream, Reader, Writer, errors)¶ Creates a StreamReaderWriter instance. stream must be a file-like object. Reader and Writer must be factory functions or classes providing the StreamReader and StreamWriter interface resp. Error handling is done in the same way as defined for the stream readers and writers. StreamReaderWriter instances define the combined interfaces of StreamReader and StreamWriter classes. They inherit all other methods and attributes from the underlying stream. 7.8.1.7. StreamRecoder Objects¶ The StreamRecoder provide a frontend - backend view of encoding data which is sometimes useful when dealing with different encoding environments. The design is such that one can use the factory functions returned by the lookup() function to construct the instance. class codecs.StreamRecoder(stream, encode, decode, Reader, Writer, errors)¶ Creates a StreamRecoder instance which implements a two-way conversion: encode and decode work on the frontend (the input to read() and output of write()) while Reader and Writer work on the backend (reading and writing to the stream). You can use these objects to do transparent direct recodings from e.g. Latin-1 to UTF-8 and back. stream must be a file-like object. encode, decode must adhere to the Codec interface. Reader, Writer must be factory functions or classes providing objects of the StreamReader and StreamWriter interface respectively. encode and decode are needed for the frontend translation, Reader and Writer for the backend translation. The intermediate format used is determined by the two sets of codecs, e.g. the Unicode codecs will use Unicode as the intermediate encoding. Error handling is done in the same way as defined for the stream readers and writers. StreamRecoder instances define the combined interfaces of StreamReader and StreamWriter classes. They inherit all other methods and attributes from the underlying stream. 7.8.2. Encodings and Unicode¶ Unicode strings are stored internally as sequences of codepoints (to be precise as Py_UNICODE arrays). Depending on the way Python is compiled (either via --enable-unicode=ucs2 or --enable-unicode=ucs4, with the former being the default) Py_UNICODE is either a 16-bit or 32-bit data type. Once a Unicode object is used outside of CPU and memory, CPU endianness and how these arrays are stored as bytes become an issue. Transforming a unicode object into a sequence of bytes is called encoding and recreating the unicode object from the sequence of bytes is known as decoding. There are many different methods for how this transformation can be done (these methods are also called encodings). The simplest method is to map the codepoints 0-255 to the bytes 0x0-0xff. This means that a unicode object that contains codepoints above U+00FF can’t be encoded with this method (which is called 'latin-1' or 'iso-8859-1'). unicode.encode() will raise a UnicodeEncodeError that looks like this: UnicodeEncodeError: 'latin-1' codec can't encode character u'\u1234' in position 3: ordinal not in range(256). There’s another group of encodings (the so called charmap encodings) that choose a different subset of all unicode code points and how these codepoints are mapped to the bytes 0x0-0xff. To see how this is done simply open e.g. encodings/cp1252.py (which is an encoding that is used primarily on Windows). There’s a string constant with 256 characters that shows you which character is mapped to which byte value. All of these encodings can only encode 256 of the 65536 (or 1114111) codepoints defined in unicode. A simple and straightforward way that can store each Unicode code point, is to store each codepoint as two consecutive bytes. There are two possibilities: Store the bytes in big endian or in little endian order. These two encodings are called UTF-16-BE and UTF-16-LE respectively. Their disadvantage is that if e.g. you use UTF-16-BE on a little endian machine you will always have to swap bytes on encoding and decoding. UTF-16 avoids this problem: Bytes will always be in natural endianness. When these bytes are read by a CPU with a different endianness, then bytes have to be swapped though. To be able to detect the endianness of a UTF-16 byte sequence, there’s the so called BOM (the “Byte Order Mark”). This is the Unicode character U+FEFF. This character will be prepended to every UTF-16 byte sequence. The byte swapped version of this character (0xFFFE) is an illegal character that may not appear in a Unicode text. So when the first character in an UTF-16 byte sequence appears to be a U+FFFE the bytes have to be swapped on decoding. Unfortunately upto Unicode 4.0 the character U+FEFF had a second purpose as a ZERO WIDTH NO-BREAK SPACE: A character that has no width and doesn’t allow a word to be split. It can e.g. be used to give hints to a ligature algorithm. With Unicode 4.0 using U+FEFF as a ZERO WIDTH NO-BREAK SPACE has been deprecated (with U+2060 (WORD JOINER) assuming this role). Nevertheless Unicode software still must be able to handle U+FEFF in both roles: As a BOM it’s a device to determine the storage layout of the encoded bytes, and vanishes once the byte sequence has been decoded into a Unicode string; as a ZERO WIDTH NO-BREAK SPACE it’s a normal character that will be decoded like any other. There’s another encoding that is able to encoding the full range of Unicode characters: UTF-8. UTF-8 is an 8-bit encoding, which means there are no issues with byte order in UTF-8. Each byte in a UTF-8 byte sequence consists of two parts: Marker bits (the most significant bits) and payload bits. The marker bits are a sequence of zero to six 1 bits followed by a 0 bit. Unicode characters are encoded like this (with x being payload bits, which when concatenated give the Unicode character): Range Encoding U-00000000 ... U-0000007F 0xxxxxxx U-00000080 ... U-000007FF 110xxxxx 10xxxxxx U-00000800 ... U-0000FFFF 1110xxxx 10xxxxxx 10xxxxxx U-00010000 ... U-001FFFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx U-00200000 ... U-03FFFFFF 111110xx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx U-04000000 ... U-7FFFFFFF 1111110x 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx The least significant bit of the Unicode character is the rightmost x bit. As UTF-8 is an 8-bit encoding no BOM is required and any U+FEFF character in the decoded Unicode string (even if it’s the first character) is treated as a ZERO WIDTH NO-BREAK SPACE. Without external information it’s impossible to reliably determine which encoding was used for encoding a Unicode string. Each charmap encoding can decode any random byte sequence. However that’s not possible with UTF-8, as UTF-8 byte sequences have a structure that doesn’t allow arbitrary byte sequences. To increase the reliability with which a UTF-8 encoding can be detected, Microsoft invented a variant of UTF-8 (that Python 2.5 calls &quot;utf-8-sig&quot;) for its Notepad program: Before any of the Unicode characters is written to the file, a UTF-8 encoded BOM (which looks like this as a byte sequence: 0xef, 0xbb, 0xbf) is written. As it’s rather improbable that any charmap encoded file starts with these byte values (which would e.g. map to LATIN SMALL LETTER I WITH DIAERESIS RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK INVERTED QUESTION MARK in iso-8859-1), this increases the probability that a utf-8-sig encoding can be correctly guessed from the byte sequence. So here the BOM is not used to be able to determine the byte order used for generating the byte sequence, but as a signature that helps in guessing the encoding. On encoding the utf-8-sig codec will write 0xef, 0xbb, 0xbf as the first three bytes to the file. On decoding utf-8-sig will skip those three bytes if they appear as the first three bytes in the file. 7.8.3. Standard Encodings¶ Python comes with a number of codecs built-in, either implemented as C functions or with dictionaries as mapping tables. The following table lists the codecs by name, together with a few common aliases, and the languages for which the encoding is likely used. Neither the list of aliases nor the list of languages is meant to be exhaustive. Notice that spelling alternatives that only differ in case or use a hyphen instead of an underscore are also valid aliases; therefore, e.g. 'utf-8' is a valid alias for the 'utf_8' codec. Many of the character sets support the same languages. They vary in individual characters (e.g. whether the EURO SIGN is supported or not), and in the assignment of characters to code positions. For the European languages in particular, the following variants typically exist: an ISO 8859 codeset a Microsoft Windows code page, which is typically derived from a 8859 codeset, but replaces control characters with additional graphic characters an IBM EBCDIC code page an IBM PC code page, which is ASCII compatible Codec Aliases Languages ascii 646, us-ascii English big5 big5-tw, csbig5 Traditional Chinese big5hkscs big5-hkscs, hkscs Traditional Chinese cp037 IBM037, IBM039 English cp424 EBCDIC-CP-HE, IBM424 Hebrew cp437 437, IBM437 English cp500 EBCDIC-CP-BE, EBCDIC-CP-CH, IBM500 Western Europe cp720 Arabic cp737 Greek cp775 IBM775 Baltic languages cp850 850, IBM850 Western Europe cp852 852, IBM852 Central and Eastern Europe cp855 855, IBM855 Bulgarian, Byelorussian, Macedonian, Russian, Serbian cp856 Hebrew cp857 857, IBM857 Turkish cp858 858, IBM858 Western Europe cp860 860, IBM860 Portuguese cp861 861, CP-IS, IBM861 Icelandic cp862 862, IBM862 Hebrew cp863 863, IBM863 Canadian cp864 IBM864 Arabic cp865 865, IBM865 Danish, Norwegian cp866 866, IBM866 Russian cp869 869, CP-GR, IBM869 Greek cp874 Thai cp875 Greek cp932 932, ms932, mskanji, ms-kanji Japanese cp949 949, ms949, uhc Korean cp950 950, ms950 Traditional Chinese cp1006 Urdu cp1026 ibm1026 Turkish cp1140 ibm1140 Western Europe cp1250 windows-1250 Central and Eastern Europe cp1251 windows-1251 Bulgarian, Byelorussian, Macedonian, Russian, Serbian cp1252 windows-1252 Western Europe cp1253 windows-1253 Greek cp1254 windows-1254 Turkish cp1255 windows-1255 Hebrew cp1256 windows-1256 Arabic cp1257 windows-1257 Baltic languages cp1258 windows-1258 Vietnamese euc_jp eucjp, ujis, u-jis Japanese euc_jis_2004 jisx0213, eucjis2004 Japanese euc_jisx0213 eucjisx0213 Japanese euc_kr euckr, korean, ksc5601, ks_c-5601, ks_c-5601-1987, ksx1001, ks_x-1001 Korean gb2312 chinese, csiso58gb231280, euc- cn, euccn, eucgb2312-cn, gb2312-1980, gb2312-80, iso- ir-58 Simplified Chinese gbk 936, cp936, ms936 Unified Chinese gb18030 gb18030-2000 Unified Chinese hz hzgb, hz-gb, hz-gb-2312 Simplified Chinese iso2022_jp csiso2022jp, iso2022jp, iso-2022-jp Japanese iso2022_jp_1 iso2022jp-1, iso-2022-jp-1 Japanese iso2022_jp_2 iso2022jp-2, iso-2022-jp-2 Japanese, Korean, Simplified Chinese, Western Europe, Greek iso2022_jp_2004 iso2022jp-2004, iso-2022-jp-2004 Japanese iso2022_jp_3 iso2022jp-3, iso-2022-jp-3 Japanese iso2022_jp_ext iso2022jp-ext, iso-2022-jp-ext Japanese iso2022_kr csiso2022kr, iso2022kr, iso-2022-kr Korean latin_1 iso-8859-1, iso8859-1, 8859, cp819, latin, latin1, L1 West Europe iso8859_2 iso-8859-2, latin2, L2 Central and Eastern Europe iso8859_3 iso-8859-3, latin3, L3 Esperanto, Maltese iso8859_4 iso-8859-4, latin4, L4 Baltic languages iso8859_5 iso-8859-5, cyrillic Bulgarian, Byelorussian, Macedonian, Russian, Serbian iso8859_6 iso-8859-6, arabic Arabic iso8859_7 iso-8859-7, greek, greek8 Greek iso8859_8 iso-8859-8, hebrew Hebrew iso8859_9 iso-8859-9, latin5, L5 Turkish iso8859_10 iso-8859-10, latin6, L6 Nordic languages iso8859_13 iso-8859-13, latin7, L7 Baltic languages iso8859_14 iso-8859-14, latin8, L8 Celtic languages iso8859_15 iso-8859-15, latin9, L9 Western Europe iso8859_16 iso-8859-16, latin10, L10 South-Eastern Europe johab cp1361, ms1361 Korean koi8_r Russian koi8_u Ukrainian mac_cyrillic maccyrillic Bulgarian, Byelorussian, Macedonian, Russian, Serbian mac_greek macgreek Greek mac_iceland maciceland Icelandic mac_latin2 maclatin2, maccentraleurope Central and Eastern Europe mac_roman macroman Western Europe mac_turkish macturkish Turkish ptcp154 csptcp154, pt154, cp154, cyrillic-asian Kazakh shift_jis csshiftjis, shiftjis, sjis, s_jis Japanese shift_jis_2004 shiftjis2004, sjis_2004, sjis2004 Japanese shift_jisx0213 shiftjisx0213, sjisx0213, s_jisx0213 Japanese utf_32 U32, utf32 all languages utf_32_be UTF-32BE all languages utf_32_le UTF-32LE all languages utf_16 U16, utf16 all languages utf_16_be UTF-16BE all languages (BMP only) utf_16_le UTF-16LE all languages (BMP only) utf_7 U7, unicode-1-1-utf-7 all languages utf_8 U8, UTF, utf8 all languages utf_8_sig all languages A number of codecs are specific to Python, so their codec names have no meaning outside Python. Some of them don’t convert from Unicode strings to byte strings, but instead use the property of the Python codecs machinery that any bijective function with one argument can be considered as an encoding. For the codecs listed below, the result in the “encoding” direction is always a byte string. The result of the “decoding” direction is listed as operand type in the table. Codec Aliases Operand type Purpose base64_codec base64, base-64 byte string Convert operand to MIME base64 bz2_codec bz2 byte string Compress the operand using bz2 hex_codec hex byte string Convert operand to hexadecimal representation, with two digits per byte idna Unicode string Implements RFC 3490, see also encodings.idna mbcs dbcs Unicode string Windows only: Encode operand according to the ANSI codepage (CP_ACP) palmos Unicode string Encoding of PalmOS 3.5 punycode Unicode string Implements RFC 3492 quopri_codec quopri, quoted-printable, quotedprintable byte string Convert operand to MIME quoted printable raw_unicode_escape Unicode string Produce a string that is suitable as raw Unicode literal in Python source code rot_13 rot13 Unicode string Returns the Caesar-cypher encryption of the operand string_escape byte string Produce a string that is suitable as string literal in Python source code undefined any Raise an exception for all conversions. Can be used as the system encoding if no automatic coercion between byte and Unicode strings is desired. unicode_escape Unicode string Produce a string that is suitable as Unicode literal in Python source code unicode_internal Unicode string Return the internal representation of the operand uu_codec uu byte string Convert the operand using uuencode zlib_codec zip, zlib byte string Compress the operand using gzip New in version 2.3: The idna and punycode encodings. 7.8.4. encodings.idna — Internationalized Domain Names in Applications¶ New in version 2.3. This module implements RFC 3490 (Internationalized Domain Names in Applications) and RFC 3492 (Nameprep: A Stringprep Profile for Internationalized Domain Names (IDN)). It builds upon the punycode encoding and stringprep. These RFCs together define a protocol to support non-ASCII characters in domain names. A domain name containing non-ASCII characters (such as www.Alliancefrançaise.nu) is converted into an ASCII-compatible encoding (ACE, such as www.xn--alliancefranaise-npb.nu). The ACE form of the domain name is then used in all places where arbitrary characters are not allowed by the protocol, such as DNS queries, HTTP Host fields, and so on. This conversion is carried out in the application; if possible invisible to the user: The application should transparently convert Unicode domain labels to IDNA on the wire, and convert back ACE labels to Unicode before presenting them to the user. Python supports this conversion in several ways: the idna codec performs conversion between Unicode and ACE, separating an input string into labels based on the separator characters defined in section 3.1 (1) of RFC 3490 and converting each label to ACE as required, and conversely separating an input byte string into labels based on the . separator and converting any ACE labels found into unicode. Furthermore, the socket module transparently converts Unicode host names to ACE, so that applications need not be concerned about converting host names themselves when they pass them to the socket module. On top of that, modules that have host names as function parameters, such as httplib and ftplib, accept Unicode host names (httplib then also transparently sends an IDNA hostname in the Host field if it sends that field at all). When receiving host names from the wire (such as in reverse name lookup), no automatic conversion to Unicode is performed: Applications wishing to present such host names to the user should decode them to Unicode. The module encodings.idna also implements the nameprep procedure, which performs certain normalizations on host names, to achieve case-insensitivity of international domain names, and to unify similar characters. The nameprep functions can be used directly if desired. encodings.idna.nameprep(label)¶ Return the nameprepped version of label. The implementation currently assumes query strings, so AllowUnassigned is true. encodings.idna.ToASCII(label)¶ Convert a label to ASCII, as specified in RFC 3490. UseSTD3ASCIIRules is assumed to be false. encodings.idna.ToUnicode(label)¶ Convert a label to Unicode, as specified in RFC 3490. 7.8.5. encodings.utf_8_sig — UTF-8 codec with BOM signature¶ New in version 2.5. This module implements a variant of the UTF-8 codec: On encoding a UTF-8 encoded BOM will be prepended to the UTF-8 encoded bytes. For the stateful encoder this is only done once (on the first write to the byte stream). For decoding an optional UTF-8 encoded BOM at the start of the data will be skipped. Table Of Contents 7.8. codecs — Codec registry and base classes 7.8.1. Codec Base Classes 7.8.1.1. Codec Objects 7.8.1.2. IncrementalEncoder Objects 7.8.1.3. IncrementalDecoder Objects 7.8.1.4. StreamWriter Objects 7.8.1.5. StreamReader Objects 7.8.1.6. StreamReaderWriter Objects 7.8.1.7. StreamRecoder Objects 7.8.2. Encodings and Unicode 7.8.3. Standard Encodings 7.8.4. encodings.idna — Internationalized Domain Names in Applications 7.8.5. encodings.utf_8_sig — UTF-8 codec with BOM signature Previous topic 7.7. textwrap — Text wrapping and filling Next topic 7.9. unicodedata — Unicode Database This Page Report a Bug Show Source Quick search Enter search terms or a module, class or function name. Navigation index modules | next | previous | Python v2.7.1 documentation » The Python Standard Library » 7. String Services » © Copyright 1990-2011, Python Software Foundation. The Python Software Foundation is a non-profit corporation. Please donate. Last updated on May 10, 2011. Found a bug? Created using Sphinx 0.6.7. " />
/home/bani/Dropbox/Inbox/__inboxz/ak/inbox/cache.rdf:                   NS1:content="English French [qt-devnet.developpez.com] Building PySide on Linux PySide uses CMake’s system to build the source code packages. You can familiarise yourself with CMake at PySide CMake Primer. The Easy Way There is now a “buildscripts” repository available on Gitorious: http://qt.gitorious.org/pyside/buildscripts With this repository, you can automate the build steps outlined in this Wiki page. It also takes care of installing the correct prerequisite packages for your distribution (i.e. use ? 1 sudo ./dependencies.ubuntu.sh to install build dependencies on Debian or Ubuntu). If there is no dependencies script for your distribution, please submit a patch. See the README [qt.gitorious.org] file for detailed usage instructions. Prerequisites CMake &gt;= 2.6.0 Qt libraries and development headers &gt;= 4.6 (preferably the latest stable release) libxml2 and development headers &gt;= 2.6.32 (for apiextractor only) libxslt and development headers &gt;= 1.1.19 (for apiextractor only) Python libraries and development headers &gt;= 2.5 (for shiboken and pyside) Overview PySide consists of a chain of four interdependent packages: The API Extractor library is used by the bindings generator to parse the header and typesystem files to create an internal representation of the API. It is based on the QtScriptGenerator [labs.trolltech.com] codebase. The Generator Runner (A.K.A. generatorrunner) is the program that controls the bindings generation process according to the rules given by the user through headers, typesystem files and generator front-ends (such as Shiboken Generator). It depends on API Extractor library. The Shiboken Generator (A.K.A. shiboken) is the plugin that creates the PySide bindings source files from Qt headers and auxiliary files (typesystems, global.h and glue files). It depends on Generator Runner and API Extractor library. PySide Qt bindings (A.K.A. pyside) is the set of typesystem definitions and glue code that allows generation of Python Qt binding modules using the PySide toolchain. It depends on the Shiboken libraries and Generator Runner. There is also an optional package called pyside-tools which provides some useful utilities for creating PySide applications. If you don’t want or need that package, skip the commands that say “pyside-tools” in them in the scripts below. Getting the source code Fetch these from the repos: ? 1 2 3 4 5 git clone git://gitorious.org/pyside/apiextractor.git git clone git://gitorious.org/pyside/generatorrunner.git git clone git://gitorious.org/pyside/shiboken.git git clone git://gitorious.org/pyside/pyside.git git clone git://gitorious.org/pyside/pyside-tools.git Tarballs are found at PySideDownloads. Building and installing Sandbox If you wish to install PySide into a local sandbox then follow these instructions, otherwise you can skip this step. We will assume that PYSIDESANDBOXPATH will be the path to your local sandbox. ? 1 export PYSIDESANDBOXPATH=$HOME/sandbox Setup these variables accordingly. ? 1 2 3 4 5 6 export PATH=$PYSIDESANDBOXPATH/bin:$PATH export PYTHONPATH=$PYSIDESANDBOXPATH/lib/python2.6/site-packages:$PYTHONPATH export LD_LIBRARY_PATH=$PYSIDESANDBOXPATH/lib:$LD_LIBRARY_PATH export PKG_CONFIG_PATH=$PYSIDESANDBOXPATH/lib/pkgconfig:$PKG_CONFIG_PATH # set -DENABLE_ICECC=1 if you're using the icecream distributed compiler alias runcmake='cmake .. -DCMAKE_INSTALL_PREFIX=$PYSIDESANDBOXPATH -DCMAKE_BUILD_TYPE=Debug -DENABLE_ICECC=0' It makes sense to place these variables into a shell script that you can source whenever you need to work with the PySide bindings from the sandbox (especially if you have a system-wide installation of PySide as well). In the next step replace cmake with runcmake, and sudo make install. Building For each package in order (apiextractor, generatorrunner, shiboken, pyside), run the following commands: ? 1 2 3 4 5 mkdir build cd build cmake .. make sudo make install Depending on the package and whether there is an existing library with the same version number already installed, you might need to run ldconfig to update the run-time linker cache. ? 1 sudo ldconfig That’s it! PySide should now be successfully built! Practical tips Use build scripts for a successful life Especially if you are just interested in tracking the PySide head, you might be interested in using the following utility scripts. clone_all: ? 1 2 3 4 5 6 7 #!/usr/bin/env bash allrepos=&quot;apiextractor generatorrunner shiboken pyside pyside-mobility&quot; for repo in ${allrepos} ; do git clone git://gitorious.org/pyside/$repo.git done pull_all: ? 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #!/usr/bin/env bash alldirs=(&quot;apiextractor&quot; &quot;generatorrunner&quot; &quot;shiboken&quot; &quot;pyside&quot; &quot;pyside-mobility&quot;) if [ $# == 0 ] ; then dirs=(&quot;${alldirs[@]}&quot;) else dirs=(&quot;$@&quot;) fi for d in &quot;${dirs[@]}&quot; ; do (cd &quot;$d&quot; git pull origin master ) # exit from &quot;$d&quot; done build_all: ? 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #!/usr/bin/env bash alldirs=(&quot;apiextractor&quot; &quot;generatorrunner&quot; &quot;shiboken&quot; &quot;pyside&quot;) if [ $# == 0 ] ; then dirs=(&quot;${alldirs[@]}&quot;) else dirs=(&quot;$@&quot;) fi for d in &quot;${dirs[@]}&quot; ; do rm -rf &quot;$d/build&quot; mkdir -p &quot;$d/build&quot; (cd &quot;$d/build&quot; cmake .. &amp;&amp; make -j4 &amp;&amp; sudo make install || exit 1 ) # exit from &quot;$d/build&quot; done Categories: LanguageBindings PySide " />
/home/bani/Dropbox/Inbox/__inboxz/ak/Kubuntu/.kde_set/share/apps/ktexteditor_snippets/data/GTD.xml~: Causes Kate to use and existing instance if there is one. If you want all documents to open in one kate instance, you can add this option to the default command in your kde application configuration, as well as create a shell alias in your command intepreter if it supports that. 
/home/bani/Dropbox/Inbox/__inboxz/ak/Kubuntu/.kde_set/share/apps/ktexteditor_snippets/data/GTD.xml: Causes Kate to use and existing instance if there is one. If you want all documents to open in one kate instance, you can add this option to the default command in your kde application configuration, as well as create a shell alias in your command intepreter if it supports that. 
/home/bani/Dropbox/Inbox/__inboxz/ak/Kubuntu/@Vaio/FF/data/20110718014451/index.html:            <p>Insert or remove the default prefix for mail or pick another from your defined collection by the prefixes.<br>Prefix may be associated with the project / task that you are executing It may also describe the content of the email - [ORG] - Organizing, [PRV] - private, etc. .. For every prefix you can define the list of recipients used when sending out an email.<br>Make categorizing messages easier - when you add a prefix to message then you and the recipient will know what should by in the mail.<br><br>SubSwitch gives you also:<br>1/ auto-discovery of prefixes - recognition of prefixes during answering/forwarding messages with the possibility of adding a new prefix to the list, or as an alias for an existing prefix<br>2/ ignore list used during answering/forwarding messages<br>3/ import of settings from *.csv files &amp; export of your settings to *.csv files<br><br><strong><br>I'm looking for help with SubSwitch translation. If you want to have your language's version of SubSwitch - write for detailed instructions.<br></strong><br><br>For further instructions and assistance please write to me - ktsystems@gmail.com</p>
/home/bani/Dropbox/Inbox/__inboxz/ak/Kubuntu/@Vaio/FF/data/20110718014451/index.html:                <a class="screenshot thumbnail" rel="jquery-lightbox" href="https://static-cdn.addons.mozilla.net/img/uploads/previews/full/45/45470.png?modified=1273139154" title="Recognition of prefix while replying and adding found prefix as alias to existing one. 
/home/bani/Dropbox/Inbox/__inboxz/ak/Kubuntu/@AK/wwautokey/autokey.json:                    "code": "#Enter script code\n# IDE \"helper\" not part of the framework\nimport datetime\nimport hashlib\nimport base64\n\nfrom gluon.contrib.login_methods.email_auth import email_auth\nfrom gluon import *\nfrom gluon.globals import *\nfrom gluon.html import *\nfrom gluon.http import *\nfrom gluon.sqlhtml import SQLFORM, SQLTABLE, form_factory\n# session = Session()\n# request = Request()\n# response = Response()\n\n# stream = open(filename,'rb')\n#  db.myfile.insert(image=db.myfile.image.store(stream,filename))\n\n\n\n# row = db(db.myfile).select().first()\n# filename, stream) = db.myfile.image.retrieve(row.image)\n# import shutil\n#  shutil.copyfileobj(stream,open(filename,'wb'))\n\nQuery, Set, Rows\n\nLet's consider again the table defined (and dropped) previously and insert three records:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n\n\t\n\n>>> db.define_table('person', Field('name'))\n>>> db.person.insert(name=\"Alex\")\n1\n>>> db.person.insert(name=\"Bob\")\n2\n>>> db.person.insert(name=\"Carl\")\n3\n\nYou can store the table in a variable. For example, with variable person, you could do:\n\nTable\n\n1.\n\n\t\n\n>>> person = db.person\n\nYou can also store a field in a variable such as name. For example, you could also do:\n\nField\n\n1.\n\n\t\n\n>>> name = person.name\n\nYou can even build a query (using operators like ==, !=, <, >, <=, >=, like, belongs) and store the query in a variable q such as in:\n\nQuery\n\n1.\n\n\t\n\n>>> q = name=='Alex'\n\nWhen you call db with a query, you define a set of records. You can store it in a variable s and write:\n\nSet\n\n1.\n\n\t\n\n>>> s = db(q)\n\nNotice that no database query has been performed so far. DAL + Query simply define a set of records in this db that match the query. web2py determines from the query which table (or tables) are involved and, in fact, there is no need to specify that.\nselect\n\nGiven a Set, s, you can fetch the records with the command select:\n\nRows\nselect\n\n1.\n\n\t\n\n>>> rows = s.select()\n\nRow\nIt returns an iterable object of class gluon.sql.Rows whose elements are Row objects. gluon.sql.Row objects act like dictionaries, but their elements can also be accessed as attributes, like gluon.storage.Storage.The former differ from the latter because its values are readonly.\n\nThe Rows object allows looping over the result of the select and printing the selected field values for each row:\n\n1.\n2.\n3.\n\n\t\n\n>>> for row in rows:\n        print row.id, row.name\n1 Alex\n\nYou can do all the steps in one statement:\n\n1.\n2.\n3.\n\n\t\n\n>>> for row in db(db.person.name=='Alex').select():\n        print row.name\nAlex\n\nALL\n\nThe select command can take arguments. All unnamed arguments are interpreted as the names of the fields that you want to fetch. For example, you can be explicit on fetching field \"id\" and field \"name\":\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> for row in db().select(db.person.id, db.person.name):\n        print row.name\nAlex\nBob\nCarl\n\nThe table attribute ALL allows you to specify all fields:\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> for row in db().select(db.person.ALL):\n        print row.name\nAlex\nBob\nCarl\n\nNotice that there is no query string passed to db. web2py understands that if you want all fields of the table person without additional information then you want all records of the table person.\n\nAn equivalent alternative syntax is the following:\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> for row in db(db.person.id > 0).select():\n        print row.name\nAlex\nBob\nCarl\n\nand web2py understands that if you ask for all records of the table person (id > 0) without additional information, then you want all the fields of table person.\n\nGiven one row\n\nrow = rows[0]\n\nyou can extract its values using multiple equivalent expressions:\n\n>>> row.name\nAlex\n>>> row['name']\nAlex\n>>> row('person.name')\nAlex\n\nThe latter syntax is particularly handy when selecting en expression instead of a column. We will show this later.\n\nYou can also do\n\nrows.compact = False\n\nto disable the notation\n\nrow[i].name\n\nand enable, instead, the less compact notation:\n\nrow[i].person.name\n\nYes this is unusual and not rarely needed.\n\nShortcuts\nDAL shortcuts\n\nThe DAL supports various code-simplifying shortcuts. In particular:\n\n1.\n\n\t\n\nmyrecord = db.mytable[id]\n\nreturns the record with the given id if it exists. If the id does not exist, it returns None. The above statement is equivalent to\n\n1.\n\n\t\n\nmyrecord = db(db.mytable.id==id).select().first()\n\nYou can delete records by id:\n\n1.\n\n\t\n\ndel db.mytable[id]\n\nand this is equivalent to\n\n1.\n\n\t\n\ndb(db.mytable.id==id).delete()\n\nand deletes the record with the given id, if it exists.\n\nYou can insert records:\n\n1.\n\n\t\n\ndb.mytable[0] = dict(myfield='somevalue')\n\nIt is equivalent to\n\n1.\n\n\t\n\ndb.mytable.insert(myfield='somevalue')\n\nand it creates a new record with field values specified by the dictionary on the right hand side.\n\nYou can update records:\n\n1.\n\n\t\n\ndb.mytable[id] = dict(myfield='somevalue')\n\nwhich is equivalent to\n\n1.\n\n\t\n\ndb(db.mytable.id==id).update(myfield='somevalue')\n\nand it updates an existing record with field values specified by the dictionary on the right hand side.\nFetching a Row\n\nYet another convenient syntax is the following:\n\n1.\n2.\n3.\n\n\t\n\nrecord = db.mytable(id)\nrecord = db.mytable(db.mytable.id==id)\nrecord = db.mytable(id,myfield='somevalue')\n\nApparently similar to db.mytable[id] the above syntax is more flexible and safer. First of all it checks whether id is an int (or str(id) is an int) and returns None if not (it never raises an exception). It also allows to specify multiple conditions that the record must meet. If they are not met, it also returns None.\nRecursive selects\nrecursive selects\n\nConsider the previous table person and a new table \"dog\" referencing a \"person\":\n\n1.\n\n\t\n\n>>> db.define_table('dog', Field('name'), Field('owner',db.person))\n\nand a simple select from this table:\n\n1.\n\n\t\n\n>>> dogs = db(db.dog).select()\n\nwhich is equivalent to\n\n1.\n\n\t\n\n>>> dogs = db(db.dog._id>0).select()\n\nwhere ._id is a reference to the primary key of the table. Normally db.dog._id is the same as db.dog.id and we will assume that in most of this book.\n_id\n\nFor each Row of dogs it is possible to fetch not just fields from the selected table (dog) but also from linked tables (recursively):\n\n1.\n\n\t\n\n>>> for dog in dogs: print dog.name, dog.owner.name\n\nHere dog.owner.name requires one database select for each dog in dogs and it is therefore inefficient. We suggest using joins whenever possible instead of recursive selects, nevertheless this is convenient and practical when accessing individual records.\n\nYou can also do it backwards, by selecting the dogs referenced by a person:\n\n1.\n2.\n3.\n\n\t\n\nperson =  db.person(id)\nfor dog in person.dog.select(orderby=db.dog.name):\n    print person.name, 'owns', dog.name\n\nIn this last expressions person.dog is a shortcut for\n\n1.\n\n\t\n\ndb(db.dog.owner==person.id)\n\ni.e. the Set of dogs referenced by the current person. This syntax breaks down if the referencing table has multiple references to the referenced table. In this case one needs to be more explicit and use a full Query.\nSerializing Rows in views\n\nGiven the following action containing a query\nSQLTABLE\n\n1.\n2.\n\n\t\n\ndef index()\n    return dict(rows = db(query).select())\n\nThe result of a select can be displayed in a view with the following syntax:\n\n1.\n2.\n3.\n\n\t\n\n{{extend 'layout.html'}}\n<h1>Records</h1>\n{{=rows}}\n\nWhich is equivalent to:\n\n1.\n2.\n3.\n\n\t\n\n{{extend 'layout.html'}}\n<h1>Records</h1>\n{{=SQLTABLE(rows)}}\n\nSQLTABLE converts the rows into an HTML table with a header containing the column names and one row per record. The rows are marked as alternating class \"even\" and class \"odd\". Under the hood, Rows is first converted into a SQLTABLE object (not to be confused with Table) and then serialized. The values extracted from the database are also formatted by the validators associated to the field and then escaped. (Note: Using a db in this way in a view is usually not considered good MVC practice.)\n\nYet it is possible and sometimes convenient to call SQLTABLE explicitly.\n\nThe SQLTABLE constructor takes the following optional arguments:\n\n    linkto the URL or an action to be used to link reference fields (default to None)\n    upload the URL or the download action to allow downloading of uploaded files (default to None)\n    headers a dictionary mapping field names to their labels to be used as headers (default to {}). It can also be an instruction. Currently we support headers='fieldname:capitalize'.\n    truncate the number of characters for truncating long values in the table (default is 16)\n    columns the list of fieldnames to be shown as columns (in tablename.fieldname format).\n\nThose not listed are not displayed (defaults to all).\n\n    **attributes generic helper attributes to be passed to the most external TABLE object.\n\nHere is an example:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n\n\t\n\n{{extend 'layout.html'}}\n<h1>Records</h1>\n{{=SQLTABLE(rows,\n     headers='fieldname:capitalize',\n     truncate=100,\n     upload=URL('download'))\n}}\n\nSQLFORM.grid\nSQLFORM.smartgrid\n\n    SQLTABLE is useful but there are types when one needs more. SQLFORM.grid is an extension of SQLTABLE that creates a table with search features and pagination, as well as ability to open detailed records, create, edit and delete records. SQLFORM.smartgrid is a further generalizaiton that allows all of the above but also creates buttons to access referencing records.\n\nHere is an example of usage of SQLFORM.grid:\n\n1.\n2.\n\n\t\n\ndef index():\n    return dict(grid=SQLFORM.grid(query))\n\nand the corresponding view:\n\n{{extend 'layout.html'}}\n{{=grid}}\n\nSQLFORM.grid and SQLFORM.smartgrid should be preferrable to SQLTABLE because they are more powerful although higher level and therefore more constraining. They will be explained in more detail in chapter 8.\norderby, groupby, limitby, distinct\n\nThe select command takes five optional arguments: orderby, groupby, limitby, left and cache. Here we discuss the first three.\n\nYou can fetch the records sorted by name:\n\norderby\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> for row in db().select(\n        db.person.ALL, orderby=db.person.name):\n        print row.name\nAlex\nBob\nCarl\n\nYou can fetch the records sorted by name in reverse order (notice the tilde):\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> for row in db().select(\n        db.person.ALL, orderby=~db.person.name):\n        print row.name\nCarl\nBob\nAlex\n\nYou can have the fetched records appear in random order:\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> for row in db().select(\n        db.person.ALL, orderby='<random>'):\n        print row.name\nCarl\nAlex\nBob\n\n    The use of orderby='<random>' is not supported on Google NoSQL. However, in this situation and likewise in many others where built-ins are insufficient, imports can be used:\n\n    1.\n    2.\n\n    \t\n\n    import random\n    rows=db(...).select().sort(lambda row: random.random())\n\nAnd you can sort the records according to multiple fields by concatenating them with a \"|\":\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> for row in db().select(\n        db.person.ALL, orderby=db.person.name|db.person.id):\n        print row.name\nCarl\nBob\nAlex\n\nUsing groupby together with orderby, you can group records with the same value for the specified field (this is back-end specific, and is not on the Google NoSQL):\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n\n\t\n\n>>> for row in db().select(\n        db.person.ALL,\n        orderby=db.person.name, groupby=db.person.name):\n        print row.name\nAlex\nBob\nCarl\n\ndistinct\n\nWith the argument distinct=True, you can specify that you only want to select distinct records. This has the same effect as grouping using all specified fields except that it does not require sorting. When using distinct it is important not to select ALL fields, and in particular not to select the \"id\" field, else all records will always be distinct.\n\nHere is an example:\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> for row in db().select(db.person.name, distinct=True):\n        print row.name\nAlex\nBob\nCarl\n\nNotice that distinct can also be an expression for example:\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> for row in db().select(db.person.name,distinct=db.person.name):\n        print row.name\nAlex\nBob\nCarl\n\nWith limitby, you can select a subset of the records (in this case, the first two starting at zero):\n\nlimitby\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> for row in db().select(db.person.ALL, limitby=(0, 2)):\n        print row.name\nAlex\nBob\n\nLogical operators\n\nQueries can be combined using the binary AND operator \"&\":\n\nand\nor\nnot\n\n1.\n2.\n3.\n\n\t\n\n>>> rows = db((db.person.name=='Alex') & (db.person.id>3)).select()\n>>> for row in rows: print row.id, row.name\n4 Alex\n\nand the binary OR operator \"|\":\n\n1.\n2.\n3.\n\n\t\n\n>>> rows = db((db.person.name=='Alex') | (db.person.id>3)).select()\n>>> for row in rows: print row.id, row.name\n1 Alex\n\nYou can negate a query (or sub-query) with the \"!=\" binary operator:\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> rows = db((db.person.name!='Alex') | (db.person.id>3)).select()\n>>> for row in rows: print row.id, row.name\n2 Bob\n3 Carl\n\nor by explicit negation with the \"~\" unary operator:\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> rows = db((~db.person.name=='Alex') | (db.person.id>3)).select()\n>>> for row in rows: print row.id, row.name\n2 Bob\n3 Carl\n\nDue to Python restrictions in overloading \"and\" and \"or\" operators, these cannot be used in forming queries. The binary operators must be used instead.\n\nIt is also possible to build queries using in-place logical operators:\n\n>>> query = db.person.name!='Alex'\n>>> query &= db.person.id>3\n>>> query |= db.person.name=='John'\n\ncount, isempty, delete, update\n\nYou can count records in a set:\n\ncount\nisempty\n\n1.\n2.\n\n\t\n\n>>> print db(db.person.id > 0).count()\n3\n\nNotice that count takes an optional distinct argument which defaults to False, and it works very much like the same argument for select.\n\nSometimes you may need to check is a table is empty. A more efficient way than counting is using the isempty method:\n\n1.\n2.\n\n\t\n\n>>> print db(db.person.id > 0).isempty()\nFalse\n\nor equivalently:\n\n1.\n2.\n\n\t\n\n>>> print db(db.person).isempty()\nFalse\n\nYou can delete records in a set:\n\ndelete\n\n1.\n\n\t\n\n>>> db(db.person.id > 3).delete()\n\nAnd you can update all records in a set by passing named arguments corresponding to the fields that need to be updated:\n\nupdate\n\n1.\n\n\t\n\n>>> db(db.person.id > 3).update(name='Ken')\n\nExpressions\n\nThe value assigned an update statement can be an expression. For example consider this model\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> db.define_table('person',\n        Field('name'),\n        Field('visits', 'integer', default=0))\n>>> db(db.person.name == 'Massimo').update(\n        visits = db.person.visits + 1)\n\nThe values used in queries can also be expressions\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> db.define_table('person',\n        Field('name'),\n        Field('visits', 'integer', default=0),\n        Field('clicks', 'integer', default=0))\n>>> db(db.person.visits == db.person.clicks + 1).delete()\n\nupdate_record\n\nupdate_record\nweb2py also allows updating a single record that is already in memory using update_record\n\n1.\n2.\n\n\t\n\n>>> row = db(db.person.id==2).select().first()\n>>> row.update_record(name='Curt')\n\nupdate_record should not be confused with\n\n1.\n\n\t\n\n>>> row.update(name='Curt')\n\nbecause for a single row, the method update updates the row object but not the database record, as in the case of update_record.\n\nIt is also possible to change the attributes of a row (one at the time) and then call update_record() without arguments to save the changes:\n\n1.\n2.\n3.\n\n\t\n\n>>> row = db(db.person.id > 2).select().first()\n>>> row.name = 'Curt'\n>>> row.update_record() # saves above change\n\nfirst and last\n\nfirst\nlast\n\nGiven a Rows object containing records:\n\n1.\n2.\n3.\n\n\t\n\n>>> rows = db(query).select()\n>>> first_row = rows.first()\n>>> last_row = rows.last()\n\nare equivalent to\n\n1.\n2.\n\n\t\n\n>>> first_row = rows[0] if len(rows)>0 else None\n>>> last_row = rows[-1] if len(rows)>0 else None\n\nas_dict and as_list\n\nas_list\nas_dict\n\nA Row object can be serialized into a regular dictionary using the as_dict() method and a Rows object can be serialized into a list of dictionaries using the as_list() method. Here are some examples:\n\n1.\n2.\n3.\n\n\t\n\n>>> rows = db(query).select()\n>>> rows_list = rows.as_list()\n>>> first_row_dict = rows.first().as_dict()\n\nThese methods are convenient for passing Rows to generic views and or to store Rows in sessions (since Rows objects themselves cannot be serialized since contain a reference to an open DB connection):\n\n1.\n2.\n3.\n\n\t\n\n>>> rows = db(query).select()\n>>> session.rows = rows # not allowed!\n>>> session.rows = rows.as_list() # allowed!\n\nfind, exclude, sort\n\nfind\nexclude\nsort\n\nThere are times when one needs to perform two selects and one contains a subset of a previous select. In this case it is pointless to access the database again. The find, exclude and sort objects allow you to manipulate a Rows objects and generate another one without accessing the database. More specifically:\n\n    find returns a new set of Rows filtered by a condition and leaves the original unchanged.\n    exclude returns a new set of Rows filtered by a condition and removes them from the original Rows.\n    sort returns a new set of Rows sorted by a condition and leaves the original unchanged.\n\nAll these methods take a single argument, a function that acts on each individual row.\n\nHere is an example of usage:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.\n17.\n18.\n19.\n\n\t\n\n>>> db.define_table('person',Field('name'))\n>>> db.person.insert(name='John')\n>>> db.person.insert(name='Max')\n>>> db.person.insert(name='Alex')\n>>> rows = db(db.person).select()\n>>> for row in rows.find(lambda row: row.name[0]=='M'):\n        print row.name\nMax\n>>> print len(rows)\n3\n>>> for row in rows.exclude(lambda row: row.name[0]=='M'):\n        print row.name\nMax\n>>> print len(rows)\n2\n>>> for row in rows.sort(lambda row: row.name):\n        print row.name\nAlex\nJohn\n\nThey can be combined:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n\n\t\n\n>>> rows = db(db.person).select()\n>>> rows = rows.find(\n        lambda row: 'x' in row.name).sort(\n            lambda row: row.name)\n>>> for row in rows:\n        print row.name\nAlex\nMax\n\nOther methods\nupdate_or_insert\nupdate_or_insert\n\nSome times you need to perform an insert only if there is no record with the same values as those being inserted. This can be done with\n\n1.\n2.\n\n\t\n\ndb.define_table('person',Field('name'),Field('birthplace'))\ndb.person.update_or_insert(name='John',birthplace='Chicago')\n\nThe record will be inserted only of there is no other user called John born in Chicago.\n\nYou can specify which values to use as a key to determine if the record exists. For example:\n\n1.\n2.\n\n\t\n\ndb.person.update_or_insert(db.person.name=='John',\n     name='John',birthplace='Chicago')\n\nand if there is John his birthplace will be updated else a new record will be created.\nvalidate_and_insert, validate_and_update\n\nvalidate_and_insert\nvalidate_and_update\n\nThe function\n\n1.\n\n\t\n\nret = db.mytable.validate_and_insert(field='value')\n\nworks very much like\n\n1.\n\n\t\n\nid = db.mytable.insert(field='value')\n\nexcept that it calls the validators for the fields before performing the insert and bails out if the validation does not pass. If validation does not pass the errors can be found in ret.error. If it passes, the id of the new record is in ret.id. Mind that normally validation is done by the form processing logic so this function is rarely needed.\n\nSimilarly\n\n1.\n\n\t\n\nret = db(query).validate_and_update(field='value')\n\nworks very much the same as\n\n1.\n\n\t\n\nnum = db(query).update(field='value')\n\nexcept that it calls the validators for the fields before performing the update. Notice that it only works if query involves a single table. The number of updated records can be found in res.updated and errors will be ret.errors.\nsmart_query (experimental)\n\nThere are times when you need to parse a query using natural language such as\n\nname contain m and age greater than 18\n\nThe DAL provides a method to parse this type of queries:\n\nsearch = 'name contain m and age greater than 18'\nrows = db.smart_query([db.person],search).select()\n\nThe first argument must be a list of tables or fields that should be allowed in the search. It raises a RuntimeError if the search string is invalid. This functionality can be used to build RESTful interfaces (see chapter 10) and it is used internally by the SQLFORM.grid and SQLFORM.smartgrid.\n\nIn the smartquery search string, a field can be identified by fieldname only and or by tablename.fieldname. Strings may be delimited by double quotes if they contain spaces.\nComputed fields\ncompute\n\nDAL fields may have a compute attribute. This must be a function (or lambda) that takes a Row object and returns a value for the field. When a new record is modified, including both insertions and updates, if a value for the field is not provided, web2py tries to compute from the other field values using the compute function. Here is an example:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n\n\t\n\n>>> db.define_table('item',\n        Field('unit_price','double'),\n        Field('quantity','integer'),\n        Field('total_price',\n            compute=lambda r: r['unit_price']*r['quantity']))\n>>> r = db.item.insert(unit_price=1.99, quantity=5)\n>>> print r.total_price\n9.95\n\nNotice that the computed value is stored in the db and it is not computed on retrieval, as in the case of virtual fields, described later. Two typical applications of computed fields are:\n\n    in wiki applications, to store the processed input wiki text as HTML, to avoid re-processing on every request\n    for searching, to compute normalized values for a field, to be used for searching.\n\nVirtual fields\nOld style virtual fields\nvirtualfields\n\nVirtual fields are also computed fields (as in the previous subsection) but they differ from those because they are virtual in the sense that they are not stored in the db and they are computed each time records are extracted from the database. They can be used to simplify the user's code without using additional storage but they cannot be used for searching.\n\nIn order to define one or more virtual fields, you have to define a container class, instantiate it and link it to a table or to a select. For example, consider the following table:\n\n1.\n2.\n3.\n\n\t\n\n>>> db.define_table('item',\n        Field('unit_price','double'),\n        Field('quantity','integer'),\n\nOne can define a total_price virtual field as\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> class MyVirtualFields(object):\n        def total_price(self):\n            return self.item.unit_price*self.item.quantity\n>>> db.item.virtualfields.append(MyVirtualFields())\n\nNotice that each method of the class that takes a single argument (self) is a new virtual field. self refers to each one row of the select. Field values are referred by full path as in self.item.unit_price. The table is linked to the virtual fields by appending an instance of the class to the table's virtualfields attribute.\n\nVirtual fields can also access recursive fields as in\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n\n\t\n\n>>> db.define_table('item',\n        Field('unit_price','double'))\n>>> db.define_table('order_item',\n        Field('item',db.item),\n        Field('quantity','integer'))\n>>> class MyVirtualFields(object):\n        def total_price(self):\n            return self.order_item.item.unit_price \\\n                * self.order_item.quantity\n>>> db.order_item.virtualfields.append(MyVirtualFields())\n\nNotice the recursive field access self.order_item.item.unit_price where self is the looping record.\n\nThey can also act on the result of a JOIN\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n\n\t\n\n>>> db.define_table('item',\n        Field('unit_price','double'))\n>>> db.define_table('order_item',\n        Field('item',db.item),\n        Field('quantity','integer'))\n>>> rows = db(db.order_item.item==db.item.id).select()\n>>> class MyVirtualFields(object):\n        def total_price(self):\n            return self.item.unit_price \\\n                * self.order_item.quantity\n>>> rows.setvirtualfields(order_item=MyVirtualFields())\n>>> for row in rows: print row.order_item.total_price\n\nNotice how in this case the syntax is different. The virtual field accesses both self.item.unit_price and self.order_item.quantity which belong to the join select. The virtual field is attached to the rows of the table using the setvirtualfields method of the rows object. This method takes an arbitrary number of named arguments and can be used to set multiple virtual fields, defined in multiple classes, and attach them to multiple tables:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n\n\t\n\n>>> class MyVirtualFields1(object):\n        def discounted_unit_price(self):\n            return self.item.unit_price*0.90\n>>> class MyVirtualFields2(object):\n        def total_price(self):\n            return self.item.unit_price \\\n                * self.order_item.quantity\n        def discounted_total_price(self):\n            return self.item.discounted_unit_price \\\n                * self.order_item.quantity\n>>> rows.setvirtualfields(\n        item=MyVirtualFields1(),\n        order_item=MyVirtualFields2())\n>>> for row in rows:\n        print row.order_item.discounted_total_price\n\nVirtual fields can be lazy; all they need to do is return a function and access it by calling the function:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n\n\t\n\n>>> db.define_table('item',\n        Field('unit_price','double'),\n        Field('quantity','integer'),\n>>> class MyVirtualFields(object):\n        def lazy_total_price(self):\n            def lazy(self=self):\n                return self.item.unit_price \\\n                    * self.item.quantity\n            return lazy\n>>> db.item.virtualfields.append(MyVirtualFields())\n>>> for item in db(db.item).select():\n        print item.lazy_total_price()\n\nor shorter using a lambda function:\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> class MyVirtualFields(object):\n        def lazy_total_price(self):\n            return lambda self=self: self.item.unit_price \\\n                * self.item.quantity\n\nNew style virtual fields (experimental)\n\nweb2py provides a new and easier way to define virtual fields and lazy virtual fields. This section is marked experimental because they APIs may still change a little from what is described here.\n\nHere we will consider the same example as in the previous subsection. In particular we consider the following model:\n\n1.\n2.\n3.\n\n\t\n\n>>> db.define_table('item',\n        Field('unit_price','double'),\n        Field('quantity','integer'),\n\nOne can define a total_price virtual field as\n\n1.\n\n\t\n\n>>> db.item.total_price = Field.Virtual(lambda row: row.unit_price*row.quantity)\n\ni.e. by simply defining a new field total_price to be a Field.Virtual. The only argument of the constructor is a function that takes a row and returns the computed values.\n\nA virtual field defined as the one above is automatically computed for all records when the records are selected:\n\n>>> for row in db(db.item).select(): print row.total_price\n\nIt is also possible to define lazy virtual fields which are calculated on-demand, when called. For example:\n\n1.\n2.\n\n\t\n\n>>> db.item.total_price = Field.Lazy(lambda row, discount=0.0: \\\n       row.unit_price*row.quantity*(1.0-discount/100))\n\nIn this case row.total_price is not a value but a function. The function takes the same arguments as the function passed to the Lazy constructor except for row which is implicit (think of it as self for rows objects).\n\nThe lazy field in the example above allows one to compute the total price for each item:\n\n>>> for row in db(db.item).select(): print row.total_price()\n\nAnd it also allows to pass an optional discount percentage (15%):\n\n>>> for row in db(db.item).select(): print row.total_price(15)\n\n    Mind that virtual fields do not have the same attributes as the other fields (default, readable, requires, etc) and they do not appear in the list of db.table.fields and are not visualized by default in tables (TABLE) and grids (SQLFORM.grid, SQLFORM.smartgrid).\n\nOne to many relation\none to many\n\nTo illustrate how to implement one to many relations with the web2py DAL, define another table \"dog\" that refers to the table \"person\" which we redefine here:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n\n\t\n\n>>> db.define_table('person',\n                    Field('name'),\n                    format='%(name)s')\n>>> db.define_table('dog',\n                    Field('name'),\n                    Field('owner', db.person),\n                    format='%(name)s')\n\nTable \"dog\" has two fields, the name of the dog and the owner of the dog. When a field type is another table, it is intended that the field reference the other table by its id. In fact, you can print the actual type value and get:\n\n1.\n2.\n\n\t\n\n>>> print db.dog.owner.type\nreference person\n\nNow, insert three dogs, two owned by Alex and one by Bob:\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> db.dog.insert(name='Skipper', owner=1)\n1\n>>> db.dog.insert(name='Snoopy', owner=1)\n2\n>>> db.dog.insert(name='Puppy', owner=2)\n3\n\nYou can select as you did for any other table:\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> for row in db(db.dog.owner==1).select():\n        print row.name\nSkipper\nSnoopy\n\nBecause a dog has a reference to a person, a person can have many dogs, so a record of table person now acquires a new attribute dog, which is a Set, that defines the dogs of that person. This allows looping over all persons and fetching their dogs easily:\n\nreferencing\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n\n\t\n\n>>> for person in db().select(db.person.ALL):\n        print person.name\n        for dog in person.dog.select():\n            print '    ', dog.name\nAlex\n     Skipper\n     Snoopy\nBob\n     Puppy\nCarl\n\nInner joins\n\nAnother way to achieve a similar result is by using a join, specifically an INNER JOIN. web2py performs joins automatically and transparently when the query links two or more tables as in the following example:\n\nRows\ninner join\njoin\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> rows = db(db.person.id==db.dog.owner).select()\n>>> for row in rows:\n        print row.person.name, 'has', row.dog.name\nAlex has Skipper\nAlex has Snoopy\nBob has Puppy\n\nObserve that web2py did a join, so the rows now contain two records, one from each table, linked together. Because the two records may have fields with conflicting names, you need to specify the table when extracting a field value from a row. This means that while before you could do:\n\n1.\n\n\t\n\nrow.name\n\nand it was obvious whether this was the name of a person or a dog, in the result of a join you have to be more explicit and say:\n\n1.\n\n\t\n\nrow.person.name\n\nor:\n\n1.\n\n\t\n\nrow.dog.name\n\nThere is an alterantive syntax for INNER JOINS:\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> rows = db(db.person).select(join=db.dog.on(db.person.id==db.dog.owner))\n>>> for row in rows:\n    print row.person.name, 'has', row.dog.name\nAlex has Skipper\nAlex has Snoopy\nBob has Puppy\n\nWhile the output is the same, the generated SQL in the two cases can be different. The latter syntax removes possible ambiguities when the same table is joined twice and aliased:\n\n>>> db.define_table('dog',\n        Field('name'),\n        Field('owner1',db.person),\n        Field('owner2',db.person))\n>>> rows = db(db.person).select(\n    join=[db.person.with_alias('owner1').on(db.person.id==db.dog.owner1).\n          db.person.with_alias('owner2').on(db.person.id==db.dog.owner2)])\n\nThe value of join can be list of db.table.on(...) to join.\nLeft outer join\n\nNotice that Carl did not appear in the list above because he has no dogs. If you intend to select on persons (whether they have dogs or not) and their dogs (if they have any), then you need to perform a LEFT OUTER JOIN. This is done using the argument \"left\" of the select command. Here is an example:\n\nRows\nleft outer join\nouter join\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n\n\t\n\n>>> rows=db().select(\n        db.person.ALL, db.dog.ALL,\n        left=db.dog.on(db.person.id==db.dog.owner))\n>>> for row in rows:\n        print row.person.name, 'has', row.dog.name\nAlex has Skipper\nAlex has Snoopy\nBob has Puppy\nCarl has None\n\nwhere:\n\n1.\n\n\t\n\nleft = db.dog.on(...)\n\ndoes the left join query. Here the argument of db.dog.on is the condition required for the join (the same used above for the inner join). In the case of a left join, it is necessary to be explicit about which fields to select.\n\nMultiple left joins can be combined by passing a list or tuple of db.mytable.on(...) to the left attribute.\nGrouping and counting\n\nWhen doing joins, sometimes you want to group rows according to certain criteria and count them. For example, count the number of dogs owned by every person. web2py allows this as well. First, you need a count operator. Second, you want to join the person table with the dog table by owner. Third, you want to select all rows (person + dog), group them by person, and count them while grouping:\n\ngrouping\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> count = db.person.id.count()\n>>> for row in db(db.person.id==db.dog.owner).select(\n        db.person.name, count, groupby=db.person.name):\n        print row.person.name, row[count]\nAlex 2\nBob 1\n\nNotice the count operator (which is built-in) is used as a field. The only issue here is in how to retrieve the information. Each row clearly contains a person and the count, but the count is not a field of a person nor is it a table. So where does it go? It goes into the storage object representing the record with a key equal to the query expression itself.\nMany to many\n\nmany-to-many\nIn the previous examples, we allowed a dog to have one owner but one person could have many dogs. What if Skipper was owned by Alex and Curt? This requires a many-to-many relation, and it is realized via an intermediate table that links a person to a dog via an ownership relation.\n\nHere is how to do it:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n\n\t\n\n>>> db.define_table('person',\n                    Field('name'))\n>>> db.define_table('dog',\n                    Field('name'))\n>>> db.define_table('ownership',\n                    Field('person', db.person),\n                    Field('dog', db.dog))\n\nthe existing ownership relationship can now be rewritten as:\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> db.ownership.insert(person=1, dog=1) # Alex owns Skipper\n>>> db.ownership.insert(person=1, dog=2) # Alex owns Snoopy\n>>> db.ownership.insert(person=2, dog=3) # Bob owns Puppy\n\nNow you can add the new relation that Curt co-owns Skipper:\n\n1.\n2.\n\n\t\n\n>>> db.ownership.insert(person=3, dog=1) # Curt owns Skipper too\n\nBecause you now have a three-way relation between tables, it may be convenient to define a new set on which to perform operations:\n\n1.\n2.\n3.\n\n\t\n\n>>> persons_and_dogs = db(\n        (db.person.id==db.ownership.person) \\\n        & (db.dog.id==db.ownership.dog))\n\nNow it is easy to select all persons and their dogs from the new Set:\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> for row in persons_and_dogs.select():\n        print row.person.name, row.dog.name\nAlex Skipper\nAlex Snoopy\nBob Puppy\nCurt Skipper\n\nSimilarly, you can search for all dogs owned by Alex:\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> for row in persons_and_dogs(db.person.name=='Alex').select():\n        print row.dog.name\nSkipper\nSnoopy\n\nand all owners of Skipper:\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> for row in persons_and_dogs(db.dog.name=='Skipper').select():\n        print row.person.name\nAlex\nCurt\n\nA lighter alternative to Many 2 Many relations is tagging. Tagging is discussed in the context of the IS_IN_DB validator. Tagging works even on database backends that do not support JOINs like the Google App Engine NoSQL.\nMany to many, list:<type>, and contains\n\nlist:string\nlist:integer\nlist:reference\ncontains\nmultiple\ntags\n\nweb2py provides the following special field types:\n\n1.\n2.\n3.\n\n\t\n\nlist:string\nlist:integer\nlist:reference <table>\n\nThey can contain lists of strings, of integers and of references respectively.\n\nOn Google App Engine NoSQL list:string is mapped into StringListProperty, the other two are mapped into ListProperty(int). On relational databases they all mapped into text fields which contain the list of items separated by |. For example [1,2,3] is mapped into |1|2|3|.\n\nFor lists of string the items are escaped so that any | in the item is replaced by a ||. Anyway this is an internal representation and it is transparent to the user.\n\nYou can use list:string, for example, in the following way:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n\n\t\n\n>>> db.define_table('product',\n        Field('name'),\n        Field('colors','list:string'))\n>>> db.product.colors.requires=IS_IN_SET(('red','blue','green'))\n>>> db.product.insert(name='Toy Car',colors=['red','green'])\n>>> products = db(db.product.colors.contains('red')).select()\n>>> for item in products:\n        print item.name, item.colors\nToy Car ['red', 'green']\n\nlist:integer works in the same way but the items must be integers.\n\nAs usual the requirements are enforced at the level of forms, not at the level of insert.\n\n    For list:<type> fields the contains(value) operator maps into a non trivial query that checks for lists containing the value. The contains operator also works for regular string and text fields and it maps into a LIKE '%value%'.\n\nThe list:reference and the contains(value) operator are particularly useful to de-normalize many-to-many relations. Here is an example:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n\n\t\n\n>>> db.define_table('tag',Field('name'),format='%(name)s')\n>>> db.define_table('product',\n        Field('name'),\n        Field('tags','list:reference tag'))\n>>> a = db.tag.insert(name='red')\n>>> b = db.tag.insert(name='green')\n>>> c = db.tag.insert(name='blue')\n>>> db.product.insert(name='Toy Car',tags=[a, b, c])\n>>> products = db(db.product.tags.contains(b)).select()\n>>> for item in products:\n        print item.name, item.tags\nToy Car [1, 2, 3]\n>>> for item in products:\n        print item.name, db.product.tags.represent(item.tags)\nToy Car red, green, blue\n\nNotice that a list:reference tag field get a default constraint\n\n1.\n\n\t\n\nrequires = IS_IN_DB(db,'tag.id',db.tag._format,multiple=True)\n\nthat produces a SELECT/OPTION multiple drop-box in forms.\n\nAlso notice that this field gets a default represent attribute which represents the list of references as a comma-separated list of formatted references. This is used in read forms and SQLTABLEs.\n\n    While list:reference has a default validator and a default representation, list:integer and list:string do not. So these two need an IS_IN_SET or an IS_IN_DB validator if you want to use them in forms.\n\nOther operators\n\nweb2py has other operators that provide an API to access equivalent SQL operators. Let's define another table \"log\" to store security events, their event_time and severity, where the severity is an integer number.\n\ndate\ndatetime\ntime\n\n1.\n2.\n3.\n\n\t\n\n>>> db.define_table('log', Field('event'),\n                           Field('event_time', 'datetime'),\n                           Field('severity', 'integer'))\n\nAs before, insert a few events, a \"port scan\", an \"xss injection\" and an \"unauthorized login\". For the sake of the example, you can log events with the same event_time but with different severities (1, 2, 3 respectively).\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n\n\t\n\n>>> import datetime\n>>> now = datetime.datetime.now()\n>>> print db.log.insert(\n        event='port scan', event_time=now, severity=1)\n1\n>>> print db.log.insert(\n        event='xss injection', event_time=now, severity=2)\n2\n>>> print db.log.insert(\n        event='unauthorized login', event_time=now, severity=3)\n3\n\nlike, startswith, contains, upper, lower\n\nlike\nstartswith\ncontains\nupper\nlower\n\nFields have a like operator that you can use to match strings:\n\n1.\n2.\n3.\n\n\t\n\n>>> for row in db(db.log.event.like('port%')).select():\n        print row.event\nport scan\n\nHere \"port%\" indicates a string starting with \"port\". The percent sign character, \"%\", is a wild-card character that means \"any sequence of characters\".\n\nweb2py also provides some shortcuts:\n\n1.\n2.\n\n\t\n\ndb.mytable.myfield.startswith('value')\ndb.mytable.myfield.contains('value')\n\nwhich are equivalent respectively to\n\n1.\n2.\n\n\t\n\ndb.mytable.myfield.like('value%')\ndb.mytable.myfield.like('%value%')\n\nNotice that contains has a special meaning for list:<type> fields and it was discussed in a previous section.\n\nThe contains method can also be passed a list of values and an optional boolean argument all to search for records that contain all values:\n\ndb.mytable.myfield.contains(['value1','value2'], all=True)\n\nor any value from the list\n\ndb.mytable.myfield.contains(['value1','value2'], all=false)\n\nThe upper and lower methods allow you to convert the value of the field to upper or lower case, and you can also combine them with the like operator:\n\nupper\nlower\n\n1.\n2.\n3.\n\n\t\n\n>>> for row in db(db.log.event.upper().like('PORT%')).select():\n        print row.event\nport scan\n\nyear, month, day, hour, minutes, seconds\n\nhour\nminutes\nseconds\nday\nmonth\nyear\n\nThe date and datetime fields have day, month and year methods. The datetime and time fields have hour, minutes and seconds methods. Here is an example:\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> for row in db(db.log.event_time.year()==2009).select():\n        print row.event\nport scan\nxss injection\nunauthorized login\n\nbelongs\n\nThe SQL IN operator is realized via the belongs method which returns true when the field value belongs to the specified set (list of tuples):\n\nbelongs\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> for row in db(db.log.severity.belongs((1, 2))).select():\n        print row.event\nport scan\nxss injection\n\nThe DAL also allows a nested select as the argument of the belongs operator. The only caveat is that the nested select has to be a _select, not a select, and only one field has to be selected explicitly, the one that defines the set.\n\nnested select\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> bad_days = db(db.log.severity==3)._select(db.log.event_time)\n>>> for row in db(db.log.event_time.belongs(bad_days)).select():\n        print row.event\nport scan\nxss injection\nunauthorized login\n\nsum, min, max and len\n\nsum\nmin\nmax\nPreviously, you have used the count operator to count records. Similarly, you can use the sum operator to add (sum) the values of a specific field from a group of records. As in the case of count, the result of a sum is retrieved via the store object:\n\n1.\n2.\n3.\n\n\t\n\n>>> sum = db.log.severity.sum()\n>>> print db().select(sum).first()[sum]\n6\n\nYou can also use min and max to the mininum and maximum value for the selected records\n\n1.\n2.\n3.\n\n\t\n\n>>> max = db.log.severity.max()\n>>> print db().select(max).first()[max]\n3\n\n.len() computes the length of a string, text or boolean fields.\n\nExpressions can be combined to form more complex expressions. For example here we are computing the sum of the length of all the severity strings in the logs, increased of one:\n\n1.\n2.\n\n\t\n\n>>> sum = (db.log.severity.len()+1).sum()\n>>> print db().select(sum).first()[sum]\n\nSubstrings\n\nOne can build an expression to refer to a substring. For example, we can group dogs whose name starts with the same three characters and select only one from each group:\n\n1.\n\n\t\n\ndb(db.dog).select(dictinct = db.dog.name[:3])\n\nDefault values with coalesce and coalesce_zero\n\nThere are times when you need to pull a value from database but also need a default values if the value for a record is set to NULL. In SQL there is a keyword, COALESCE, for this. web2py has an equivalent coalesce method:\n\n>>> db.define_table('sysuser',Field('username'),Field('fullname'))\n>>> db.sysuser.insert(username='max',fullname='Max Power')\n>>> db.sysuser.insert(username='tim',fullname=None)\nprint db(db.sysuser).select(db.sysuser.fullname.coalesce(db.sysuser.username))\n\"COALESCE(sysuser.fullname,sysuser.username)\"\nMax Power\ntim\n\nOther times you need to compute a mathematical expression but some fields have a value set to None while it should be zero. coalesce_zero comes to the rescue by defaulting None to zero in the query:\n\n>>> db.define_table('sysuser',Field('username'),Field('points'))\n>>> db.sysuser.insert(username='max',points=10)\n>>> db.sysuser.insert(username='tim',points=None)\n>>> print db(db.sysuser).select(db.sysuser.points.coalesce_zero().sum())\n\"SUM(COALESCE(sysuser.points,0))\"\n10\n\nGenerating raw sql\nraw SQL\n\nSometimes you need to generate the SQL but not execute it. This is easy to do with web2py since every command that performs database IO has an equivalent command that does not, and simply returns the SQL that would have been executed. These commands have the same names and syntax as the functional ones, but they start with an underscore:\n\nHere is _insert\n_insert\n\n1.\n2.\n\n\t\n\n>>> print db.person._insert(name='Alex')\nINSERT INTO person(name) VALUES ('Alex');\n\nHere is _count\n_count\n\n1.\n2.\n\n\t\n\n>>> print db(db.person.name=='Alex')._count()\nSELECT count(*) FROM person WHERE person.name='Alex';\n\nHere is _select\n_select\n\n1.\n2.\n\n\t\n\n>>> print db(db.person.name=='Alex')._select()\nSELECT person.id, person.name FROM person WHERE person.name='Alex';\n\nHere is _delete\n_delete\n\n1.\n2.\n\n\t\n\n>>> print db(db.person.name=='Alex')._delete()\nDELETE FROM person WHERE person.name='Alex';\n\nAnd finally, here is _update\n_update\n\n1.\n2.\n\n\t\n\n>>> print db(db.person.name=='Alex')._update()\nUPDATE person SET  WHERE person.name='Alex';\n\n    Moreover you can always use db._lastsql to return the most recent SQL code, whether it was executed manually using executesql or was SQL generated by the DAL.\n\nExporting and importing data\n\nexport\nimport\n\nCSV (one Table at a time)\n\nWhen a DALRows object is converted to a string it is automatically serialized in CSV:\n\ncsv\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> rows = db(db.person.id==db.dog.owner).select()\n>>> print rows\nperson.id,person.name,dog.id,dog.name,dog.owner\n1,Alex,1,Skipper,1\n1,Alex,2,Snoopy,1\n2,Bob,3,Puppy,2\n\nYou can serialize a single table in CSV and store it in a file \"test.csv\":\n\n1.\n\n\t\n\n>>> open('test.csv', 'w').write(str(db(db.person.id).select()))\n\nand you can easily read it back with:\n\n1.\n\n\t\n\n>>> db.person.import_from_csv_file(open('test.csv', 'r'))\n\nWhen importing, web2py looks for the field names in the CSV header. In this example, it finds two columns: \"person.id\" and \"person.name\". It ignores the \"person.\" prefix, and it ignores the \"id\" fields. Then all records are appended and assigned new ids. Both of these operations can be performed via the appadmin web interface.\nCSV (all tables at once)\n\nIn web2py, you can backup/restore an entire database with two commands:\n\nTo export:\n\n1.\n\n\t\n\n>>> db.export_to_csv_file(open('somefile.csv', 'wb'))\n\nTo import:\n\n1.\n\n\t\n\n>>> db.import_from_csv_file(open('somefile.csv', 'rb'))\n\nThis mechanism can be used even if the importing database is of a different type than the exporting database. The data is stored in \"somefile.csv\" as a CSV file where each table starts with one line that indicates the tablename, and another line with the fieldnames:\n\n1.\n2.\n\n\t\n\nTABLE tablename\nfield1, field2, field3, ...\n\nTwo tables are separated \\r\\n\\r\\n. The file ends with the line\n\n1.\n\n\t\n\nEND\n\nThe file does not include uploaded files if these are not stored in the database. In any case it is easy enough to zip the \"uploads\" folder separately.\n\nWhen importing, the new records will be appended to the database if it is not empty. In general the new imported records will not have the same record id as the original (saved) records but web2py will restore references so they are not broken, even if the id values may change.\n\nIf a table contains a field called \"uuid\", this field will be used to identify duplicates. Also, if an imported record has the same \"uuid\" as an existing record, the previous record will be updated.\nCSV and remote database synchronization\n\nConsider the following model:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n\n\t\n\ndb = DAL('sqlite:memory:')\ndb.define_table('person',\n    Field('name'),\n    format='%(name)s')\ndb.define_table('dog',\n    Field('owner', db.person),\n    Field('name'),\n    format='%(name)s')\n\nif not db(db.person).count():\n    id = db.person.insert(name=\"Massimo\")\n    db.dog.insert(owner=id, name=\"Snoopy\")\n\nEach record is identified by an ID and referenced by that ID. If you have two copies of the database used by distinct web2py installations, the ID is unique only within each database and not across the databases. This is a problem when merging records from different databases.\n\nIn order to make a record uniquely identifiable across databases, they must:\n\n    have a unique id (UUID),\n    have an event_time (to figure out which one is more recent if multiple copies),\n    reference the UUID instead of the id.\n\nThis can be achieved without modifying web2py. Here is what to do:\n\n1. Change the above model into:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.\n17.\n18.\n19.\n\n\t\n\ndb.define_table('person',\n    Field('uuid', length=64, default=lambda:str(uuid.uuid4())),\n    Field('modified_on', 'datetime', default=now),\n    Field('name'),\n    format='%(name)s')\n\ndb.define_table('dog',\n    Field('uuid', length=64, default=lambda:str(uuid.uuid4())),\n    Field('modified_on', 'datetime', default=now),\n    Field('owner', length=64),\n    Field('name'),\n    format='%(name)s')\n\ndb.dog.owner.requires = IS_IN_DB(db,'person.uuid','%(name)s')\n\nif not db(db.person.id).count():\n    id = uuid.uuid4()\n    db.person.insert(name=\"Massimo\", uuid=id)\n    db.dog.insert(owner=id, name=\"Snoopy\")\n\n    Note, in the above table definitions, the default value for the two 'uuid' fields is set to a lambda function, which returns a UUID (converted to a string). The lambda function is called once for each record inserted, ensuring that each record gets a unique UUID, even if multiple records are inserted in a single transaction.\n\n2. Create a controller action to export the database:\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\ndef export():\n    s = StringIO.StringIO()\n    db.export_to_csv_file(s)\n    response.headers['Content-Type'] = 'text/csv'\n    return s.getvalue()\n\n3. Create a controller action to import a saved copy of the other database and sync records:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n\n\t\n\ndef import_and_sync():\n    form = FORM(INPUT(_type='file', _name='data'), INPUT(_type='submit'))\n    if form.process(session=None).accepted:\n        db.import_from_csv_file(form.vars.data.file,unique=False)\n        # for every table\n        for table in db.tables:\n            # for every uuid, delete all but the latest\n            items = db(db[table]).select(db[table].id,\n                       db[table].uuid,\n                       orderby=db[table].modified_on,\n                       groupby=db[table].uuid)\n            for item in items:\n                db((db[table].uuid==item.uuid)&\\\n                   (db[table].id!=item.id)).delete()\n    return dict(form=form)\n\nNotice that session=None disables the CSRF protection since this URL is intended to be accessed from outside.\n\n4. Create an index manually to make the search by uuid faster.\n\nNotice that steps 2 and 3 work for every database model; they are not specific for this example.\n\nXML-RPC\nAlternatively, you can use XML-RPC to export/import the file.\n\nIf the records reference uploaded files, you also need to export/import the content of the uploads folder. Notice that files therein are already labeled by UUIDs so you do not need to worry about naming conflicts and references.\nHTML and XML (one Table at a time)\n\nDALRows objects\nDALRows objects also have an xml method (like helpers) that serializes it to XML/HTML:\n\nHTML\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.\n17.\n18.\n19.\n20.\n21.\n22.\n23.\n\n\t\n\n>>> rows = db(db.person.id > 0).select()\n>>> print rows.xml()\n<table>\n  <thead>\n    <tr>\n      <th>person.id</th>\n      <th>person.name</th>\n      <th>dog.id</th>\n      <th>dog.name</th>\n      <th>dog.owner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr class=\"even\">\n      <td>1</td>\n      <td>Alex</td>\n      <td>1</td>\n      <td>Skipper</td>\n      <td>1</td>\n    </tr>\n    ...\n  </tbody>\n</table>\n\nDALRows custom tags\nIf you need to serialize the DALRows in any other XML format with custom tags, you can easily do that using the universal TAG helper and the * notation:\nXML\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n\n\t\n\n>>> rows = db(db.person.id > 0).select()\n>>> print TAG.result(*[TAG.row(*[TAG.field(r[f], _name=f) \\\n          for f in db.person.fields]) for r in rows])\n<result>\n  <row>\n    <field name=\"id\">1</field>\n    <field name=\"name\">Alex</field>\n  </row>\n  ...\n</result>\n\nData representation\n\nexport_to_csv_file\nThe export_to_csv_file function accepts a keyword argument named represent. When True it will use the columns represent function while exporting the data instead of the raw data.\n\ncolnames\nThe function also accepts a keyword argument named colnames that should contain a list of column names one wish to export. It defaults to all columns.\n\nBoth export_to_csv_file and import_from_csv_file accept keyword arguments that tell the csv parser the format to save/load the files:\n\n    delimiter: delimiter to separate values (default ',')\n    quotechar: character to use to quote string values (default to double quotes)\n    quoting: quote system (default csv.QUOTE_MINIMAL)\n\nHere is some example usage:\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> import csv\n>>> db.export_to_csv_file(open('/tmp/test.txt', 'w'),\n        delimiter='|',\n        quotechar='\"',\n        quoting=csv.QUOTE_NONNUMERIC)\n\nWhich would render something similar to\n\n1.\n\n\t\n\n\"hello\"|35|\"this is the text description\"|\"2009-03-03\"\n\nFor more information consult the official Python documentation [quoteall]\nCaching selects\n\nThe select method also takes a cache argument, which defaults to None. For caching purposes, it should be set to a tuple where the first element is the cache model (cache.ram, cache.disk, etc.), and the second element is the expiration time in seconds.\n\nIn the following example, you see a controller that caches a select on the previously defined db.log table. The actual select fetches data from the back-end database no more frequently than once every 60 seconds and stores the result in cache.ram. If the next call to this controller occurs in less than 60 seconds since the last database IO, it simply fetches the previous data from cache.ram.\n\ncache select\n\n1.\n2.\n3.\n\n\t\n\ndef cache_db_select():\n    logs = db().select(db.log.ALL, cache=(cache.ram, 60))\n    return dict(logs=logs)\n\n    The results of a select are complex, un-pickleable objects; they cannot be stored in a session and cannot be cached in any other way than the one explained here.\n\nSelf-Reference and aliases\n\nself reference\nalias\nIt is possible to define tables with fields that refer to themselves although the usual notation may fail. The following code would be wrong because it uses a variable db.person before it is defined:\n\n1.\n2.\n3.\n4.\n\n\t\n\ndb.define_table('person',\n    Field('name'),\n    Field('father_id', db.person),\n    Field('mother_id', db.person))\n\nThe solution consists of using an alternate notation\nreference table\n\n1.\n2.\n3.\n4.\n\n\t\n\ndb.define_table('person',\n    Field('name'),\n    Field('father_id', 'reference person'),\n    Field('mother_id', 'reference person'))\n\nIn fact db.tablename and \"reference tablename\" are equivalent field types.\n\nwith_alias\nIf the table refers to itself, then it is not possible to perform a JOIN to select a person and its parents without use of the SQL \"AS\" keyword. This is achieved in web2py using the with_alias. Here is an example:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.\n\n\t\n\n>>> Father = db.person.with_alias('father')\n>>> Mother = db.person.with_alias('mother')\n>>> db.person.insert(name='Massimo')\n1\n>>> db.person.insert(name='Claudia')\n2\n>>> db.person.insert(name='Marco', father_id=1, mother_id=2)\n3\n>>> rows = db().select(db.person.name, Father.name, Mother.name,\n      left=(Father.on(Father.id==db.person.father_id),\n            Mother.on(Mother.id==db.person.mother_id)))\n>>> for row in rows:\n        print row.person.name, row.father.name, row.mother.name\nMassimo None None\nClaudia None None\nMarco Massimo Claudia\n\nNotice that we have chosen to make a distinction between:\n\n    \"father_id\": the field name used in the table \"person\";\n    \"father\": the alias we want to use for the table referenced by the above field; this is communicated to the database;\n    \"Father\": the variable used by web2py to refer to that alias.\n\nThe difference is subtle, and there is nothing wrong in using the same name for the three of them:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.\n17.\n18.\n19.\n20.\n\n\t\n\ndb.define_table('person',\n    Field('name'),\n    Field('father', 'reference person'),\n    Field('mother', 'reference person'))\n>>> father = db.person.with_alias('father')\n>>> mother = db.person.with_alias('mother')\n>>> db.person.insert(name='Massimo')\n1\n>>> db.person.insert(name='Claudia')\n2\n>>> db.person.insert(name='Marco', father=1, mother=2)\n3\n>>> rows = db().select(db.person.name, father.name, mother.name,\n      left=(father.on(father.id==db.person.father),\n            mother.on(mother.id==db.person.mother)))\n>>> for row in rows:\n        print row.person.name, row.father.name, row.mother.name\nMassimo None None\nClaudia None None\nMarco Massimo Claudia\n\nBut it is important to have the distinction clear in order to build correct queries.\nAdvanced features\nTable inheritance\ninheritance\n\nIt is possible to create a table that contains all the fields from another table. It is sufficient to pass the other table in place of a field to define_table. For example\n\n1.\n2.\n\n\t\n\ndb.define_table('person', Field('name'))\ndb.define_table('doctor', db.person, Field('specialization'))\n\ndummy table\nIt is also possible to define a dummy table that is not stored in a database in order to reuse it in multiple other places. For example:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n\n\t\n\nsignature = db.Table(db, 'signature',\n    Field('created_on', 'datetime', default=request.now),\n    Field('created_by', db.auth_user, default=auth.user_id),\n    Field('updated_on', 'datetime', update=request.now),\n    Field('updated_by', db.auth_user, update=auth.user_id))\n\ndb.define_table('payment', Field('amount', 'double'), signature)\n\nThis example assumes that standard web2py authentication is enabled.\n\nNotice that if you user Auth web2py already creates one such table for you:\n\nauth = Auth(db)\ndb.define_table('payment', Field('amount', 'double'), auth.signature)\n\nWhen using table inheritance, if you want the inheriting table to inherit validators, be sure to define the validators of the parent table before defining the inheriting table.\nCommon fields and multi-tenancy\n\ncommon fields\nmulti tenancy\n\ndb._common_fields is a list of fields that should belong to all the tables. This list can also contain tables and it it is understood as all fields from the table. For example occasionally you find yourself in need to add a signature to all your tables but the `auth tables. In this case, after you db.define_tables() but before defining any other table, insert\n\ndb._common_fields.append(auth.signature)\n\nOne field is special: \"request_tenant\". This field does not exist but you can create it and add it to any of your tables (or them all):\n\ndb._common_fields.append(Field('request_tenant',\n    default=request.env.http_host,writable=False))\n\nFor every table with a field called db._request_tenant, all records for all queries are always automatically filtered by:\n\n1.\n\n\t\n\ndb.table.request_tenant == db.table.request_tenant.default\n\nand for every record insert, this field is set to the default value. In the example above we have chosen\n\ndefault = request.env.http_host\n\ni.e. we have chose to ask our app to filter all tables in all queries with\n\ndb.table.request_tenant == request.env.http_host\n\nThis simple trick allow us to turn any application into a multi-tenant application. i.e. even if we run one instance of the app and we use one single database, if the app is accessed under two or more domains (in the example the domain name is retrieved from request.env.http_host) the visitors will see different data depending on the domain. Think of running multiple web stores under different domains with one app and one database.\n\nYou can turn off multi tenancy filters using:\nignore_common_filters\n\n1.\n\n\t\n\nrows = db(query, ignore_common_filters=True).select()\n\nCommon filters\n\nA common filter is a generalization of the above multi-tenancy idea. It provides an easy way to prevent repeating of the same query. Consider for example the following table:\n\ndb.define_table('blog_post',\n    Field('subject'),\n    Field('post_text', 'text'),\n    Field('is_public', 'boolean'),\n    common_filter = lambda query: db.blog_post.is_public==True\n)\n\nAny select, delete or update in this table, will include only public blog posts. The attribute can also be changed in controllers:\n\ndb.blog_post._common_filter = lambda query: db.blog_post.is_public == True\n\nIt serves both as a way to avoid repeating the \"db.blog_post.is_public==True\" phrase in each blog post search, and also as a security enhancement, that prevents you from forgetting to disallow viewing of none public posts.\n\nIn case you actually do want items left out by the common filter (for example, allowing the admin to see none public posts), you can either remove the filter:\n\ndb.blog_post._common_filter = None\n\nor ignore it:\n\ndb(query, ignore_common_filters=True).select(...)\n\nCustom Field types (experimental)\nSQLCustomType\n\nIt is possible to define new/custom field types. For example we consider here the example if a field that contains binary data in compressed form:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n\n\t\n\nfrom gluon.dal import SQLCustomType\nimport zlib\n\ncompressed = SQLCustomType(\n     type ='text',\n     native='text',\n     encoder =(lambda x: zlib.compress(x or '')),\n     decoder = (lambda x: zlib.decompress(x))\n)\n\ndb.define_table('example', Field('data',type=compressed))\n\nSQLCustomType is a field type factory. Its type argument must be one of the standard web2py types. It tells web2py how to treat the field values at the web2py level. native is the name of the field as far as the database is concerned. Allowed names depend on the database engine. encoder is an optional transformation function applied when the data is stored and decoder is the optional reversed transformation function.\n\nThis feature is marked as experimental. In practice is has been in web2py for a long time and it works but it can make the code not portable, for example when the native type is database specific. It does not work on Google App Engine NoSQL.\nUsing DAL without define tables\n\nThe DAL can be used from any Python program simply by doing this:\n\n1.\n2.\n\n\t\n\nfrom gluon import DAL, Field\ndb = DAL('sqlite://storage.sqlite',folder='path/to/app/databases')\n\ni.e. import the DAL, Field, connect and specify the folder which contains the .table files (the app/databases folder).\n\nTo access the data and its attributes we still have to define all the tables we are going to access with db.define_tables(...).\n\nIf we just need access to the data but not to the web2py table attributes, we get away without re-defining the tables but simply asking web2py to read the necessary info from the metadata in the .table files:\n\n1.\n2.\n3.\n\n\t\n\nfrom gluon import DAL, Field\ndb = DAL('sqlite://storage.sqlite',folder='path/to/app/databases',\n         auto_import=True))\n\nThis allows us to access any db.table without need to re-define it.\nCopy data from one db into another\n\nConsider the situation in which you have been using the following database:\n\ndb = DAL('sqlite://storage.sqlite')\n\nand you wish to move to another database using a different connection string:\n\ndb = DAL('postgresql://username:password@hocalhost/mydb')\n\nBefore you switch, you want to move the data and rebuild all the metadata for the new database. We assume the new database to exist but we also assume it is empty.\n\nWeb2py provides a script that does this work for you:\n\ncd web2py\npython scripts/cpdb.py \\\n   -f applications/app/databases \\\n   -y 'sqlite://storage.sqlite' \\\n   -Y 'postgresql://username:password@hocalhost/mydb'\n\nAfter running the script you can simply switch the connection string in the model and everything should work out of the box. The new data should be there.\n\nThis script provides various command line options that allows you to move data from one application to another, move all tables or only some tables, clear the data in the tables. for more info try:\n\npython scripts/cpdb.py -h\n\nNote on new DAL and adapters\n\nThe source code of the Database Abstraction Layer was completely rewritten in 2010. While it stays backward compatible, the rewrite made it more modular and easier to extend. Here we explain the main logic.\n\nThe file \"gluon/dal.py\" defines, among other, the following classes.\n\nConnectionPool\nBaseAdapter extends ConnectionPool\nRow\nDAL\nReference\nTable\nExpression\nField\nQuery\nSet\nRows\n\nTheir use has been explained in the previous sections, except for BaseAdapter. When the methods of a Table or Set object need to communicate with the database they delegate to methods of the adapter the task to generate the SQL and or the function call.\n\nFor example:\n\ndb.myable.insert(myfield='myvalue')\n\ncalls\n\nTable.insert(myfield='myvalue')\n\nwhich delegates the adapter by returning:\n\ndb._adapter.insert(db.mytable,db.mytable._listify(dict(myfield='myvalue')))\n\nHere db.mytable._listify converts the dict of arguments into a list of (field,value) and calls the insert method of the adapter. db._adapter does more or less the following:\n\nquery = db._adapter._insert(db.mytable,list_of_fields)\ndb._adapter.execute(query)\n\nwhere the first line builds the query and the second executes it.\n\nBaseAdapter define the interface for all adapters.\n\n\"gluon/dal.py\" at the moment of writing this book, contains the following adapters:\n\nSQLiteAdapter extends BaseAdapter\nJDBCSQLiteAdapter extends SQLiteAdapter\nMySQLAdapter extends BaseAdapter\nPostgreSQLAdapter extends BaseAdapter\nJDBCPostgreSQLAdapter extends PostgreSQLAdapter\nOracleAdapter extends BaseAdapter\nMSSQLAdapter extends BaseAdapter\nMSSQL2Adapter extends MSSQLAdapter\nFireBirdAdapter extends BaseAdapter\nFireBirdEmbeddedAdapter extends FireBirdAdapter\nInformixAdapter extends BaseAdapter\nDB2Adapter extends BaseAdapter\nIngresAdapter extends BaseAdapter\nIngresUnicodeAdapter extends IngresAdapter\nGoogleSQLAdapter extends MySQLAdapter\nNoSQLAdapter extends BaseAdapter\nGoogleDatastoreAdapter extends NoSQLAdapter\nCubridAdapter extends MySQLAdapter (experimental)\nTeradataAdapter extends DB2Adapter (experimental)\nSAPDBAdapter extends BaseAdapter (experimental)\nCouchDBAdapter extends NoSQLAdapter (experimental)\nMongoDBAdapter extends NoSQLAdapter (experimental)\n\nwhich override the behavior of the BaseAdapter.\n\nEach adapter has more or less this structure:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.\n17.\n18.\n19.\n20.\n21.\n22.\n23.\n24.\n25.\n26.\n27.\n28.\n29.\n30.\n31.\n32.\n33.\n\n\t\n\nclass MySQLAdapter(BaseAdapter):\n\n    # specify a diver to use\n    driver = globals().get('pymysql',None)\n\n    # map web2py types into database types\n    types = {\n        'boolean': 'CHAR(1)',\n        'string': 'VARCHAR(%(length)s)',\n        'text': 'LONGTEXT',\n ...\n        }\n\n    # connect to the database using driver\n    def __init__(self,db,uri,pool_size=0,folder=None,db_codec ='UTF-8',\n                credential_decoder=lambda x:x, driver_args={},\n                adapter_args={}):\n        # parse uri string and store parameters in driver_args\n        ...\n        # define a connection function\n        def connect(driver_args=driver_args):\n            return self.driver.connect(**driver_args)\n        # place it in the pool\n        self.pool_connection(connect)\n        # set optional parameters (after connection)\n        self.execute('SET FOREIGN_KEY_CHECKS=1;')\n        self.execute(\"SET sql_mode='NO_BACKSLASH_ESCAPES';\")\n\n   # override BaseAdapter methods as needed\n   def lastrowid(self,table):\n        self.execute('select last_insert_id();')\n        return int(self.cursor.fetchone()[0])\n\nLooking at the various adapters as examples should be easy to write new ones.\n\nWhen db instance is created:\n\ndb = DAL('mysql://...')\n\nthe prefix in the uri string defines the adapter. The mapping is defined in the following dictionary also in \"gluon/dal.py\":\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.\n17.\n18.\n19.\n20.\n21.\n22.\n23.\n24.\n25.\n26.\n\n\t\n\nADAPTERS = {\n    'sqlite': SQLiteAdapter,\n    'sqlite:memory': SQLiteAdapter,\n    'mysql': MySQLAdapter,\n    'postgres': PostgreSQLAdapter,\n    'oracle': OracleAdapter,\n    'mssql': MSSQLAdapter,\n    'mssql2': MSSQL2Adapter,\n    'db2': DB2Adapter,\n    'teradata': TeradataAdapter,\n    'informix': InformixAdapter,\n    'firebird': FireBirdAdapter,\n    'firebird_embedded': FireBirdAdapter,\n    'ingres': IngresAdapter,\n    'ingresu': IngresUnicodeAdapter,\n    'sapdb': SAPDBAdapter,\n    'cubrid': CubridAdapter,\n    'jdbc:sqlite': JDBCSQLiteAdapter,\n    'jdbc:sqlite:memory': JDBCSQLiteAdapter,\n    'jdbc:postgres': JDBCPostgreSQLAdapter,\n    'gae': GoogleDatastoreAdapter, # discouraged, for backward compatibility\n    'google:datastore': GoogleDatastoreAdapter,\n    'google:sql': GoogleSQLAdapter,\n    'couchdb': CouchDBAdapter,\n    'mongodb': MongoDBAdapter,\n}\n\nthe uri string is then parsed in more detail by the adapter itself.\n\nFor any adapter you can replace the driver with a different one:\n\nfrom gluon.dal import MySQLAdapter\nMySQLAdapter.driver = mysqldb\n\nand you can specify optional driver arguments and adapter arguments:\n\ndb =DAL(..., driver_args={}, adapter_args={})\n\nGotchas\n\nSQLite does not support dropping and altering columns. That means that web2py migrations will work up to a point. If you delete a field from a table, the column will remain in the database but be invisible to web2py. If you decide to re-instate the column, web2py will try re-create it and fail. In this case you must set fake_migrate=True so that metadata is rebuilt without attempting to add the column again. Also, for the same reason, SQLite is not aware of any change of column type. If you insert a number in a string field, it will be stored as string. If you later change the model and replace the type \"string\" with type \"integer\", SQLite will continue to keep the number as a string and this may cause problem when you try to extract the data.\n\nMySQL does not support multiple ALTER TABLE within a single transaction. This means that any migration process is broken into multiple commits. If something happens that causes a failure it is possible to break a migration (the web2py metadata are no-longer in sync with the actual table structure in the database). This is unfortunate but it can be prevented (migrate one table at the time) or it can be fixed a posteriori (revert the web2py model to what corresponds to the table structure in database, set fake_migrate=True and after the metadata has been rebuilt, set fake_migrate=False and migrate the table again).\n\nGoogle SQL has the same problems as MySQL and some more. In particular table metadata itself must be stored in the database in a table that is not migrated by web2py. This is because Google App Engine has a readonly file system. Web2py migrations in Google:SQL combined with the MySQL issue described above can result in metadata corruption. Again this can be prevented (my migrating the table at once and then setting migrate=False so that the metadata table is not accessed any more) or it can fixed a posteriori (my accessing the database using the Google dashboard and deleting any corrupted entry from the table called web2py_filesystem.\n\nMSSQL does not support the SQL OFFSET keyword. Therefore the database cannot do pagination. When doing a limitby=(a,b) web2py will fetch the first b rows and discard the first the a. This may result in a considerable overhead when compared with other database engines.\n\nOracle also does not support pagination. It does not support neither the OFFSET nor the LIMIT keywords. Web2py achieves pagination but translating a db(...).select(limitby=(a,b)) into a complex three-way nested select (as suggested by official Oracle documentation). This works for simple select but may break for complex selects involving alised fields and or joins.\n\nMSSQL has problems with circular references in tables that have ONDELETE CASCADE. This is MSSSQL bug and you work around it by setting the ondelete attribute for all reference fields to \"NO ACTION\". You can also do it once for all before you define tables:\n\n1.\n2.\n3.\n4.\n\n\t\n\ndb = DAL('mssql://....')\nfor key in ['reference','reference FK']:\n    db._adapter.types[key]=db._adapter.types[key].replace(\n        '%(on_delete_action)s','NO ACTION')\n\nMSSQL also has problems with arguments passed to the DISTINCT keyword and therefore while this works,\n\ndb(query).select(distinct=True)\n\nthis does not\n\ndb(query).select(distinct=db.mytable.myfield)\n\nGoogle NoSQL (Datastore) does not allow joins, left joins, aggregates, expression, OR involving more than one table, the like operator and search in \"text\"\" fields. Transactions are limited and not provided automatically by web2py (you need to use the Google API run_in_transaction which you can look up in the Google App Engine documentation online). Google also limits the number of records you can retrieve in each one query (1000 at the time of writing). On the Google datastore record IDs are integer but they are not sequential. While on SQL the \"list:string\" type is mapped into a \"text\" type, on the Google Datastore it is mapped into a ListStringProperty. Similarly \"list:integer\" and \"list:reference\" are mapped into \"ListProperty\". This makes that searches for content inside these fields types are more efficient on Google NoSQL than on SQL databases.\n\n\n\n\n\ndb = DAL('sqlite://xpstorage.sqlite')\n# session.connect(request, response, db = db)\n\ndb.define_table('image',\n    Field('name'),\n    Field('body'))\n\n\n\n\n\ntext = clipboard.get_selection()\n#\nww = \"\"\" %s \"\"\" %text\n\n# fileName = \"/home/tazjel/Dropbox/Wpy_test.py\"\n\n#  system.create_file(fileName, contents= ww)\n\ndb.image.insert(name= ww)\ndb.commit()\n\n# rows=db(db.image.ALL).select(db.image.ALL)\nrows = db().select(db.image.ALL)\nfor row in rows: \n    # www = \"Total :\" + row.name\n    keyboard.send_key(row)    \n    \nkeyboard.send_keys(\"<p>%s</p>\"%www)\n\n# keyboard.send_key(www)    \n\n\n# The following three lines are application-specific and used just so\n# komodo (edit) (or even other IDEs sich as Wing) \"finds\" the methods\n# for my classes, this does not have anyhing to do with the web2py\n# framework itself, as I am already instantiating \"auth_user\",\n# \"stackhelper\" etc in one of my models...\n# from qastack.models import db\n# from qastack.modules.CustomAuthentication import CustomAuthentication \\\n  #   as auth_user\n# from qastack.modules.QAStackHelper import QAStackHelper as stackhelper", 
/home/bani/Dropbox/Inbox/__inboxz/ak/Kubuntu/@AK/wwautokey/autokey.json~:                    "code": "#Enter script code\n# IDE \"helper\" not part of the framework\nimport datetime\nimport hashlib\nimport base64\n\nfrom gluon.contrib.login_methods.email_auth import email_auth\nfrom gluon import *\nfrom gluon.globals import *\nfrom gluon.html import *\nfrom gluon.http import *\nfrom gluon.sqlhtml import SQLFORM, SQLTABLE, form_factory\n# session = Session()\n# request = Request()\n# response = Response()\n\n# stream = open(filename,'rb')\n#  db.myfile.insert(image=db.myfile.image.store(stream,filename))\n\n\n\n# row = db(db.myfile).select().first()\n# filename, stream) = db.myfile.image.retrieve(row.image)\n# import shutil\n#  shutil.copyfileobj(stream,open(filename,'wb'))\n\nQuery, Set, Rows\n\nLet's consider again the table defined (and dropped) previously and insert three records:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n\n\t\n\n>>> db.define_table('person', Field('name'))\n>>> db.person.insert(name=\"Alex\")\n1\n>>> db.person.insert(name=\"Bob\")\n2\n>>> db.person.insert(name=\"Carl\")\n3\n\nYou can store the table in a variable. For example, with variable person, you could do:\n\nTable\n\n1.\n\n\t\n\n>>> person = db.person\n\nYou can also store a field in a variable such as name. For example, you could also do:\n\nField\n\n1.\n\n\t\n\n>>> name = person.name\n\nYou can even build a query (using operators like ==, !=, <, >, <=, >=, like, belongs) and store the query in a variable q such as in:\n\nQuery\n\n1.\n\n\t\n\n>>> q = name=='Alex'\n\nWhen you call db with a query, you define a set of records. You can store it in a variable s and write:\n\nSet\n\n1.\n\n\t\n\n>>> s = db(q)\n\nNotice that no database query has been performed so far. DAL + Query simply define a set of records in this db that match the query. web2py determines from the query which table (or tables) are involved and, in fact, there is no need to specify that.\nselect\n\nGiven a Set, s, you can fetch the records with the command select:\n\nRows\nselect\n\n1.\n\n\t\n\n>>> rows = s.select()\n\nRow\nIt returns an iterable object of class gluon.sql.Rows whose elements are Row objects. gluon.sql.Row objects act like dictionaries, but their elements can also be accessed as attributes, like gluon.storage.Storage.The former differ from the latter because its values are readonly.\n\nThe Rows object allows looping over the result of the select and printing the selected field values for each row:\n\n1.\n2.\n3.\n\n\t\n\n>>> for row in rows:\n        print row.id, row.name\n1 Alex\n\nYou can do all the steps in one statement:\n\n1.\n2.\n3.\n\n\t\n\n>>> for row in db(db.person.name=='Alex').select():\n        print row.name\nAlex\n\nALL\n\nThe select command can take arguments. All unnamed arguments are interpreted as the names of the fields that you want to fetch. For example, you can be explicit on fetching field \"id\" and field \"name\":\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> for row in db().select(db.person.id, db.person.name):\n        print row.name\nAlex\nBob\nCarl\n\nThe table attribute ALL allows you to specify all fields:\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> for row in db().select(db.person.ALL):\n        print row.name\nAlex\nBob\nCarl\n\nNotice that there is no query string passed to db. web2py understands that if you want all fields of the table person without additional information then you want all records of the table person.\n\nAn equivalent alternative syntax is the following:\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> for row in db(db.person.id > 0).select():\n        print row.name\nAlex\nBob\nCarl\n\nand web2py understands that if you ask for all records of the table person (id > 0) without additional information, then you want all the fields of table person.\n\nGiven one row\n\nrow = rows[0]\n\nyou can extract its values using multiple equivalent expressions:\n\n>>> row.name\nAlex\n>>> row['name']\nAlex\n>>> row('person.name')\nAlex\n\nThe latter syntax is particularly handy when selecting en expression instead of a column. We will show this later.\n\nYou can also do\n\nrows.compact = False\n\nto disable the notation\n\nrow[i].name\n\nand enable, instead, the less compact notation:\n\nrow[i].person.name\n\nYes this is unusual and not rarely needed.\n\nShortcuts\nDAL shortcuts\n\nThe DAL supports various code-simplifying shortcuts. In particular:\n\n1.\n\n\t\n\nmyrecord = db.mytable[id]\n\nreturns the record with the given id if it exists. If the id does not exist, it returns None. The above statement is equivalent to\n\n1.\n\n\t\n\nmyrecord = db(db.mytable.id==id).select().first()\n\nYou can delete records by id:\n\n1.\n\n\t\n\ndel db.mytable[id]\n\nand this is equivalent to\n\n1.\n\n\t\n\ndb(db.mytable.id==id).delete()\n\nand deletes the record with the given id, if it exists.\n\nYou can insert records:\n\n1.\n\n\t\n\ndb.mytable[0] = dict(myfield='somevalue')\n\nIt is equivalent to\n\n1.\n\n\t\n\ndb.mytable.insert(myfield='somevalue')\n\nand it creates a new record with field values specified by the dictionary on the right hand side.\n\nYou can update records:\n\n1.\n\n\t\n\ndb.mytable[id] = dict(myfield='somevalue')\n\nwhich is equivalent to\n\n1.\n\n\t\n\ndb(db.mytable.id==id).update(myfield='somevalue')\n\nand it updates an existing record with field values specified by the dictionary on the right hand side.\nFetching a Row\n\nYet another convenient syntax is the following:\n\n1.\n2.\n3.\n\n\t\n\nrecord = db.mytable(id)\nrecord = db.mytable(db.mytable.id==id)\nrecord = db.mytable(id,myfield='somevalue')\n\nApparently similar to db.mytable[id] the above syntax is more flexible and safer. First of all it checks whether id is an int (or str(id) is an int) and returns None if not (it never raises an exception). It also allows to specify multiple conditions that the record must meet. If they are not met, it also returns None.\nRecursive selects\nrecursive selects\n\nConsider the previous table person and a new table \"dog\" referencing a \"person\":\n\n1.\n\n\t\n\n>>> db.define_table('dog', Field('name'), Field('owner',db.person))\n\nand a simple select from this table:\n\n1.\n\n\t\n\n>>> dogs = db(db.dog).select()\n\nwhich is equivalent to\n\n1.\n\n\t\n\n>>> dogs = db(db.dog._id>0).select()\n\nwhere ._id is a reference to the primary key of the table. Normally db.dog._id is the same as db.dog.id and we will assume that in most of this book.\n_id\n\nFor each Row of dogs it is possible to fetch not just fields from the selected table (dog) but also from linked tables (recursively):\n\n1.\n\n\t\n\n>>> for dog in dogs: print dog.name, dog.owner.name\n\nHere dog.owner.name requires one database select for each dog in dogs and it is therefore inefficient. We suggest using joins whenever possible instead of recursive selects, nevertheless this is convenient and practical when accessing individual records.\n\nYou can also do it backwards, by selecting the dogs referenced by a person:\n\n1.\n2.\n3.\n\n\t\n\nperson =  db.person(id)\nfor dog in person.dog.select(orderby=db.dog.name):\n    print person.name, 'owns', dog.name\n\nIn this last expressions person.dog is a shortcut for\n\n1.\n\n\t\n\ndb(db.dog.owner==person.id)\n\ni.e. the Set of dogs referenced by the current person. This syntax breaks down if the referencing table has multiple references to the referenced table. In this case one needs to be more explicit and use a full Query.\nSerializing Rows in views\n\nGiven the following action containing a query\nSQLTABLE\n\n1.\n2.\n\n\t\n\ndef index()\n    return dict(rows = db(query).select())\n\nThe result of a select can be displayed in a view with the following syntax:\n\n1.\n2.\n3.\n\n\t\n\n{{extend 'layout.html'}}\n<h1>Records</h1>\n{{=rows}}\n\nWhich is equivalent to:\n\n1.\n2.\n3.\n\n\t\n\n{{extend 'layout.html'}}\n<h1>Records</h1>\n{{=SQLTABLE(rows)}}\n\nSQLTABLE converts the rows into an HTML table with a header containing the column names and one row per record. The rows are marked as alternating class \"even\" and class \"odd\". Under the hood, Rows is first converted into a SQLTABLE object (not to be confused with Table) and then serialized. The values extracted from the database are also formatted by the validators associated to the field and then escaped. (Note: Using a db in this way in a view is usually not considered good MVC practice.)\n\nYet it is possible and sometimes convenient to call SQLTABLE explicitly.\n\nThe SQLTABLE constructor takes the following optional arguments:\n\n    linkto the URL or an action to be used to link reference fields (default to None)\n    upload the URL or the download action to allow downloading of uploaded files (default to None)\n    headers a dictionary mapping field names to their labels to be used as headers (default to {}). It can also be an instruction. Currently we support headers='fieldname:capitalize'.\n    truncate the number of characters for truncating long values in the table (default is 16)\n    columns the list of fieldnames to be shown as columns (in tablename.fieldname format).\n\nThose not listed are not displayed (defaults to all).\n\n    **attributes generic helper attributes to be passed to the most external TABLE object.\n\nHere is an example:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n\n\t\n\n{{extend 'layout.html'}}\n<h1>Records</h1>\n{{=SQLTABLE(rows,\n     headers='fieldname:capitalize',\n     truncate=100,\n     upload=URL('download'))\n}}\n\nSQLFORM.grid\nSQLFORM.smartgrid\n\n    SQLTABLE is useful but there are types when one needs more. SQLFORM.grid is an extension of SQLTABLE that creates a table with search features and pagination, as well as ability to open detailed records, create, edit and delete records. SQLFORM.smartgrid is a further generalizaiton that allows all of the above but also creates buttons to access referencing records.\n\nHere is an example of usage of SQLFORM.grid:\n\n1.\n2.\n\n\t\n\ndef index():\n    return dict(grid=SQLFORM.grid(query))\n\nand the corresponding view:\n\n{{extend 'layout.html'}}\n{{=grid}}\n\nSQLFORM.grid and SQLFORM.smartgrid should be preferrable to SQLTABLE because they are more powerful although higher level and therefore more constraining. They will be explained in more detail in chapter 8.\norderby, groupby, limitby, distinct\n\nThe select command takes five optional arguments: orderby, groupby, limitby, left and cache. Here we discuss the first three.\n\nYou can fetch the records sorted by name:\n\norderby\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> for row in db().select(\n        db.person.ALL, orderby=db.person.name):\n        print row.name\nAlex\nBob\nCarl\n\nYou can fetch the records sorted by name in reverse order (notice the tilde):\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> for row in db().select(\n        db.person.ALL, orderby=~db.person.name):\n        print row.name\nCarl\nBob\nAlex\n\nYou can have the fetched records appear in random order:\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> for row in db().select(\n        db.person.ALL, orderby='<random>'):\n        print row.name\nCarl\nAlex\nBob\n\n    The use of orderby='<random>' is not supported on Google NoSQL. However, in this situation and likewise in many others where built-ins are insufficient, imports can be used:\n\n    1.\n    2.\n\n    \t\n\n    import random\n    rows=db(...).select().sort(lambda row: random.random())\n\nAnd you can sort the records according to multiple fields by concatenating them with a \"|\":\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> for row in db().select(\n        db.person.ALL, orderby=db.person.name|db.person.id):\n        print row.name\nCarl\nBob\nAlex\n\nUsing groupby together with orderby, you can group records with the same value for the specified field (this is back-end specific, and is not on the Google NoSQL):\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n\n\t\n\n>>> for row in db().select(\n        db.person.ALL,\n        orderby=db.person.name, groupby=db.person.name):\n        print row.name\nAlex\nBob\nCarl\n\ndistinct\n\nWith the argument distinct=True, you can specify that you only want to select distinct records. This has the same effect as grouping using all specified fields except that it does not require sorting. When using distinct it is important not to select ALL fields, and in particular not to select the \"id\" field, else all records will always be distinct.\n\nHere is an example:\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> for row in db().select(db.person.name, distinct=True):\n        print row.name\nAlex\nBob\nCarl\n\nNotice that distinct can also be an expression for example:\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> for row in db().select(db.person.name,distinct=db.person.name):\n        print row.name\nAlex\nBob\nCarl\n\nWith limitby, you can select a subset of the records (in this case, the first two starting at zero):\n\nlimitby\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> for row in db().select(db.person.ALL, limitby=(0, 2)):\n        print row.name\nAlex\nBob\n\nLogical operators\n\nQueries can be combined using the binary AND operator \"&\":\n\nand\nor\nnot\n\n1.\n2.\n3.\n\n\t\n\n>>> rows = db((db.person.name=='Alex') & (db.person.id>3)).select()\n>>> for row in rows: print row.id, row.name\n4 Alex\n\nand the binary OR operator \"|\":\n\n1.\n2.\n3.\n\n\t\n\n>>> rows = db((db.person.name=='Alex') | (db.person.id>3)).select()\n>>> for row in rows: print row.id, row.name\n1 Alex\n\nYou can negate a query (or sub-query) with the \"!=\" binary operator:\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> rows = db((db.person.name!='Alex') | (db.person.id>3)).select()\n>>> for row in rows: print row.id, row.name\n2 Bob\n3 Carl\n\nor by explicit negation with the \"~\" unary operator:\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> rows = db((~db.person.name=='Alex') | (db.person.id>3)).select()\n>>> for row in rows: print row.id, row.name\n2 Bob\n3 Carl\n\nDue to Python restrictions in overloading \"and\" and \"or\" operators, these cannot be used in forming queries. The binary operators must be used instead.\n\nIt is also possible to build queries using in-place logical operators:\n\n>>> query = db.person.name!='Alex'\n>>> query &= db.person.id>3\n>>> query |= db.person.name=='John'\n\ncount, isempty, delete, update\n\nYou can count records in a set:\n\ncount\nisempty\n\n1.\n2.\n\n\t\n\n>>> print db(db.person.id > 0).count()\n3\n\nNotice that count takes an optional distinct argument which defaults to False, and it works very much like the same argument for select.\n\nSometimes you may need to check is a table is empty. A more efficient way than counting is using the isempty method:\n\n1.\n2.\n\n\t\n\n>>> print db(db.person.id > 0).isempty()\nFalse\n\nor equivalently:\n\n1.\n2.\n\n\t\n\n>>> print db(db.person).isempty()\nFalse\n\nYou can delete records in a set:\n\ndelete\n\n1.\n\n\t\n\n>>> db(db.person.id > 3).delete()\n\nAnd you can update all records in a set by passing named arguments corresponding to the fields that need to be updated:\n\nupdate\n\n1.\n\n\t\n\n>>> db(db.person.id > 3).update(name='Ken')\n\nExpressions\n\nThe value assigned an update statement can be an expression. For example consider this model\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> db.define_table('person',\n        Field('name'),\n        Field('visits', 'integer', default=0))\n>>> db(db.person.name == 'Massimo').update(\n        visits = db.person.visits + 1)\n\nThe values used in queries can also be expressions\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> db.define_table('person',\n        Field('name'),\n        Field('visits', 'integer', default=0),\n        Field('clicks', 'integer', default=0))\n>>> db(db.person.visits == db.person.clicks + 1).delete()\n\nupdate_record\n\nupdate_record\nweb2py also allows updating a single record that is already in memory using update_record\n\n1.\n2.\n\n\t\n\n>>> row = db(db.person.id==2).select().first()\n>>> row.update_record(name='Curt')\n\nupdate_record should not be confused with\n\n1.\n\n\t\n\n>>> row.update(name='Curt')\n\nbecause for a single row, the method update updates the row object but not the database record, as in the case of update_record.\n\nIt is also possible to change the attributes of a row (one at the time) and then call update_record() without arguments to save the changes:\n\n1.\n2.\n3.\n\n\t\n\n>>> row = db(db.person.id > 2).select().first()\n>>> row.name = 'Curt'\n>>> row.update_record() # saves above change\n\nfirst and last\n\nfirst\nlast\n\nGiven a Rows object containing records:\n\n1.\n2.\n3.\n\n\t\n\n>>> rows = db(query).select()\n>>> first_row = rows.first()\n>>> last_row = rows.last()\n\nare equivalent to\n\n1.\n2.\n\n\t\n\n>>> first_row = rows[0] if len(rows)>0 else None\n>>> last_row = rows[-1] if len(rows)>0 else None\n\nas_dict and as_list\n\nas_list\nas_dict\n\nA Row object can be serialized into a regular dictionary using the as_dict() method and a Rows object can be serialized into a list of dictionaries using the as_list() method. Here are some examples:\n\n1.\n2.\n3.\n\n\t\n\n>>> rows = db(query).select()\n>>> rows_list = rows.as_list()\n>>> first_row_dict = rows.first().as_dict()\n\nThese methods are convenient for passing Rows to generic views and or to store Rows in sessions (since Rows objects themselves cannot be serialized since contain a reference to an open DB connection):\n\n1.\n2.\n3.\n\n\t\n\n>>> rows = db(query).select()\n>>> session.rows = rows # not allowed!\n>>> session.rows = rows.as_list() # allowed!\n\nfind, exclude, sort\n\nfind\nexclude\nsort\n\nThere are times when one needs to perform two selects and one contains a subset of a previous select. In this case it is pointless to access the database again. The find, exclude and sort objects allow you to manipulate a Rows objects and generate another one without accessing the database. More specifically:\n\n    find returns a new set of Rows filtered by a condition and leaves the original unchanged.\n    exclude returns a new set of Rows filtered by a condition and removes them from the original Rows.\n    sort returns a new set of Rows sorted by a condition and leaves the original unchanged.\n\nAll these methods take a single argument, a function that acts on each individual row.\n\nHere is an example of usage:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.\n17.\n18.\n19.\n\n\t\n\n>>> db.define_table('person',Field('name'))\n>>> db.person.insert(name='John')\n>>> db.person.insert(name='Max')\n>>> db.person.insert(name='Alex')\n>>> rows = db(db.person).select()\n>>> for row in rows.find(lambda row: row.name[0]=='M'):\n        print row.name\nMax\n>>> print len(rows)\n3\n>>> for row in rows.exclude(lambda row: row.name[0]=='M'):\n        print row.name\nMax\n>>> print len(rows)\n2\n>>> for row in rows.sort(lambda row: row.name):\n        print row.name\nAlex\nJohn\n\nThey can be combined:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n\n\t\n\n>>> rows = db(db.person).select()\n>>> rows = rows.find(\n        lambda row: 'x' in row.name).sort(\n            lambda row: row.name)\n>>> for row in rows:\n        print row.name\nAlex\nMax\n\nOther methods\nupdate_or_insert\nupdate_or_insert\n\nSome times you need to perform an insert only if there is no record with the same values as those being inserted. This can be done with\n\n1.\n2.\n\n\t\n\ndb.define_table('person',Field('name'),Field('birthplace'))\ndb.person.update_or_insert(name='John',birthplace='Chicago')\n\nThe record will be inserted only of there is no other user called John born in Chicago.\n\nYou can specify which values to use as a key to determine if the record exists. For example:\n\n1.\n2.\n\n\t\n\ndb.person.update_or_insert(db.person.name=='John',\n     name='John',birthplace='Chicago')\n\nand if there is John his birthplace will be updated else a new record will be created.\nvalidate_and_insert, validate_and_update\n\nvalidate_and_insert\nvalidate_and_update\n\nThe function\n\n1.\n\n\t\n\nret = db.mytable.validate_and_insert(field='value')\n\nworks very much like\n\n1.\n\n\t\n\nid = db.mytable.insert(field='value')\n\nexcept that it calls the validators for the fields before performing the insert and bails out if the validation does not pass. If validation does not pass the errors can be found in ret.error. If it passes, the id of the new record is in ret.id. Mind that normally validation is done by the form processing logic so this function is rarely needed.\n\nSimilarly\n\n1.\n\n\t\n\nret = db(query).validate_and_update(field='value')\n\nworks very much the same as\n\n1.\n\n\t\n\nnum = db(query).update(field='value')\n\nexcept that it calls the validators for the fields before performing the update. Notice that it only works if query involves a single table. The number of updated records can be found in res.updated and errors will be ret.errors.\nsmart_query (experimental)\n\nThere are times when you need to parse a query using natural language such as\n\nname contain m and age greater than 18\n\nThe DAL provides a method to parse this type of queries:\n\nsearch = 'name contain m and age greater than 18'\nrows = db.smart_query([db.person],search).select()\n\nThe first argument must be a list of tables or fields that should be allowed in the search. It raises a RuntimeError if the search string is invalid. This functionality can be used to build RESTful interfaces (see chapter 10) and it is used internally by the SQLFORM.grid and SQLFORM.smartgrid.\n\nIn the smartquery search string, a field can be identified by fieldname only and or by tablename.fieldname. Strings may be delimited by double quotes if they contain spaces.\nComputed fields\ncompute\n\nDAL fields may have a compute attribute. This must be a function (or lambda) that takes a Row object and returns a value for the field. When a new record is modified, including both insertions and updates, if a value for the field is not provided, web2py tries to compute from the other field values using the compute function. Here is an example:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n\n\t\n\n>>> db.define_table('item',\n        Field('unit_price','double'),\n        Field('quantity','integer'),\n        Field('total_price',\n            compute=lambda r: r['unit_price']*r['quantity']))\n>>> r = db.item.insert(unit_price=1.99, quantity=5)\n>>> print r.total_price\n9.95\n\nNotice that the computed value is stored in the db and it is not computed on retrieval, as in the case of virtual fields, described later. Two typical applications of computed fields are:\n\n    in wiki applications, to store the processed input wiki text as HTML, to avoid re-processing on every request\n    for searching, to compute normalized values for a field, to be used for searching.\n\nVirtual fields\nOld style virtual fields\nvirtualfields\n\nVirtual fields are also computed fields (as in the previous subsection) but they differ from those because they are virtual in the sense that they are not stored in the db and they are computed each time records are extracted from the database. They can be used to simplify the user's code without using additional storage but they cannot be used for searching.\n\nIn order to define one or more virtual fields, you have to define a container class, instantiate it and link it to a table or to a select. For example, consider the following table:\n\n1.\n2.\n3.\n\n\t\n\n>>> db.define_table('item',\n        Field('unit_price','double'),\n        Field('quantity','integer'),\n\nOne can define a total_price virtual field as\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> class MyVirtualFields(object):\n        def total_price(self):\n            return self.item.unit_price*self.item.quantity\n>>> db.item.virtualfields.append(MyVirtualFields())\n\nNotice that each method of the class that takes a single argument (self) is a new virtual field. self refers to each one row of the select. Field values are referred by full path as in self.item.unit_price. The table is linked to the virtual fields by appending an instance of the class to the table's virtualfields attribute.\n\nVirtual fields can also access recursive fields as in\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n\n\t\n\n>>> db.define_table('item',\n        Field('unit_price','double'))\n>>> db.define_table('order_item',\n        Field('item',db.item),\n        Field('quantity','integer'))\n>>> class MyVirtualFields(object):\n        def total_price(self):\n            return self.order_item.item.unit_price \\\n                * self.order_item.quantity\n>>> db.order_item.virtualfields.append(MyVirtualFields())\n\nNotice the recursive field access self.order_item.item.unit_price where self is the looping record.\n\nThey can also act on the result of a JOIN\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n\n\t\n\n>>> db.define_table('item',\n        Field('unit_price','double'))\n>>> db.define_table('order_item',\n        Field('item',db.item),\n        Field('quantity','integer'))\n>>> rows = db(db.order_item.item==db.item.id).select()\n>>> class MyVirtualFields(object):\n        def total_price(self):\n            return self.item.unit_price \\\n                * self.order_item.quantity\n>>> rows.setvirtualfields(order_item=MyVirtualFields())\n>>> for row in rows: print row.order_item.total_price\n\nNotice how in this case the syntax is different. The virtual field accesses both self.item.unit_price and self.order_item.quantity which belong to the join select. The virtual field is attached to the rows of the table using the setvirtualfields method of the rows object. This method takes an arbitrary number of named arguments and can be used to set multiple virtual fields, defined in multiple classes, and attach them to multiple tables:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n\n\t\n\n>>> class MyVirtualFields1(object):\n        def discounted_unit_price(self):\n            return self.item.unit_price*0.90\n>>> class MyVirtualFields2(object):\n        def total_price(self):\n            return self.item.unit_price \\\n                * self.order_item.quantity\n        def discounted_total_price(self):\n            return self.item.discounted_unit_price \\\n                * self.order_item.quantity\n>>> rows.setvirtualfields(\n        item=MyVirtualFields1(),\n        order_item=MyVirtualFields2())\n>>> for row in rows:\n        print row.order_item.discounted_total_price\n\nVirtual fields can be lazy; all they need to do is return a function and access it by calling the function:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n\n\t\n\n>>> db.define_table('item',\n        Field('unit_price','double'),\n        Field('quantity','integer'),\n>>> class MyVirtualFields(object):\n        def lazy_total_price(self):\n            def lazy(self=self):\n                return self.item.unit_price \\\n                    * self.item.quantity\n            return lazy\n>>> db.item.virtualfields.append(MyVirtualFields())\n>>> for item in db(db.item).select():\n        print item.lazy_total_price()\n\nor shorter using a lambda function:\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> class MyVirtualFields(object):\n        def lazy_total_price(self):\n            return lambda self=self: self.item.unit_price \\\n                * self.item.quantity\n\nNew style virtual fields (experimental)\n\nweb2py provides a new and easier way to define virtual fields and lazy virtual fields. This section is marked experimental because they APIs may still change a little from what is described here.\n\nHere we will consider the same example as in the previous subsection. In particular we consider the following model:\n\n1.\n2.\n3.\n\n\t\n\n>>> db.define_table('item',\n        Field('unit_price','double'),\n        Field('quantity','integer'),\n\nOne can define a total_price virtual field as\n\n1.\n\n\t\n\n>>> db.item.total_price = Field.Virtual(lambda row: row.unit_price*row.quantity)\n\ni.e. by simply defining a new field total_price to be a Field.Virtual. The only argument of the constructor is a function that takes a row and returns the computed values.\n\nA virtual field defined as the one above is automatically computed for all records when the records are selected:\n\n>>> for row in db(db.item).select(): print row.total_price\n\nIt is also possible to define lazy virtual fields which are calculated on-demand, when called. For example:\n\n1.\n2.\n\n\t\n\n>>> db.item.total_price = Field.Lazy(lambda row, discount=0.0: \\\n       row.unit_price*row.quantity*(1.0-discount/100))\n\nIn this case row.total_price is not a value but a function. The function takes the same arguments as the function passed to the Lazy constructor except for row which is implicit (think of it as self for rows objects).\n\nThe lazy field in the example above allows one to compute the total price for each item:\n\n>>> for row in db(db.item).select(): print row.total_price()\n\nAnd it also allows to pass an optional discount percentage (15%):\n\n>>> for row in db(db.item).select(): print row.total_price(15)\n\n    Mind that virtual fields do not have the same attributes as the other fields (default, readable, requires, etc) and they do not appear in the list of db.table.fields and are not visualized by default in tables (TABLE) and grids (SQLFORM.grid, SQLFORM.smartgrid).\n\nOne to many relation\none to many\n\nTo illustrate how to implement one to many relations with the web2py DAL, define another table \"dog\" that refers to the table \"person\" which we redefine here:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n\n\t\n\n>>> db.define_table('person',\n                    Field('name'),\n                    format='%(name)s')\n>>> db.define_table('dog',\n                    Field('name'),\n                    Field('owner', db.person),\n                    format='%(name)s')\n\nTable \"dog\" has two fields, the name of the dog and the owner of the dog. When a field type is another table, it is intended that the field reference the other table by its id. In fact, you can print the actual type value and get:\n\n1.\n2.\n\n\t\n\n>>> print db.dog.owner.type\nreference person\n\nNow, insert three dogs, two owned by Alex and one by Bob:\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> db.dog.insert(name='Skipper', owner=1)\n1\n>>> db.dog.insert(name='Snoopy', owner=1)\n2\n>>> db.dog.insert(name='Puppy', owner=2)\n3\n\nYou can select as you did for any other table:\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> for row in db(db.dog.owner==1).select():\n        print row.name\nSkipper\nSnoopy\n\nBecause a dog has a reference to a person, a person can have many dogs, so a record of table person now acquires a new attribute dog, which is a Set, that defines the dogs of that person. This allows looping over all persons and fetching their dogs easily:\n\nreferencing\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n\n\t\n\n>>> for person in db().select(db.person.ALL):\n        print person.name\n        for dog in person.dog.select():\n            print '    ', dog.name\nAlex\n     Skipper\n     Snoopy\nBob\n     Puppy\nCarl\n\nInner joins\n\nAnother way to achieve a similar result is by using a join, specifically an INNER JOIN. web2py performs joins automatically and transparently when the query links two or more tables as in the following example:\n\nRows\ninner join\njoin\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> rows = db(db.person.id==db.dog.owner).select()\n>>> for row in rows:\n        print row.person.name, 'has', row.dog.name\nAlex has Skipper\nAlex has Snoopy\nBob has Puppy\n\nObserve that web2py did a join, so the rows now contain two records, one from each table, linked together. Because the two records may have fields with conflicting names, you need to specify the table when extracting a field value from a row. This means that while before you could do:\n\n1.\n\n\t\n\nrow.name\n\nand it was obvious whether this was the name of a person or a dog, in the result of a join you have to be more explicit and say:\n\n1.\n\n\t\n\nrow.person.name\n\nor:\n\n1.\n\n\t\n\nrow.dog.name\n\nThere is an alterantive syntax for INNER JOINS:\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> rows = db(db.person).select(join=db.dog.on(db.person.id==db.dog.owner))\n>>> for row in rows:\n    print row.person.name, 'has', row.dog.name\nAlex has Skipper\nAlex has Snoopy\nBob has Puppy\n\nWhile the output is the same, the generated SQL in the two cases can be different. The latter syntax removes possible ambiguities when the same table is joined twice and aliased:\n\n>>> db.define_table('dog',\n        Field('name'),\n        Field('owner1',db.person),\n        Field('owner2',db.person))\n>>> rows = db(db.person).select(\n    join=[db.person.with_alias('owner1').on(db.person.id==db.dog.owner1).\n          db.person.with_alias('owner2').on(db.person.id==db.dog.owner2)])\n\nThe value of join can be list of db.table.on(...) to join.\nLeft outer join\n\nNotice that Carl did not appear in the list above because he has no dogs. If you intend to select on persons (whether they have dogs or not) and their dogs (if they have any), then you need to perform a LEFT OUTER JOIN. This is done using the argument \"left\" of the select command. Here is an example:\n\nRows\nleft outer join\nouter join\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n\n\t\n\n>>> rows=db().select(\n        db.person.ALL, db.dog.ALL,\n        left=db.dog.on(db.person.id==db.dog.owner))\n>>> for row in rows:\n        print row.person.name, 'has', row.dog.name\nAlex has Skipper\nAlex has Snoopy\nBob has Puppy\nCarl has None\n\nwhere:\n\n1.\n\n\t\n\nleft = db.dog.on(...)\n\ndoes the left join query. Here the argument of db.dog.on is the condition required for the join (the same used above for the inner join). In the case of a left join, it is necessary to be explicit about which fields to select.\n\nMultiple left joins can be combined by passing a list or tuple of db.mytable.on(...) to the left attribute.\nGrouping and counting\n\nWhen doing joins, sometimes you want to group rows according to certain criteria and count them. For example, count the number of dogs owned by every person. web2py allows this as well. First, you need a count operator. Second, you want to join the person table with the dog table by owner. Third, you want to select all rows (person + dog), group them by person, and count them while grouping:\n\ngrouping\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> count = db.person.id.count()\n>>> for row in db(db.person.id==db.dog.owner).select(\n        db.person.name, count, groupby=db.person.name):\n        print row.person.name, row[count]\nAlex 2\nBob 1\n\nNotice the count operator (which is built-in) is used as a field. The only issue here is in how to retrieve the information. Each row clearly contains a person and the count, but the count is not a field of a person nor is it a table. So where does it go? It goes into the storage object representing the record with a key equal to the query expression itself.\nMany to many\n\nmany-to-many\nIn the previous examples, we allowed a dog to have one owner but one person could have many dogs. What if Skipper was owned by Alex and Curt? This requires a many-to-many relation, and it is realized via an intermediate table that links a person to a dog via an ownership relation.\n\nHere is how to do it:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n\n\t\n\n>>> db.define_table('person',\n                    Field('name'))\n>>> db.define_table('dog',\n                    Field('name'))\n>>> db.define_table('ownership',\n                    Field('person', db.person),\n                    Field('dog', db.dog))\n\nthe existing ownership relationship can now be rewritten as:\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> db.ownership.insert(person=1, dog=1) # Alex owns Skipper\n>>> db.ownership.insert(person=1, dog=2) # Alex owns Snoopy\n>>> db.ownership.insert(person=2, dog=3) # Bob owns Puppy\n\nNow you can add the new relation that Curt co-owns Skipper:\n\n1.\n2.\n\n\t\n\n>>> db.ownership.insert(person=3, dog=1) # Curt owns Skipper too\n\nBecause you now have a three-way relation between tables, it may be convenient to define a new set on which to perform operations:\n\n1.\n2.\n3.\n\n\t\n\n>>> persons_and_dogs = db(\n        (db.person.id==db.ownership.person) \\\n        & (db.dog.id==db.ownership.dog))\n\nNow it is easy to select all persons and their dogs from the new Set:\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> for row in persons_and_dogs.select():\n        print row.person.name, row.dog.name\nAlex Skipper\nAlex Snoopy\nBob Puppy\nCurt Skipper\n\nSimilarly, you can search for all dogs owned by Alex:\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> for row in persons_and_dogs(db.person.name=='Alex').select():\n        print row.dog.name\nSkipper\nSnoopy\n\nand all owners of Skipper:\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> for row in persons_and_dogs(db.dog.name=='Skipper').select():\n        print row.person.name\nAlex\nCurt\n\nA lighter alternative to Many 2 Many relations is tagging. Tagging is discussed in the context of the IS_IN_DB validator. Tagging works even on database backends that do not support JOINs like the Google App Engine NoSQL.\nMany to many, list:<type>, and contains\n\nlist:string\nlist:integer\nlist:reference\ncontains\nmultiple\ntags\n\nweb2py provides the following special field types:\n\n1.\n2.\n3.\n\n\t\n\nlist:string\nlist:integer\nlist:reference <table>\n\nThey can contain lists of strings, of integers and of references respectively.\n\nOn Google App Engine NoSQL list:string is mapped into StringListProperty, the other two are mapped into ListProperty(int). On relational databases they all mapped into text fields which contain the list of items separated by |. For example [1,2,3] is mapped into |1|2|3|.\n\nFor lists of string the items are escaped so that any | in the item is replaced by a ||. Anyway this is an internal representation and it is transparent to the user.\n\nYou can use list:string, for example, in the following way:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n\n\t\n\n>>> db.define_table('product',\n        Field('name'),\n        Field('colors','list:string'))\n>>> db.product.colors.requires=IS_IN_SET(('red','blue','green'))\n>>> db.product.insert(name='Toy Car',colors=['red','green'])\n>>> products = db(db.product.colors.contains('red')).select()\n>>> for item in products:\n        print item.name, item.colors\nToy Car ['red', 'green']\n\nlist:integer works in the same way but the items must be integers.\n\nAs usual the requirements are enforced at the level of forms, not at the level of insert.\n\n    For list:<type> fields the contains(value) operator maps into a non trivial query that checks for lists containing the value. The contains operator also works for regular string and text fields and it maps into a LIKE '%value%'.\n\nThe list:reference and the contains(value) operator are particularly useful to de-normalize many-to-many relations. Here is an example:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n\n\t\n\n>>> db.define_table('tag',Field('name'),format='%(name)s')\n>>> db.define_table('product',\n        Field('name'),\n        Field('tags','list:reference tag'))\n>>> a = db.tag.insert(name='red')\n>>> b = db.tag.insert(name='green')\n>>> c = db.tag.insert(name='blue')\n>>> db.product.insert(name='Toy Car',tags=[a, b, c])\n>>> products = db(db.product.tags.contains(b)).select()\n>>> for item in products:\n        print item.name, item.tags\nToy Car [1, 2, 3]\n>>> for item in products:\n        print item.name, db.product.tags.represent(item.tags)\nToy Car red, green, blue\n\nNotice that a list:reference tag field get a default constraint\n\n1.\n\n\t\n\nrequires = IS_IN_DB(db,'tag.id',db.tag._format,multiple=True)\n\nthat produces a SELECT/OPTION multiple drop-box in forms.\n\nAlso notice that this field gets a default represent attribute which represents the list of references as a comma-separated list of formatted references. This is used in read forms and SQLTABLEs.\n\n    While list:reference has a default validator and a default representation, list:integer and list:string do not. So these two need an IS_IN_SET or an IS_IN_DB validator if you want to use them in forms.\n\nOther operators\n\nweb2py has other operators that provide an API to access equivalent SQL operators. Let's define another table \"log\" to store security events, their event_time and severity, where the severity is an integer number.\n\ndate\ndatetime\ntime\n\n1.\n2.\n3.\n\n\t\n\n>>> db.define_table('log', Field('event'),\n                           Field('event_time', 'datetime'),\n                           Field('severity', 'integer'))\n\nAs before, insert a few events, a \"port scan\", an \"xss injection\" and an \"unauthorized login\". For the sake of the example, you can log events with the same event_time but with different severities (1, 2, 3 respectively).\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n\n\t\n\n>>> import datetime\n>>> now = datetime.datetime.now()\n>>> print db.log.insert(\n        event='port scan', event_time=now, severity=1)\n1\n>>> print db.log.insert(\n        event='xss injection', event_time=now, severity=2)\n2\n>>> print db.log.insert(\n        event='unauthorized login', event_time=now, severity=3)\n3\n\nlike, startswith, contains, upper, lower\n\nlike\nstartswith\ncontains\nupper\nlower\n\nFields have a like operator that you can use to match strings:\n\n1.\n2.\n3.\n\n\t\n\n>>> for row in db(db.log.event.like('port%')).select():\n        print row.event\nport scan\n\nHere \"port%\" indicates a string starting with \"port\". The percent sign character, \"%\", is a wild-card character that means \"any sequence of characters\".\n\nweb2py also provides some shortcuts:\n\n1.\n2.\n\n\t\n\ndb.mytable.myfield.startswith('value')\ndb.mytable.myfield.contains('value')\n\nwhich are equivalent respectively to\n\n1.\n2.\n\n\t\n\ndb.mytable.myfield.like('value%')\ndb.mytable.myfield.like('%value%')\n\nNotice that contains has a special meaning for list:<type> fields and it was discussed in a previous section.\n\nThe contains method can also be passed a list of values and an optional boolean argument all to search for records that contain all values:\n\ndb.mytable.myfield.contains(['value1','value2'], all=True)\n\nor any value from the list\n\ndb.mytable.myfield.contains(['value1','value2'], all=false)\n\nThe upper and lower methods allow you to convert the value of the field to upper or lower case, and you can also combine them with the like operator:\n\nupper\nlower\n\n1.\n2.\n3.\n\n\t\n\n>>> for row in db(db.log.event.upper().like('PORT%')).select():\n        print row.event\nport scan\n\nyear, month, day, hour, minutes, seconds\n\nhour\nminutes\nseconds\nday\nmonth\nyear\n\nThe date and datetime fields have day, month and year methods. The datetime and time fields have hour, minutes and seconds methods. Here is an example:\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> for row in db(db.log.event_time.year()==2009).select():\n        print row.event\nport scan\nxss injection\nunauthorized login\n\nbelongs\n\nThe SQL IN operator is realized via the belongs method which returns true when the field value belongs to the specified set (list of tuples):\n\nbelongs\n\n1.\n2.\n3.\n4.\n\n\t\n\n>>> for row in db(db.log.severity.belongs((1, 2))).select():\n        print row.event\nport scan\nxss injection\n\nThe DAL also allows a nested select as the argument of the belongs operator. The only caveat is that the nested select has to be a _select, not a select, and only one field has to be selected explicitly, the one that defines the set.\n\nnested select\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> bad_days = db(db.log.severity==3)._select(db.log.event_time)\n>>> for row in db(db.log.event_time.belongs(bad_days)).select():\n        print row.event\nport scan\nxss injection\nunauthorized login\n\nsum, min, max and len\n\nsum\nmin\nmax\nPreviously, you have used the count operator to count records. Similarly, you can use the sum operator to add (sum) the values of a specific field from a group of records. As in the case of count, the result of a sum is retrieved via the store object:\n\n1.\n2.\n3.\n\n\t\n\n>>> sum = db.log.severity.sum()\n>>> print db().select(sum).first()[sum]\n6\n\nYou can also use min and max to the mininum and maximum value for the selected records\n\n1.\n2.\n3.\n\n\t\n\n>>> max = db.log.severity.max()\n>>> print db().select(max).first()[max]\n3\n\n.len() computes the length of a string, text or boolean fields.\n\nExpressions can be combined to form more complex expressions. For example here we are computing the sum of the length of all the severity strings in the logs, increased of one:\n\n1.\n2.\n\n\t\n\n>>> sum = (db.log.severity.len()+1).sum()\n>>> print db().select(sum).first()[sum]\n\nSubstrings\n\nOne can build an expression to refer to a substring. For example, we can group dogs whose name starts with the same three characters and select only one from each group:\n\n1.\n\n\t\n\ndb(db.dog).select(dictinct = db.dog.name[:3])\n\nDefault values with coalesce and coalesce_zero\n\nThere are times when you need to pull a value from database but also need a default values if the value for a record is set to NULL. In SQL there is a keyword, COALESCE, for this. web2py has an equivalent coalesce method:\n\n>>> db.define_table('sysuser',Field('username'),Field('fullname'))\n>>> db.sysuser.insert(username='max',fullname='Max Power')\n>>> db.sysuser.insert(username='tim',fullname=None)\nprint db(db.sysuser).select(db.sysuser.fullname.coalesce(db.sysuser.username))\n\"COALESCE(sysuser.fullname,sysuser.username)\"\nMax Power\ntim\n\nOther times you need to compute a mathematical expression but some fields have a value set to None while it should be zero. coalesce_zero comes to the rescue by defaulting None to zero in the query:\n\n>>> db.define_table('sysuser',Field('username'),Field('points'))\n>>> db.sysuser.insert(username='max',points=10)\n>>> db.sysuser.insert(username='tim',points=None)\n>>> print db(db.sysuser).select(db.sysuser.points.coalesce_zero().sum())\n\"SUM(COALESCE(sysuser.points,0))\"\n10\n\nGenerating raw sql\nraw SQL\n\nSometimes you need to generate the SQL but not execute it. This is easy to do with web2py since every command that performs database IO has an equivalent command that does not, and simply returns the SQL that would have been executed. These commands have the same names and syntax as the functional ones, but they start with an underscore:\n\nHere is _insert\n_insert\n\n1.\n2.\n\n\t\n\n>>> print db.person._insert(name='Alex')\nINSERT INTO person(name) VALUES ('Alex');\n\nHere is _count\n_count\n\n1.\n2.\n\n\t\n\n>>> print db(db.person.name=='Alex')._count()\nSELECT count(*) FROM person WHERE person.name='Alex';\n\nHere is _select\n_select\n\n1.\n2.\n\n\t\n\n>>> print db(db.person.name=='Alex')._select()\nSELECT person.id, person.name FROM person WHERE person.name='Alex';\n\nHere is _delete\n_delete\n\n1.\n2.\n\n\t\n\n>>> print db(db.person.name=='Alex')._delete()\nDELETE FROM person WHERE person.name='Alex';\n\nAnd finally, here is _update\n_update\n\n1.\n2.\n\n\t\n\n>>> print db(db.person.name=='Alex')._update()\nUPDATE person SET  WHERE person.name='Alex';\n\n    Moreover you can always use db._lastsql to return the most recent SQL code, whether it was executed manually using executesql or was SQL generated by the DAL.\n\nExporting and importing data\n\nexport\nimport\n\nCSV (one Table at a time)\n\nWhen a DALRows object is converted to a string it is automatically serialized in CSV:\n\ncsv\n\n1.\n2.\n3.\n4.\n5.\n6.\n\n\t\n\n>>> rows = db(db.person.id==db.dog.owner).select()\n>>> print rows\nperson.id,person.name,dog.id,dog.name,dog.owner\n1,Alex,1,Skipper,1\n1,Alex,2,Snoopy,1\n2,Bob,3,Puppy,2\n\nYou can serialize a single table in CSV and store it in a file \"test.csv\":\n\n1.\n\n\t\n\n>>> open('test.csv', 'w').write(str(db(db.person.id).select()))\n\nand you can easily read it back with:\n\n1.\n\n\t\n\n>>> db.person.import_from_csv_file(open('test.csv', 'r'))\n\nWhen importing, web2py looks for the field names in the CSV header. In this example, it finds two columns: \"person.id\" and \"person.name\". It ignores the \"person.\" prefix, and it ignores the \"id\" fields. Then all records are appended and assigned new ids. Both of these operations can be performed via the appadmin web interface.\nCSV (all tables at once)\n\nIn web2py, you can backup/restore an entire database with two commands:\n\nTo export:\n\n1.\n\n\t\n\n>>> db.export_to_csv_file(open('somefile.csv', 'wb'))\n\nTo import:\n\n1.\n\n\t\n\n>>> db.import_from_csv_file(open('somefile.csv', 'rb'))\n\nThis mechanism can be used even if the importing database is of a different type than the exporting database. The data is stored in \"somefile.csv\" as a CSV file where each table starts with one line that indicates the tablename, and another line with the fieldnames:\n\n1.\n2.\n\n\t\n\nTABLE tablename\nfield1, field2, field3, ...\n\nTwo tables are separated \\r\\n\\r\\n. The file ends with the line\n\n1.\n\n\t\n\nEND\n\nThe file does not include uploaded files if these are not stored in the database. In any case it is easy enough to zip the \"uploads\" folder separately.\n\nWhen importing, the new records will be appended to the database if it is not empty. In general the new imported records will not have the same record id as the original (saved) records but web2py will restore references so they are not broken, even if the id values may change.\n\nIf a table contains a field called \"uuid\", this field will be used to identify duplicates. Also, if an imported record has the same \"uuid\" as an existing record, the previous record will be updated.\nCSV and remote database synchronization\n\nConsider the following model:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n\n\t\n\ndb = DAL('sqlite:memory:')\ndb.define_table('person',\n    Field('name'),\n    format='%(name)s')\ndb.define_table('dog',\n    Field('owner', db.person),\n    Field('name'),\n    format='%(name)s')\n\nif not db(db.person).count():\n    id = db.person.insert(name=\"Massimo\")\n    db.dog.insert(owner=id, name=\"Snoopy\")\n\nEach record is identified by an ID and referenced by that ID. If you have two copies of the database used by distinct web2py installations, the ID is unique only within each database and not across the databases. This is a problem when merging records from different databases.\n\nIn order to make a record uniquely identifiable across databases, they must:\n\n    have a unique id (UUID),\n    have an event_time (to figure out which one is more recent if multiple copies),\n    reference the UUID instead of the id.\n\nThis can be achieved without modifying web2py. Here is what to do:\n\n1. Change the above model into:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.\n17.\n18.\n19.\n\n\t\n\ndb.define_table('person',\n    Field('uuid', length=64, default=lambda:str(uuid.uuid4())),\n    Field('modified_on', 'datetime', default=now),\n    Field('name'),\n    format='%(name)s')\n\ndb.define_table('dog',\n    Field('uuid', length=64, default=lambda:str(uuid.uuid4())),\n    Field('modified_on', 'datetime', default=now),\n    Field('owner', length=64),\n    Field('name'),\n    format='%(name)s')\n\ndb.dog.owner.requires = IS_IN_DB(db,'person.uuid','%(name)s')\n\nif not db(db.person.id).count():\n    id = uuid.uuid4()\n    db.person.insert(name=\"Massimo\", uuid=id)\n    db.dog.insert(owner=id, name=\"Snoopy\")\n\n    Note, in the above table definitions, the default value for the two 'uuid' fields is set to a lambda function, which returns a UUID (converted to a string). The lambda function is called once for each record inserted, ensuring that each record gets a unique UUID, even if multiple records are inserted in a single transaction.\n\n2. Create a controller action to export the database:\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\ndef export():\n    s = StringIO.StringIO()\n    db.export_to_csv_file(s)\n    response.headers['Content-Type'] = 'text/csv'\n    return s.getvalue()\n\n3. Create a controller action to import a saved copy of the other database and sync records:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n\n\t\n\ndef import_and_sync():\n    form = FORM(INPUT(_type='file', _name='data'), INPUT(_type='submit'))\n    if form.process(session=None).accepted:\n        db.import_from_csv_file(form.vars.data.file,unique=False)\n        # for every table\n        for table in db.tables:\n            # for every uuid, delete all but the latest\n            items = db(db[table]).select(db[table].id,\n                       db[table].uuid,\n                       orderby=db[table].modified_on,\n                       groupby=db[table].uuid)\n            for item in items:\n                db((db[table].uuid==item.uuid)&\\\n                   (db[table].id!=item.id)).delete()\n    return dict(form=form)\n\nNotice that session=None disables the CSRF protection since this URL is intended to be accessed from outside.\n\n4. Create an index manually to make the search by uuid faster.\n\nNotice that steps 2 and 3 work for every database model; they are not specific for this example.\n\nXML-RPC\nAlternatively, you can use XML-RPC to export/import the file.\n\nIf the records reference uploaded files, you also need to export/import the content of the uploads folder. Notice that files therein are already labeled by UUIDs so you do not need to worry about naming conflicts and references.\nHTML and XML (one Table at a time)\n\nDALRows objects\nDALRows objects also have an xml method (like helpers) that serializes it to XML/HTML:\n\nHTML\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.\n17.\n18.\n19.\n20.\n21.\n22.\n23.\n\n\t\n\n>>> rows = db(db.person.id > 0).select()\n>>> print rows.xml()\n<table>\n  <thead>\n    <tr>\n      <th>person.id</th>\n      <th>person.name</th>\n      <th>dog.id</th>\n      <th>dog.name</th>\n      <th>dog.owner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr class=\"even\">\n      <td>1</td>\n      <td>Alex</td>\n      <td>1</td>\n      <td>Skipper</td>\n      <td>1</td>\n    </tr>\n    ...\n  </tbody>\n</table>\n\nDALRows custom tags\nIf you need to serialize the DALRows in any other XML format with custom tags, you can easily do that using the universal TAG helper and the * notation:\nXML\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n\n\t\n\n>>> rows = db(db.person.id > 0).select()\n>>> print TAG.result(*[TAG.row(*[TAG.field(r[f], _name=f) \\\n          for f in db.person.fields]) for r in rows])\n<result>\n  <row>\n    <field name=\"id\">1</field>\n    <field name=\"name\">Alex</field>\n  </row>\n  ...\n</result>\n\nData representation\n\nexport_to_csv_file\nThe export_to_csv_file function accepts a keyword argument named represent. When True it will use the columns represent function while exporting the data instead of the raw data.\n\ncolnames\nThe function also accepts a keyword argument named colnames that should contain a list of column names one wish to export. It defaults to all columns.\n\nBoth export_to_csv_file and import_from_csv_file accept keyword arguments that tell the csv parser the format to save/load the files:\n\n    delimiter: delimiter to separate values (default ',')\n    quotechar: character to use to quote string values (default to double quotes)\n    quoting: quote system (default csv.QUOTE_MINIMAL)\n\nHere is some example usage:\n\n1.\n2.\n3.\n4.\n5.\n\n\t\n\n>>> import csv\n>>> db.export_to_csv_file(open('/tmp/test.txt', 'w'),\n        delimiter='|',\n        quotechar='\"',\n        quoting=csv.QUOTE_NONNUMERIC)\n\nWhich would render something similar to\n\n1.\n\n\t\n\n\"hello\"|35|\"this is the text description\"|\"2009-03-03\"\n\nFor more information consult the official Python documentation [quoteall]\nCaching selects\n\nThe select method also takes a cache argument, which defaults to None. For caching purposes, it should be set to a tuple where the first element is the cache model (cache.ram, cache.disk, etc.), and the second element is the expiration time in seconds.\n\nIn the following example, you see a controller that caches a select on the previously defined db.log table. The actual select fetches data from the back-end database no more frequently than once every 60 seconds and stores the result in cache.ram. If the next call to this controller occurs in less than 60 seconds since the last database IO, it simply fetches the previous data from cache.ram.\n\ncache select\n\n1.\n2.\n3.\n\n\t\n\ndef cache_db_select():\n    logs = db().select(db.log.ALL, cache=(cache.ram, 60))\n    return dict(logs=logs)\n\n    The results of a select are complex, un-pickleable objects; they cannot be stored in a session and cannot be cached in any other way than the one explained here.\n\nSelf-Reference and aliases\n\nself reference\nalias\nIt is possible to define tables with fields that refer to themselves although the usual notation may fail. The following code would be wrong because it uses a variable db.person before it is defined:\n\n1.\n2.\n3.\n4.\n\n\t\n\ndb.define_table('person',\n    Field('name'),\n    Field('father_id', db.person),\n    Field('mother_id', db.person))\n\nThe solution consists of using an alternate notation\nreference table\n\n1.\n2.\n3.\n4.\n\n\t\n\ndb.define_table('person',\n    Field('name'),\n    Field('father_id', 'reference person'),\n    Field('mother_id', 'reference person'))\n\nIn fact db.tablename and \"reference tablename\" are equivalent field types.\n\nwith_alias\nIf the table refers to itself, then it is not possible to perform a JOIN to select a person and its parents without use of the SQL \"AS\" keyword. This is achieved in web2py using the with_alias. Here is an example:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.\n\n\t\n\n>>> Father = db.person.with_alias('father')\n>>> Mother = db.person.with_alias('mother')\n>>> db.person.insert(name='Massimo')\n1\n>>> db.person.insert(name='Claudia')\n2\n>>> db.person.insert(name='Marco', father_id=1, mother_id=2)\n3\n>>> rows = db().select(db.person.name, Father.name, Mother.name,\n      left=(Father.on(Father.id==db.person.father_id),\n            Mother.on(Mother.id==db.person.mother_id)))\n>>> for row in rows:\n        print row.person.name, row.father.name, row.mother.name\nMassimo None None\nClaudia None None\nMarco Massimo Claudia\n\nNotice that we have chosen to make a distinction between:\n\n    \"father_id\": the field name used in the table \"person\";\n    \"father\": the alias we want to use for the table referenced by the above field; this is communicated to the database;\n    \"Father\": the variable used by web2py to refer to that alias.\n\nThe difference is subtle, and there is nothing wrong in using the same name for the three of them:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.\n17.\n18.\n19.\n20.\n\n\t\n\ndb.define_table('person',\n    Field('name'),\n    Field('father', 'reference person'),\n    Field('mother', 'reference person'))\n>>> father = db.person.with_alias('father')\n>>> mother = db.person.with_alias('mother')\n>>> db.person.insert(name='Massimo')\n1\n>>> db.person.insert(name='Claudia')\n2\n>>> db.person.insert(name='Marco', father=1, mother=2)\n3\n>>> rows = db().select(db.person.name, father.name, mother.name,\n      left=(father.on(father.id==db.person.father),\n            mother.on(mother.id==db.person.mother)))\n>>> for row in rows:\n        print row.person.name, row.father.name, row.mother.name\nMassimo None None\nClaudia None None\nMarco Massimo Claudia\n\nBut it is important to have the distinction clear in order to build correct queries.\nAdvanced features\nTable inheritance\ninheritance\n\nIt is possible to create a table that contains all the fields from another table. It is sufficient to pass the other table in place of a field to define_table. For example\n\n1.\n2.\n\n\t\n\ndb.define_table('person', Field('name'))\ndb.define_table('doctor', db.person, Field('specialization'))\n\ndummy table\nIt is also possible to define a dummy table that is not stored in a database in order to reuse it in multiple other places. For example:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n\n\t\n\nsignature = db.Table(db, 'signature',\n    Field('created_on', 'datetime', default=request.now),\n    Field('created_by', db.auth_user, default=auth.user_id),\n    Field('updated_on', 'datetime', update=request.now),\n    Field('updated_by', db.auth_user, update=auth.user_id))\n\ndb.define_table('payment', Field('amount', 'double'), signature)\n\nThis example assumes that standard web2py authentication is enabled.\n\nNotice that if you user Auth web2py already creates one such table for you:\n\nauth = Auth(db)\ndb.define_table('payment', Field('amount', 'double'), auth.signature)\n\nWhen using table inheritance, if you want the inheriting table to inherit validators, be sure to define the validators of the parent table before defining the inheriting table.\nCommon fields and multi-tenancy\n\ncommon fields\nmulti tenancy\n\ndb._common_fields is a list of fields that should belong to all the tables. This list can also contain tables and it it is understood as all fields from the table. For example occasionally you find yourself in need to add a signature to all your tables but the `auth tables. In this case, after you db.define_tables() but before defining any other table, insert\n\ndb._common_fields.append(auth.signature)\n\nOne field is special: \"request_tenant\". This field does not exist but you can create it and add it to any of your tables (or them all):\n\ndb._common_fields.append(Field('request_tenant',\n    default=request.env.http_host,writable=False))\n\nFor every table with a field called db._request_tenant, all records for all queries are always automatically filtered by:\n\n1.\n\n\t\n\ndb.table.request_tenant == db.table.request_tenant.default\n\nand for every record insert, this field is set to the default value. In the example above we have chosen\n\ndefault = request.env.http_host\n\ni.e. we have chose to ask our app to filter all tables in all queries with\n\ndb.table.request_tenant == request.env.http_host\n\nThis simple trick allow us to turn any application into a multi-tenant application. i.e. even if we run one instance of the app and we use one single database, if the app is accessed under two or more domains (in the example the domain name is retrieved from request.env.http_host) the visitors will see different data depending on the domain. Think of running multiple web stores under different domains with one app and one database.\n\nYou can turn off multi tenancy filters using:\nignore_common_filters\n\n1.\n\n\t\n\nrows = db(query, ignore_common_filters=True).select()\n\nCommon filters\n\nA common filter is a generalization of the above multi-tenancy idea. It provides an easy way to prevent repeating of the same query. Consider for example the following table:\n\ndb.define_table('blog_post',\n    Field('subject'),\n    Field('post_text', 'text'),\n    Field('is_public', 'boolean'),\n    common_filter = lambda query: db.blog_post.is_public==True\n)\n\nAny select, delete or update in this table, will include only public blog posts. The attribute can also be changed in controllers:\n\ndb.blog_post._common_filter = lambda query: db.blog_post.is_public == True\n\nIt serves both as a way to avoid repeating the \"db.blog_post.is_public==True\" phrase in each blog post search, and also as a security enhancement, that prevents you from forgetting to disallow viewing of none public posts.\n\nIn case you actually do want items left out by the common filter (for example, allowing the admin to see none public posts), you can either remove the filter:\n\ndb.blog_post._common_filter = None\n\nor ignore it:\n\ndb(query, ignore_common_filters=True).select(...)\n\nCustom Field types (experimental)\nSQLCustomType\n\nIt is possible to define new/custom field types. For example we consider here the example if a field that contains binary data in compressed form:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n\n\t\n\nfrom gluon.dal import SQLCustomType\nimport zlib\n\ncompressed = SQLCustomType(\n     type ='text',\n     native='text',\n     encoder =(lambda x: zlib.compress(x or '')),\n     decoder = (lambda x: zlib.decompress(x))\n)\n\ndb.define_table('example', Field('data',type=compressed))\n\nSQLCustomType is a field type factory. Its type argument must be one of the standard web2py types. It tells web2py how to treat the field values at the web2py level. native is the name of the field as far as the database is concerned. Allowed names depend on the database engine. encoder is an optional transformation function applied when the data is stored and decoder is the optional reversed transformation function.\n\nThis feature is marked as experimental. In practice is has been in web2py for a long time and it works but it can make the code not portable, for example when the native type is database specific. It does not work on Google App Engine NoSQL.\nUsing DAL without define tables\n\nThe DAL can be used from any Python program simply by doing this:\n\n1.\n2.\n\n\t\n\nfrom gluon import DAL, Field\ndb = DAL('sqlite://storage.sqlite',folder='path/to/app/databases')\n\ni.e. import the DAL, Field, connect and specify the folder which contains the .table files (the app/databases folder).\n\nTo access the data and its attributes we still have to define all the tables we are going to access with db.define_tables(...).\n\nIf we just need access to the data but not to the web2py table attributes, we get away without re-defining the tables but simply asking web2py to read the necessary info from the metadata in the .table files:\n\n1.\n2.\n3.\n\n\t\n\nfrom gluon import DAL, Field\ndb = DAL('sqlite://storage.sqlite',folder='path/to/app/databases',\n         auto_import=True))\n\nThis allows us to access any db.table without need to re-define it.\nCopy data from one db into another\n\nConsider the situation in which you have been using the following database:\n\ndb = DAL('sqlite://storage.sqlite')\n\nand you wish to move to another database using a different connection string:\n\ndb = DAL('postgresql://username:password@hocalhost/mydb')\n\nBefore you switch, you want to move the data and rebuild all the metadata for the new database. We assume the new database to exist but we also assume it is empty.\n\nWeb2py provides a script that does this work for you:\n\ncd web2py\npython scripts/cpdb.py \\\n   -f applications/app/databases \\\n   -y 'sqlite://storage.sqlite' \\\n   -Y 'postgresql://username:password@hocalhost/mydb'\n\nAfter running the script you can simply switch the connection string in the model and everything should work out of the box. The new data should be there.\n\nThis script provides various command line options that allows you to move data from one application to another, move all tables or only some tables, clear the data in the tables. for more info try:\n\npython scripts/cpdb.py -h\n\nNote on new DAL and adapters\n\nThe source code of the Database Abstraction Layer was completely rewritten in 2010. While it stays backward compatible, the rewrite made it more modular and easier to extend. Here we explain the main logic.\n\nThe file \"gluon/dal.py\" defines, among other, the following classes.\n\nConnectionPool\nBaseAdapter extends ConnectionPool\nRow\nDAL\nReference\nTable\nExpression\nField\nQuery\nSet\nRows\n\nTheir use has been explained in the previous sections, except for BaseAdapter. When the methods of a Table or Set object need to communicate with the database they delegate to methods of the adapter the task to generate the SQL and or the function call.\n\nFor example:\n\ndb.myable.insert(myfield='myvalue')\n\ncalls\n\nTable.insert(myfield='myvalue')\n\nwhich delegates the adapter by returning:\n\ndb._adapter.insert(db.mytable,db.mytable._listify(dict(myfield='myvalue')))\n\nHere db.mytable._listify converts the dict of arguments into a list of (field,value) and calls the insert method of the adapter. db._adapter does more or less the following:\n\nquery = db._adapter._insert(db.mytable,list_of_fields)\ndb._adapter.execute(query)\n\nwhere the first line builds the query and the second executes it.\n\nBaseAdapter define the interface for all adapters.\n\n\"gluon/dal.py\" at the moment of writing this book, contains the following adapters:\n\nSQLiteAdapter extends BaseAdapter\nJDBCSQLiteAdapter extends SQLiteAdapter\nMySQLAdapter extends BaseAdapter\nPostgreSQLAdapter extends BaseAdapter\nJDBCPostgreSQLAdapter extends PostgreSQLAdapter\nOracleAdapter extends BaseAdapter\nMSSQLAdapter extends BaseAdapter\nMSSQL2Adapter extends MSSQLAdapter\nFireBirdAdapter extends BaseAdapter\nFireBirdEmbeddedAdapter extends FireBirdAdapter\nInformixAdapter extends BaseAdapter\nDB2Adapter extends BaseAdapter\nIngresAdapter extends BaseAdapter\nIngresUnicodeAdapter extends IngresAdapter\nGoogleSQLAdapter extends MySQLAdapter\nNoSQLAdapter extends BaseAdapter\nGoogleDatastoreAdapter extends NoSQLAdapter\nCubridAdapter extends MySQLAdapter (experimental)\nTeradataAdapter extends DB2Adapter (experimental)\nSAPDBAdapter extends BaseAdapter (experimental)\nCouchDBAdapter extends NoSQLAdapter (experimental)\nMongoDBAdapter extends NoSQLAdapter (experimental)\n\nwhich override the behavior of the BaseAdapter.\n\nEach adapter has more or less this structure:\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.\n17.\n18.\n19.\n20.\n21.\n22.\n23.\n24.\n25.\n26.\n27.\n28.\n29.\n30.\n31.\n32.\n33.\n\n\t\n\nclass MySQLAdapter(BaseAdapter):\n\n    # specify a diver to use\n    driver = globals().get('pymysql',None)\n\n    # map web2py types into database types\n    types = {\n        'boolean': 'CHAR(1)',\n        'string': 'VARCHAR(%(length)s)',\n        'text': 'LONGTEXT',\n ...\n        }\n\n    # connect to the database using driver\n    def __init__(self,db,uri,pool_size=0,folder=None,db_codec ='UTF-8',\n                credential_decoder=lambda x:x, driver_args={},\n                adapter_args={}):\n        # parse uri string and store parameters in driver_args\n        ...\n        # define a connection function\n        def connect(driver_args=driver_args):\n            return self.driver.connect(**driver_args)\n        # place it in the pool\n        self.pool_connection(connect)\n        # set optional parameters (after connection)\n        self.execute('SET FOREIGN_KEY_CHECKS=1;')\n        self.execute(\"SET sql_mode='NO_BACKSLASH_ESCAPES';\")\n\n   # override BaseAdapter methods as needed\n   def lastrowid(self,table):\n        self.execute('select last_insert_id();')\n        return int(self.cursor.fetchone()[0])\n\nLooking at the various adapters as examples should be easy to write new ones.\n\nWhen db instance is created:\n\ndb = DAL('mysql://...')\n\nthe prefix in the uri string defines the adapter. The mapping is defined in the following dictionary also in \"gluon/dal.py\":\n\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.\n17.\n18.\n19.\n20.\n21.\n22.\n23.\n24.\n25.\n26.\n\n\t\n\nADAPTERS = {\n    'sqlite': SQLiteAdapter,\n    'sqlite:memory': SQLiteAdapter,\n    'mysql': MySQLAdapter,\n    'postgres': PostgreSQLAdapter,\n    'oracle': OracleAdapter,\n    'mssql': MSSQLAdapter,\n    'mssql2': MSSQL2Adapter,\n    'db2': DB2Adapter,\n    'teradata': TeradataAdapter,\n    'informix': InformixAdapter,\n    'firebird': FireBirdAdapter,\n    'firebird_embedded': FireBirdAdapter,\n    'ingres': IngresAdapter,\n    'ingresu': IngresUnicodeAdapter,\n    'sapdb': SAPDBAdapter,\n    'cubrid': CubridAdapter,\n    'jdbc:sqlite': JDBCSQLiteAdapter,\n    'jdbc:sqlite:memory': JDBCSQLiteAdapter,\n    'jdbc:postgres': JDBCPostgreSQLAdapter,\n    'gae': GoogleDatastoreAdapter, # discouraged, for backward compatibility\n    'google:datastore': GoogleDatastoreAdapter,\n    'google:sql': GoogleSQLAdapter,\n    'couchdb': CouchDBAdapter,\n    'mongodb': MongoDBAdapter,\n}\n\nthe uri string is then parsed in more detail by the adapter itself.\n\nFor any adapter you can replace the driver with a different one:\n\nfrom gluon.dal import MySQLAdapter\nMySQLAdapter.driver = mysqldb\n\nand you can specify optional driver arguments and adapter arguments:\n\ndb =DAL(..., driver_args={}, adapter_args={})\n\nGotchas\n\nSQLite does not support dropping and altering columns. That means that web2py migrations will work up to a point. If you delete a field from a table, the column will remain in the database but be invisible to web2py. If you decide to re-instate the column, web2py will try re-create it and fail. In this case you must set fake_migrate=True so that metadata is rebuilt without attempting to add the column again. Also, for the same reason, SQLite is not aware of any change of column type. If you insert a number in a string field, it will be stored as string. If you later change the model and replace the type \"string\" with type \"integer\", SQLite will continue to keep the number as a string and this may cause problem when you try to extract the data.\n\nMySQL does not support multiple ALTER TABLE within a single transaction. This means that any migration process is broken into multiple commits. If something happens that causes a failure it is possible to break a migration (the web2py metadata are no-longer in sync with the actual table structure in the database). This is unfortunate but it can be prevented (migrate one table at the time) or it can be fixed a posteriori (revert the web2py model to what corresponds to the table structure in database, set fake_migrate=True and after the metadata has been rebuilt, set fake_migrate=False and migrate the table again).\n\nGoogle SQL has the same problems as MySQL and some more. In particular table metadata itself must be stored in the database in a table that is not migrated by web2py. This is because Google App Engine has a readonly file system. Web2py migrations in Google:SQL combined with the MySQL issue described above can result in metadata corruption. Again this can be prevented (my migrating the table at once and then setting migrate=False so that the metadata table is not accessed any more) or it can fixed a posteriori (my accessing the database using the Google dashboard and deleting any corrupted entry from the table called web2py_filesystem.\n\nMSSQL does not support the SQL OFFSET keyword. Therefore the database cannot do pagination. When doing a limitby=(a,b) web2py will fetch the first b rows and discard the first the a. This may result in a considerable overhead when compared with other database engines.\n\nOracle also does not support pagination. It does not support neither the OFFSET nor the LIMIT keywords. Web2py achieves pagination but translating a db(...).select(limitby=(a,b)) into a complex three-way nested select (as suggested by official Oracle documentation). This works for simple select but may break for complex selects involving alised fields and or joins.\n\nMSSQL has problems with circular references in tables that have ONDELETE CASCADE. This is MSSSQL bug and you work around it by setting the ondelete attribute for all reference fields to \"NO ACTION\". You can also do it once for all before you define tables:\n\n1.\n2.\n3.\n4.\n\n\t\n\ndb = DAL('mssql://....')\nfor key in ['reference','reference FK']:\n    db._adapter.types[key]=db._adapter.types[key].replace(\n        '%(on_delete_action)s','NO ACTION')\n\nMSSQL also has problems with arguments passed to the DISTINCT keyword and therefore while this works,\n\ndb(query).select(distinct=True)\n\nthis does not\n\ndb(query).select(distinct=db.mytable.myfield)\n\nGoogle NoSQL (Datastore) does not allow joins, left joins, aggregates, expression, OR involving more than one table, the like operator and search in \"text\"\" fields. Transactions are limited and not provided automatically by web2py (you need to use the Google API run_in_transaction which you can look up in the Google App Engine documentation online). Google also limits the number of records you can retrieve in each one query (1000 at the time of writing). On the Google datastore record IDs are integer but they are not sequential. While on SQL the \"list:string\" type is mapped into a \"text\" type, on the Google Datastore it is mapped into a ListStringProperty. Similarly \"list:integer\" and \"list:reference\" are mapped into \"ListProperty\". This makes that searches for content inside these fields types are more efficient on Google NoSQL than on SQL databases.\n\n\n\n\n\ndb = DAL('sqlite://xpstorage.sqlite')\n# session.connect(request, response, db = db)\n\ndb.define_table('image',\n    Field('name'),\n    Field('body'))\n\n\n\n\n\ntext = clipboard.get_selection()\n#\nww = \"\"\" %s \"\"\" %text\n\n# fileName = \"/home/tazjel/Dropbox/Wpy_test.py\"\n\n#  system.create_file(fileName, contents= ww)\n\ndb.image.insert(name= ww)\ndb.commit()\n\n# rows=db(db.image.ALL).select(db.image.ALL)\nrows = db().select(db.image.ALL)\nfor row in rows: \n    # www = \"Total :\" + row.name\n    keyboard.send_key(row)    \n    \nkeyboard.send_keys(\"<p>%s</p>\"%www)\n\n# keyboard.send_key(www)    \n\n\n# The following three lines are application-specific and used just so\n# komodo (edit) (or even other IDEs sich as Wing) \"finds\" the methods\n# for my classes, this does not have anyhing to do with the web2py\n# framework itself, as I am already instantiating \"auth_user\",\n# \"stackhelper\" etc in one of my models...\n# from qastack.models import db\n# from qastack.modules.CustomAuthentication import CustomAuthentication \\\n  #   as auth_user\n# from qastack.modules.QAStackHelper import QAStackHelper as stackhelper", 
/home/bani/Dropbox/Inbox/__inboxz/ak/Kubuntu/@AK/@FF/Fill profiles/cache.rdf:                   NS1:content="homepage skip to navigation skip to content Package Index Browse packages Package submission List trove classifiers List packages RSS (last 40 updates) Python 3 packages Tutorial Get help Bug reports Comments Developers About News Documentation Download Community Foundation Core Development Links Package Index &gt; zope.mimetype 1.3.1 Not Logged In Login Register Lost Login? Use OpenID Google myOpenID Launchpad zope.mimetype 1.3.1 A simple package for working with MIME content types Downloads ↓ This package provides a way to work with MIME content types. There are several interfaces defined here, many of which are used primarily to look things up based on different bits of information. Contents The Zope MIME Infrastructure Supported lookups Retrieving Content Type Information MIME Types Character Sets Finding Interfaces Codec handling Constraint Functions for Interfaces Single Token MIME Type Minimal IContentInfo Implementation Events and content-type changes MIME type and character set extraction MIME types mimeTypeGetter() mimeTypeGuesser() smartMimeTypeGuesser() charsetGetter() Source for MIME type interfaces TranslatableSourceSelectWidget CHANGES 1.3.1 (2010-11-10) 1.3.0 (2010-06-26) 1.2.0 (2009-12-26) 1.1.2 (2009-05-22) 1.1.1 (2009-04-03) 1.1.0 (2007-11-01) 1.0.0 (2007-??-??) The Zope MIME Infrastructure This package provides a way to work with MIME content types. There are several interfaces defined here, many of which are used primarily to look things up based on different bits of information. The basic idea behind this is that content objects should provide an interface based on the actual content type they implement. For example, objects that represent text/xml or application/xml documents should be marked mark with the IContentTypeXml interface. This can allow additional views to be registered based on the content type, or subscribers may be registered to perform other actions based on the content type. One aspect of the content type that's important for all documents is that the content type interface determines whether the object data is interpreted as an encoded text document. Encoded text documents, in particular, can be decoded to obtain a single Unicode string. The content type intefaces for encoded text must derive from IContentTypeEncoded. (All content type interfaces derive from IContentType and directly provide IContentTypeInterface.) The default configuration provides direct support for a variety of common document types found in office environments. Supported lookups Several different queries are supported by this package: Given a MIME type expressed as a string, the associated interface, if any, can be retrieved using: # `mimeType` is the MIME type as a string interface = queryUtility(IContentTypeInterface, mimeType) Given a charset name, the associated ICodec instance can be retrieved using: # `charsetName` is the charset name as a string codec = queryUtility(ICharsetCodec, charsetName) Given a codec, the preferred charset name can be retrieved using: # `codec` is an `ICodec` instance: charsetName = getUtility(ICodecPreferredCharset, codec.name).name Given any combination of a suggested file name, file data, and content type header, a guess at a reasonable MIME type can be made using: # `filename` is a suggested file name, or None # `data` is uploaded data, or None # `content_type` is a Content-Type header value, or None # mimeType = getUtility(IMimeTypeGetter)( name=filename, data=data, content_type=content_type) Given any combination of a suggested file name, file data, and content type header, a guess at a reasonable charset name can be made using: # `filename` is a suggested file name, or None # `data` is uploaded data, or None # `content_type` is a Content-Type header value, or None # charsetName = getUtility(ICharsetGetter)( name=filename, data=data, content_type=content_type) Retrieving Content Type Information MIME Types We'll start by initializing the interfaces and registrations for the content type interfaces. This is normally done via ZCML. &gt;&gt;&gt; from zope.mimetype import types &gt;&gt;&gt; types.setup() A utility is used to retrieve MIME types. &gt;&gt;&gt; from zope import component &gt;&gt;&gt; from zope.mimetype import typegetter &gt;&gt;&gt; from zope.mimetype.interfaces import IMimeTypeGetter &gt;&gt;&gt; component.provideUtility(typegetter.smartMimeTypeGuesser, ... provides=IMimeTypeGetter) &gt;&gt;&gt; mime_getter = component.getUtility(IMimeTypeGetter) To map a particular file name, file contents, and content type to a MIME type. &gt;&gt;&gt; mime_getter(name='file.txt', data='A text file.', ... content_type='text/plain') 'text/plain' In the default implementation if not enough information is given to discern a MIME type, None is returned. &gt;&gt;&gt; mime_getter() is None True Character Sets A utility is also used to retrieve character sets (charsets). &gt;&gt;&gt; from zope.mimetype.interfaces import ICharsetGetter &gt;&gt;&gt; component.provideUtility(typegetter.charsetGetter, ... provides=ICharsetGetter) &gt;&gt;&gt; charset_getter = component.getUtility(ICharsetGetter) To map a particular file name, file contents, and content type to a charset. &gt;&gt;&gt; charset_getter(name='file.txt', data='This is a text file.', ... content_type='text/plain;charset=ascii') 'ascii' In the default implementation if not enough information is given to discern a charset, None is returned. &gt;&gt;&gt; charset_getter() is None True Finding Interfaces Given a MIME type we need to be able to find the appropriate interface. &gt;&gt;&gt; from zope.mimetype.interfaces import IContentTypeInterface &gt;&gt;&gt; component.getUtility(IContentTypeInterface, name=u'text/plain') &lt;InterfaceClass zope.mimetype.types.IContentTypeTextPlain&gt; It is also possible to enumerate all content type interfaces. &gt;&gt;&gt; utilities = list(component.getUtilitiesFor(IContentTypeInterface)) If you want to find an interface from a MIME string, you can use the utilityies. &gt;&gt;&gt; component.getUtility(IContentTypeInterface, name='text/plain') &lt;InterfaceClass zope.mimetype.types.IContentTypeTextPlain&gt; Codec handling We can create codecs programatically. Codecs are registered as utilities for ICodec with the name of their python codec. &gt;&gt;&gt; from zope import component &gt;&gt;&gt; from zope.mimetype.interfaces import ICodec &gt;&gt;&gt; from zope.mimetype.codec import addCodec &gt;&gt;&gt; sorted(component.getUtilitiesFor(ICodec)) [] &gt;&gt;&gt; addCodec('iso8859-1', 'Western (ISO-8859-1)') &gt;&gt;&gt; codec = component.getUtility(ICodec, name='iso8859-1') &gt;&gt;&gt; codec &lt;zope.mimetype.codec.Codec instance at ...&gt; &gt;&gt;&gt; codec.name 'iso8859-1' &gt;&gt;&gt; addCodec('utf-8', 'Unicode (UTF-8)') &gt;&gt;&gt; codec2 = component.getUtility(ICodec, name='utf-8') We can programmatically add charsets to a given codec. This registers each charset as a named utility for ICharset. It also registers the codec as a utility for ICharsetCodec with the name of the charset. &gt;&gt;&gt; from zope.mimetype.codec import addCharset &gt;&gt;&gt; from zope.mimetype.interfaces import ICharset, ICharsetCodec &gt;&gt;&gt; sorted(component.getUtilitiesFor(ICharset)) [] &gt;&gt;&gt; sorted(component.getUtilitiesFor(ICharsetCodec)) [] &gt;&gt;&gt; addCharset(codec.name, 'latin1') &gt;&gt;&gt; charset = component.getUtility(ICharset, name='latin1') &gt;&gt;&gt; charset &lt;zope.mimetype.codec.Charset instance at ...&gt; &gt;&gt;&gt; charset.name 'latin1' &gt;&gt;&gt; component.getUtility(ICharsetCodec, name='latin1') is codec True When adding a charset we can state that we want that charset to be the preferred charset for its codec. &gt;&gt;&gt; addCharset(codec.name, 'iso8859-1', preferred=True) &gt;&gt;&gt; addCharset(codec2.name, 'utf-8', preferred=True) A codec can have at most one preferred charset. &gt;&gt;&gt; addCharset(codec.name, 'test', preferred=True) Traceback (most recent call last): ... ValueError: Codec already has a preferred charset. Preferred charsets are registered as utilities for ICodecPreferredCharset under the name of the python codec. &gt;&gt;&gt; from zope.mimetype.interfaces import ICodecPreferredCharset &gt;&gt;&gt; preferred = component.getUtility(ICodecPreferredCharset, name='iso8859-1') &gt;&gt;&gt; preferred &lt;zope.mimetype.codec.Charset instance at ...&gt; &gt;&gt;&gt; preferred.name 'iso8859-1' &gt;&gt;&gt; sorted(component.getUtilitiesFor(ICodecPreferredCharset)) [(u'iso8859-1', &lt;zope.mimetype.codec.Charset instance at ...&gt;), (u'utf-8', &lt;zope.mimetype.codec.Charset instance at ...&gt;)] We can look up a codec by the name of its charset: &gt;&gt;&gt; component.getUtility(ICharsetCodec, name='latin1') is codec True &gt;&gt;&gt; component.getUtility(ICharsetCodec, name='utf-8') is codec2 True Or we can look up all codecs: &gt;&gt;&gt; sorted(component.getUtilitiesFor(ICharsetCodec)) [(u'iso8859-1', &lt;zope.mimetype.codec.Codec instance at ...&gt;), (u'latin1', &lt;zope.mimetype.codec.Codec instance at ...&gt;), (u'test', &lt;zope.mimetype.codec.Codec instance at ...&gt;), (u'utf-8', &lt;zope.mimetype.codec.Codec instance at ...&gt;)] Constraint Functions for Interfaces The zope.mimetype.interfaces module defines interfaces that use some helper functions to define constraints on the accepted data. These helpers are used to determine whether values conform to the what's allowed for parts of a MIME type specification and other parts of a Content-Type header as specified in RFC 2045. Single Token The first is the simplest: the tokenConstraint() function returns True if the ASCII string it is passed conforms to the token production in section 5.1 of the RFC. Let's import the function: &gt;&gt;&gt; from zope.mimetype.interfaces import tokenConstraint Typical token are the major and minor parts of the MIME type and the parameter names for the Content-Type header. The function should return True for these values: &gt;&gt;&gt; tokenConstraint(&quot;text&quot;) True &gt;&gt;&gt; tokenConstraint(&quot;plain&quot;) True &gt;&gt;&gt; tokenConstraint(&quot;charset&quot;) True The function should also return True for unusual but otherwise normal token that may be used in some situations: &gt;&gt;&gt; tokenConstraint(&quot;not-your-fathers-token&quot;) True It must also allow extension tokens and vendor-specific tokens: &gt;&gt;&gt; tokenConstraint(&quot;x-magic&quot;) True &gt;&gt;&gt; tokenConstraint(&quot;vnd.zope.special-data&quot;) True Since we expect input handlers to normalize values to lower case, upper case text is not allowed: &gt;&gt;&gt; tokenConstraint(&quot;Text&quot;) False Non-ASCII text is also not allowed: &gt;&gt;&gt; tokenConstraint(&quot;\x80&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;\xC8&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;\xFF&quot;) False Note that lots of characters are allowed in tokens, and there are no constraints that the token &quot;look like&quot; something a person would want to read: &gt;&gt;&gt; tokenConstraint(&quot;.-.-.-.&quot;) True Other characters are disallowed, however, including all forms of whitespace: &gt;&gt;&gt; tokenConstraint(&quot;foo bar&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;foo\tbar&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;foo\nbar&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;foo\rbar&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;foo\x7Fbar&quot;) False Whitespace before or after the token is not accepted either: &gt;&gt;&gt; tokenConstraint(&quot; text&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;plain &quot;) False Other disallowed characters are defined in the tspecials production from the RFC (also in section 5.1): &gt;&gt;&gt; tokenConstraint(&quot;(&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;)&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;&lt;&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;&gt;&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;@&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;,&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;;&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;:&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;\\&quot;) False &gt;&gt;&gt; tokenConstraint('&quot;') False &gt;&gt;&gt; tokenConstraint(&quot;/&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;[&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;]&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;?&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;=&quot;) False A token must contain at least one character, so tokenConstraint() returns false for an empty string: &gt;&gt;&gt; tokenConstraint(&quot;&quot;) False MIME Type A MIME type is specified using two tokens separated by a slash; whitespace between the tokens and the slash must be normalized away in the input handler. The mimeTypeConstraint() function is available to test a normalized MIME type value; let's import that function now: &gt;&gt;&gt; from zope.mimetype.interfaces import mimeTypeConstraint Let's test some common MIME types to make sure the function isn't obviously insane: &gt;&gt;&gt; mimeTypeConstraint(&quot;text/plain&quot;) True &gt;&gt;&gt; mimeTypeConstraint(&quot;application/xml&quot;) True &gt;&gt;&gt; mimeTypeConstraint(&quot;image/svg+xml&quot;) True If parts of the MIME type are missing, it isn't accepted: &gt;&gt;&gt; mimeTypeConstraint(&quot;text&quot;) False &gt;&gt;&gt; mimeTypeConstraint(&quot;text/&quot;) False &gt;&gt;&gt; mimeTypeConstraint(&quot;/plain&quot;) False As for individual tokens, whitespace is not allowed: &gt;&gt;&gt; mimeTypeConstraint(&quot;foo bar/plain&quot;) False &gt;&gt;&gt; mimeTypeConstraint(&quot;text/foo bar&quot;) False Whitespace is not accepted around the slash either: &gt;&gt;&gt; mimeTypeConstraint(&quot;text /plain&quot;) False &gt;&gt;&gt; mimeTypeConstraint(&quot;text/ plain&quot;) False Surrounding whitespace is also not accepted: &gt;&gt;&gt; mimeTypeConstraint(&quot; text/plain&quot;) False &gt;&gt;&gt; mimeTypeConstraint(&quot;text/plain &quot;) False Minimal IContentInfo Implementation The zope.mimetype.contentinfo module provides a minimal IContentInfo implementation that adds no information to what's provided by a content object. This represents the most conservative content-type policy that might be useful. Let's take a look at how this operates by creating a couple of concrete content-type interfaces: &gt;&gt;&gt; from zope.mimetype import interfaces &gt;&gt;&gt; class ITextPlain(interfaces.IContentTypeEncoded): ... &quot;&quot;&quot;text/plain&quot;&quot;&quot; &gt;&gt;&gt; class IApplicationOctetStream(interfaces.IContentType): ... &quot;&quot;&quot;application/octet-stream&quot;&quot;&quot; Now, we'll create a minimal content object that provide the necessary information: &gt;&gt;&gt; import zope.interface &gt;&gt;&gt; class Content(object): ... zope.interface.implements(interfaces.IContentTypeAware) ... ... def __init__(self, mimeType, charset=None): ... self.mimeType = mimeType ... self.parameters = {} ... if charset: ... self.parameters[&quot;charset&quot;] = charset We can now create examples of both encoded and non-encoded content: &gt;&gt;&gt; encoded = Content(&quot;text/plain&quot;, &quot;utf-8&quot;) &gt;&gt;&gt; zope.interface.alsoProvides(encoded, ITextPlain) &gt;&gt;&gt; unencoded = Content(&quot;application/octet-stream&quot;) &gt;&gt;&gt; zope.interface.alsoProvides(unencoded, IApplicationOctetStream) The minimal IContentInfo implementation only exposes the information available to it from the base content object. Let's take a look at the unencoded content first: &gt;&gt;&gt; from zope.mimetype import contentinfo &gt;&gt;&gt; ci = contentinfo.ContentInfo(unencoded) &gt;&gt;&gt; ci.effectiveMimeType 'application/octet-stream' &gt;&gt;&gt; ci.effectiveParameters {} &gt;&gt;&gt; ci.contentType 'application/octet-stream' For unencoded content, there is never a codec: &gt;&gt;&gt; print ci.getCodec() None It is also disallowed to try decoding such content: &gt;&gt;&gt; ci.decode(&quot;foo&quot;) Traceback (most recent call last): ... ValueError: no matching codec found Attemping to decode data using an uncoded object causes an exception to be raised: &gt;&gt;&gt; print ci.decode(&quot;data&quot;) Traceback (most recent call last): ... ValueError: no matching codec found If we try this with encoded data, we get somewhat different behavior: &gt;&gt;&gt; ci = contentinfo.ContentInfo(encoded) &gt;&gt;&gt; ci.effectiveMimeType 'text/plain' &gt;&gt;&gt; ci.effectiveParameters {'charset': 'utf-8'} &gt;&gt;&gt; ci.contentType 'text/plain;charset=utf-8' The getCodec() and decode() methods can be used to handle encoded data using the encoding indicated by the charset parameter. Let's store some UTF-8 data in a variable: &gt;&gt;&gt; utf8_data = unicode(&quot;\xAB\xBB&quot;, &quot;iso-8859-1&quot;).encode(&quot;utf-8&quot;) &gt;&gt;&gt; utf8_data '\xc2\xab\xc2\xbb' We want to be able to decode the data using the IContentInfo object. Let's try getting the corresponding ICodec object using getCodec(): &gt;&gt;&gt; codec = ci.getCodec() Traceback (most recent call last): ... ValueError: unsupported charset: 'utf-8' So, we can't proceed without some further preparation. What we need is to register an ICharset for UTF-8. The ICharset will need a reference (by name) to a ICodec for UTF-8. So let's create those objects and register them: &gt;&gt;&gt; import codecs &gt;&gt;&gt; from zope.mimetype.i18n import _ &gt;&gt;&gt; class Utf8Codec(object): ... zope.interface.implements(interfaces.ICodec) ... ... name = &quot;utf-8&quot; ... title = _(&quot;UTF-8&quot;) ... ... def __init__(self): ... ( self.encode, ... self.decode, ... self.reader, ... self.writer ... ) = codecs.lookup(self.name) &gt;&gt;&gt; utf8_codec = Utf8Codec() &gt;&gt;&gt; class Utf8Charset(object): ... zope.interface.implements(interfaces.ICharset) ... ... name = utf8_codec.name ... encoding = name &gt;&gt;&gt; utf8_charset = Utf8Charset() &gt;&gt;&gt; import zope.component &gt;&gt;&gt; zope.component.provideUtility( ... utf8_codec, interfaces.ICodec, utf8_codec.name) &gt;&gt;&gt; zope.component.provideUtility( ... utf8_charset, interfaces.ICharset, utf8_charset.name) Now that that's been initialized, let's try getting the codec again: &gt;&gt;&gt; codec = ci.getCodec() &gt;&gt;&gt; codec.name 'utf-8' &gt;&gt;&gt; codec.decode(utf8_data) (u'\xab\xbb', 4) We can now check that the decode() method of the IContentInfo will decode the entire data, returning the Unicode representation of the text: &gt;&gt;&gt; ci.decode(utf8_data) u'\xab\xbb' Another possibilty, of course, is that you have content that you know is encoded text of some sort, but you don't actually know what encoding it's in: &gt;&gt;&gt; encoded2 = Content(&quot;text/plain&quot;) &gt;&gt;&gt; zope.interface.alsoProvides(encoded2, ITextPlain) &gt;&gt;&gt; ci = contentinfo.ContentInfo(encoded2) &gt;&gt;&gt; ci.effectiveMimeType 'text/plain' &gt;&gt;&gt; ci.effectiveParameters {} &gt;&gt;&gt; ci.contentType 'text/plain' &gt;&gt;&gt; ci.getCodec() Traceback (most recent call last): ... ValueError: charset not known It's also possible that the initial content type information for an object is incorrect for some reason. If the browser provides a content type of &quot;text/plain; charset=utf-8&quot;, the content will be seen as encoded. A user correcting this content type using UI elements can cause the content to be considered un-encoded. At this point, there should no longer be a charset parameter to the content type, and the content info object should reflect this, though the previous encoding information will be retained in case the content type should be changed to an encoded type in the future. Let's see how this behavior will be exhibited in this API. We'll start by creating some encoded content: &gt;&gt;&gt; content = Content(&quot;text/plain&quot;, &quot;utf-8&quot;) &gt;&gt;&gt; zope.interface.alsoProvides(content, ITextPlain) We can see that the encoding information is included in the effective MIME type information provided by the content-info object: &gt;&gt;&gt; ci = contentinfo.ContentInfo(content) &gt;&gt;&gt; ci.effectiveMimeType 'text/plain' &gt;&gt;&gt; ci.effectiveParameters {'charset': 'utf-8'} We now change the content type information for the object: &gt;&gt;&gt; ifaces = zope.interface.directlyProvidedBy(content) &gt;&gt;&gt; ifaces -= ITextPlain &gt;&gt;&gt; ifaces += IApplicationOctetStream &gt;&gt;&gt; zope.interface.directlyProvides(content, *ifaces) &gt;&gt;&gt; content.mimeType = 'application/octet-stream' At this point, a content type object would provide different information: &gt;&gt;&gt; ci = contentinfo.ContentInfo(content) &gt;&gt;&gt; ci.effectiveMimeType 'application/octet-stream' &gt;&gt;&gt; ci.effectiveParameters {} The underlying content type parameters still contain the original encoding information, however: &gt;&gt;&gt; content.parameters {'charset': 'utf-8'} Events and content-type changes The IContentTypeChangedEvent is fired whenever an object's IContentTypeInterface is changed. This includes the cases when a content type interface is applied to an object that doesn't have one, and when the content type interface is removed from an object. Let's start the demonstration by defining a subscriber for the event that simply prints out the information from the event object: &gt;&gt;&gt; def handler(event): ... print &quot;changed content type interface:&quot; ... print &quot; from:&quot;, event.oldContentType ... print &quot; to:&quot;, event.newContentType We'll also define a simple content object: &gt;&gt;&gt; import zope.interface &gt;&gt;&gt; class IContent(zope.interface.Interface): ... pass &gt;&gt;&gt; class Content(object): ... ... zope.interface.implements(IContent) ... ... def __str__(self): ... return &quot;&lt;MyContent&gt;&quot; &gt;&gt;&gt; obj = Content() We'll also need a couple of content type interfaces: &gt;&gt;&gt; from zope.mimetype import interfaces &gt;&gt;&gt; class ITextPlain(interfaces.IContentTypeEncoded): ... &quot;&quot;&quot;text/plain&quot;&quot;&quot; &gt;&gt;&gt; ITextPlain.setTaggedValue(&quot;mimeTypes&quot;, [&quot;text/plain&quot;]) &gt;&gt;&gt; ITextPlain.setTaggedValue(&quot;extensions&quot;, [&quot;.txt&quot;]) &gt;&gt;&gt; zope.interface.directlyProvides( ... ITextPlain, interfaces.IContentTypeInterface) &gt;&gt;&gt; class IOctetStream(interfaces.IContentType): ... &quot;&quot;&quot;application/octet-stream&quot;&quot;&quot; &gt;&gt;&gt; IOctetStream.setTaggedValue(&quot;mimeTypes&quot;, [&quot;application/octet-stream&quot;]) &gt;&gt;&gt; IOctetStream.setTaggedValue(&quot;extensions&quot;, [&quot;.bin&quot;]) &gt;&gt;&gt; zope.interface.directlyProvides( ... IOctetStream, interfaces.IContentTypeInterface) Let's register our subscriber: &gt;&gt;&gt; import zope.component &gt;&gt;&gt; import zope.component.interfaces &gt;&gt;&gt; zope.component.provideHandler( ... handler, ... (zope.component.interfaces.IObjectEvent,)) Changing the content type interface on an object is handled by the zope.mimetype.event.changeContentType() function. Let's import that module and demonstrate that the expected event is fired appropriately: &gt;&gt;&gt; from zope.mimetype import event Since the object currently has no content type interface, &quot;removing&quot; the interface does not affect the object and the event is not fired: &gt;&gt;&gt; event.changeContentType(obj, None) Setting a content type interface on an object that doesn't have one will cause the event to be fired, with the .oldContentType attribute on the event set to None: &gt;&gt;&gt; event.changeContentType(obj, ITextPlain) changed content type interface: from: None to: &lt;InterfaceClass __builtin__.ITextPlain&gt; Calling the changeContentType() function again with the same &quot;new&quot; content type interface causes no change, so the event is not fired again: &gt;&gt;&gt; event.changeContentType(obj, ITextPlain) Providing a new interface does cause the event to be fired again: &gt;&gt;&gt; event.changeContentType(obj, IOctetStream) changed content type interface: from: &lt;InterfaceClass __builtin__.ITextPlain&gt; to: &lt;InterfaceClass __builtin__.IOctetStream&gt; Similarly, removing the content type interface triggers the event as well: &gt;&gt;&gt; event.changeContentType(obj, None) changed content type interface: from: &lt;InterfaceClass __builtin__.IOctetStream&gt; to: None MIME type and character set extraction The zope.mimetype.typegetter module provides a selection of MIME type extractors and charset extractors. These may be used to determine what the MIME type and character set for uploaded data should be. These two interfaces represent the site policy regarding interpreting upload data in the face of missing or inaccurate input. Let's go ahead and import the module: &gt;&gt;&gt; from zope.mimetype import typegetter MIME types There are a number of interesting MIME-type extractors: mimeTypeGetter() A minimal extractor that never attempts to guess. mimeTypeGuesser() An extractor that tries to guess the content type based on the name and data if the input contains no content type information. smartMimeTypeGuesser() An extractor that checks the content for a variety of constructs to try and refine the results of the mimeTypeGuesser(). This is able to do things like check for XHTML that's labelled as HTML in upload data. mimeTypeGetter() We'll start with the simplest, which does no content-based guessing at all, but uses the information provided by the browser directly. If the browser did not provide any content-type information, or if it cannot be parsed, the extractor simply asserts a &quot;safe&quot; MIME type of application/octet-stream. (The rationale for selecting this type is that since there's really nothing productive that can be done with it other than download it, it's impossible to mis-interpret the data.) When there's no information at all about the content, the extractor returns None: &gt;&gt;&gt; print typegetter.mimeTypeGetter() None Providing only the upload filename or data, or both, still produces None, since no guessing is being done: &gt;&gt;&gt; print typegetter.mimeTypeGetter(name=&quot;file.html&quot;) None &gt;&gt;&gt; print typegetter.mimeTypeGetter(data=&quot;&lt;html&gt;...&lt;/html&gt;&quot;) None &gt;&gt;&gt; print typegetter.mimeTypeGetter( ... name=&quot;file.html&quot;, data=&quot;&lt;html&gt;...&lt;/html&gt;&quot;) None If a content type header is available for the input, that is used since that represents explicit input from outside the application server. The major and minor parts of the content type are extracted and returned as a single string: &gt;&gt;&gt; typegetter.mimeTypeGetter(content_type=&quot;text/plain&quot;) 'text/plain' &gt;&gt;&gt; typegetter.mimeTypeGetter(content_type=&quot;text/plain; charset=utf-8&quot;) 'text/plain' If the content-type information is provided but malformed (not in conformance with RFC 2822), it is ignored, since the intent cannot be reliably guessed: &gt;&gt;&gt; print typegetter.mimeTypeGetter(content_type=&quot;foo bar&quot;) None This combines with ignoring the other values that may be provided as expected: &gt;&gt;&gt; print typegetter.mimeTypeGetter( ... name=&quot;file.html&quot;, data=&quot;&lt;html&gt;...&lt;/html&gt;&quot;, content_type=&quot;foo bar&quot;) None mimeTypeGuesser() A more elaborate extractor that tries to work around completely missing information can be found as the mimeTypeGuesser() function. This function will only guess if there is no usable content type information in the input. This extractor can be thought of as having the following pseudo-code: def mimeTypeGuesser(name=None, data=None, content_type=None): type = mimeTypeGetter(name=name, data=data, content_type=content_type) if type is None: type = guess the content type return type Let's see how this affects the results we saw earlier. When there's no input to use, we still get None: &gt;&gt;&gt; print typegetter.mimeTypeGuesser() None Providing only the upload filename or data, or both, now produces a non-None guess for common content types: &gt;&gt;&gt; typegetter.mimeTypeGuesser(name=&quot;file.html&quot;) 'text/html' &gt;&gt;&gt; typegetter.mimeTypeGuesser(data=&quot;&lt;html&gt;...&lt;/html&gt;&quot;) 'text/html' &gt;&gt;&gt; typegetter.mimeTypeGuesser(name=&quot;file.html&quot;, data=&quot;&lt;html&gt;...&lt;/html&gt;&quot;) 'text/html' Note that if the filename and data provided separately produce different MIME types, the result of providing both will be one of those types, but which is unspecified: &gt;&gt;&gt; mt_1 = typegetter.mimeTypeGuesser(name=&quot;file.html&quot;) &gt;&gt;&gt; mt_1 'text/html' &gt;&gt;&gt; mt_2 = typegetter.mimeTypeGuesser(data=&quot;&lt;?xml version='1.0'?&gt;...&quot;) &gt;&gt;&gt; mt_2 'text/xml' &gt;&gt;&gt; mt = typegetter.mimeTypeGuesser( ... data=&quot;&lt;?xml version='1.0'?&gt;...&quot;, name=&quot;file.html&quot;) &gt;&gt;&gt; mt in (mt_1, mt_2) True If a content type header is available for the input, that is used in the same way as for the mimeTypeGetter() function: &gt;&gt;&gt; typegetter.mimeTypeGuesser(content_type=&quot;text/plain&quot;) 'text/plain' &gt;&gt;&gt; typegetter.mimeTypeGuesser(content_type=&quot;text/plain; charset=utf-8&quot;) 'text/plain' If the content-type information is provided but malformed, it is ignored: &gt;&gt;&gt; print typegetter.mimeTypeGetter(content_type=&quot;foo bar&quot;) None When combined with values for the filename or content data, those are still used to provide reasonable guesses for the content type: &gt;&gt;&gt; typegetter.mimeTypeGuesser(name=&quot;file.html&quot;, content_type=&quot;foo bar&quot;) 'text/html' &gt;&gt;&gt; typegetter.mimeTypeGuesser( ... data=&quot;&lt;html&gt;...&lt;/html&gt;&quot;, content_type=&quot;foo bar&quot;) 'text/html' Information from a parsable content-type is still used even if a guess from the data or filename would provide a different or more-refined result: &gt;&gt;&gt; typegetter.mimeTypeGuesser( ... data=&quot;GIF89a...&quot;, content_type=&quot;application/octet-stream&quot;) 'application/octet-stream' smartMimeTypeGuesser() The smartMimeTypeGuesser() function applies more knowledge to the process of determining the MIME-type to use. Essentially, it takes the result of the mimeTypeGuesser() function and attempts to refine the content-type based on various heuristics. We still see the basic behavior that no input produces None: &gt;&gt;&gt; print typegetter.smartMimeTypeGuesser() None An unparsable content-type is still ignored: &gt;&gt;&gt; print typegetter.smartMimeTypeGuesser(content_type=&quot;foo bar&quot;) None The interpretation of uploaded data will be different in at least some interesting cases. For instance, the mimeTypeGuesser() function provides these results for some XHTML input data: &gt;&gt;&gt; typegetter.mimeTypeGuesser( ... data=&quot;&lt;?xml version='1.0' encoding='utf-8'?&gt;&lt;html&gt;...&lt;/html&gt;&quot;, ... name=&quot;file.html&quot;) 'text/html' The smart extractor is able to refine this into more usable data: &gt;&gt;&gt; typegetter.smartMimeTypeGuesser( ... data=&quot;&lt;?xml version='1.0' encoding='utf-8'?&gt;...&quot;, ... name=&quot;file.html&quot;) 'application/xhtml+xml' In this case, the smart extractor has refined the information determined from the filename using information from the uploaded data. The specific approach taken by the extractor is not part of the interface, however. charsetGetter() If you're interested in the character set of textual data, you can use the charsetGetter function (which can also be registered as the ICharsetGetter utility): The simplest case is when the character set is already specified in the content type. &gt;&gt;&gt; typegetter.charsetGetter(content_type='text/plain; charset=mambo-42') 'mambo-42' Note that the charset name is lowercased, because all the default ICharset and ICharsetCodec utilities are registered for lowercase names. &gt;&gt;&gt; typegetter.charsetGetter(content_type='text/plain; charset=UTF-8') 'utf-8' If it isn't, charsetGetter can try to guess by looking at actual data &gt;&gt;&gt; typegetter.charsetGetter(content_type='text/plain', data='just text') 'ascii' &gt;&gt;&gt; typegetter.charsetGetter(content_type='text/plain', data='\xe2\x98\xba') 'utf-8' &gt;&gt;&gt; import codecs &gt;&gt;&gt; typegetter.charsetGetter(data=codecs.BOM_UTF16_BE + '\x12\x34') 'utf-16be' &gt;&gt;&gt; typegetter.charsetGetter(data=codecs.BOM_UTF16_LE + '\x12\x34') 'utf-16le' If the character set cannot be determined, charsetGetter returns None. &gt;&gt;&gt; typegetter.charsetGetter(content_type='text/plain', data='\xff') &gt;&gt;&gt; typegetter.charsetGetter() Source for MIME type interfaces Some sample interfaces have been created in the zope.mimetype.tests module for use in this test. Let's import them: &gt;&gt;&gt; from zope.mimetype.tests import ( ... ISampleContentTypeOne, ISampleContentTypeTwo) The source should only include IContentTypeInterface interfaces that have been registered. Let's register one of these two interfaces so we can test this: &gt;&gt;&gt; import zope.component &gt;&gt;&gt; from zope.mimetype.interfaces import IContentTypeInterface &gt;&gt;&gt; zope.component.provideUtility( ... ISampleContentTypeOne, IContentTypeInterface, name=&quot;type/one&quot;) &gt;&gt;&gt; zope.component.provideUtility( ... ISampleContentTypeOne, IContentTypeInterface, name=&quot;type/two&quot;) We should see that these interfaces are included in the source: &gt;&gt;&gt; from zope.mimetype import source &gt;&gt;&gt; s = source.ContentTypeSource() &gt;&gt;&gt; ISampleContentTypeOne in s True &gt;&gt;&gt; ISampleContentTypeTwo in s False Interfaces that do not implement the IContentTypeInterface are not included in the source: &gt;&gt;&gt; import zope.interface &gt;&gt;&gt; class ISomethingElse(zope.interface.Interface): ... &quot;&quot;&quot;This isn't a content type interface.&quot;&quot;&quot; &gt;&gt;&gt; ISomethingElse in s False The source is iterable, so we can get a list of the values: &gt;&gt;&gt; values = list(s) &gt;&gt;&gt; len(values) 1 &gt;&gt;&gt; values[0] is ISampleContentTypeOne True We can get terms for the allowed values: &gt;&gt;&gt; terms = source.ContentTypeTerms(s, None) &gt;&gt;&gt; t = terms.getTerm(ISampleContentTypeOne) &gt;&gt;&gt; terms.getValue(t.token) is ISampleContentTypeOne True Interfaces that are not in the source cause an error when a term is requested: &gt;&gt;&gt; terms.getTerm(ISomethingElse) Traceback (most recent call last): ... LookupError: value is not an element in the source The term provides a token based on the module name of the interface: &gt;&gt;&gt; t.token 'zope.mimetype.tests.ISampleContentTypeOne' The term also provides the title based on the &quot;title&quot; tagged value from the interface: &gt;&gt;&gt; t.title u'Type One' Each interface provides a list of MIME types with which the interface is associated. The term object provides access to this list: &gt;&gt;&gt; t.mimeTypes ['type/one', 'type/foo'] A list of common extensions for files of this type is also available, though it may be empty: &gt;&gt;&gt; t.extensions [] The term's value, of course, is the interface passed in: &gt;&gt;&gt; t.value is ISampleContentTypeOne True This extended term API is defined by the IContentTypeTerm interface: &gt;&gt;&gt; from zope.mimetype.interfaces import IContentTypeTerm &gt;&gt;&gt; IContentTypeTerm.providedBy(t) True The value can also be retrieved using the getValue() method: &gt;&gt;&gt; iface = terms.getValue('zope.mimetype.tests.ISampleContentTypeOne') &gt;&gt;&gt; iface is ISampleContentTypeOne True Attempting to retrieve an interface that isn't in the source using the terms object generates a LookupError: &gt;&gt;&gt; terms.getValue('zope.mimetype.tests.ISampleContentTypeTwo') Traceback (most recent call last): ... LookupError: token does not represent an element in the source Attempting to look up a junk token also generates an error: &gt;&gt;&gt; terms.getValue('just.some.dotted.name.that.does.not.exist') Traceback (most recent call last): ... LookupError: could not import module for token TranslatableSourceSelectWidget TranslatableSourceSelectWidget is a SourceSelectWidget that translates and sorts the choices. We will borrow the boring set up code from the SourceSelectWidget test (source.txt in zope.formlib). &gt;&gt;&gt; import zope.interface &gt;&gt;&gt; import zope.component &gt;&gt;&gt; import zope.schema &gt;&gt;&gt; import zope.schema.interfaces &gt;&gt;&gt; class SourceList(list): ... zope.interface.implements(zope.schema.interfaces.IIterableSource) &gt;&gt;&gt; import zope.publisher.interfaces.browser &gt;&gt;&gt; from zope.browser.interfaces import ITerms &gt;&gt;&gt; from zope.schema.vocabulary import SimpleTerm &gt;&gt;&gt; class ListTerms: ... ... zope.interface.implements(ITerms) ... ... def __init__(self, source, request): ... pass # We don't actually need the source or the request :) ... ... def getTerm(self, value): ... title = unicode(value) ... try: ... token = title.encode('base64').strip() ... except binascii.Error: ... raise LookupError(token) ... return SimpleTerm(value, token=token, title=title) ... ... def getValue(self, token): ... return token.decode('base64') &gt;&gt;&gt; zope.component.provideAdapter( ... ListTerms, ... (SourceList, zope.publisher.interfaces.browser.IBrowserRequest)) &gt;&gt;&gt; dog = zope.schema.Choice( ... __name__ = 'dog', ... title=u&quot;Dogs&quot;, ... source=SourceList(['spot', 'bowser', 'prince', 'duchess', 'lassie']), ... ) &gt;&gt;&gt; dog = dog.bind(object()) Now that we have a field and a working source, we can construct and render a widget. &gt;&gt;&gt; from zope.mimetype.widget import TranslatableSourceSelectWidget &gt;&gt;&gt; from zope.publisher.browser import TestRequest &gt;&gt;&gt; request = TestRequest() &gt;&gt;&gt; widget = TranslatableSourceSelectWidget( ... dog, dog.source, request) &gt;&gt;&gt; print widget() &lt;div&gt; &lt;div class=&quot;value&quot;&gt; &lt;select id=&quot;field.dog&quot; name=&quot;field.dog&quot; size=&quot;5&quot; &gt; &lt;option value=&quot;Ym93c2Vy&quot;&gt;bowser&lt;/option&gt; &lt;option value=&quot;ZHVjaGVzcw==&quot;&gt;duchess&lt;/option&gt; &lt;option value=&quot;bGFzc2ll&quot;&gt;lassie&lt;/option&gt; &lt;option value=&quot;cHJpbmNl&quot;&gt;prince&lt;/option&gt; &lt;option value=&quot;c3BvdA==&quot;&gt;spot&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;input name=&quot;field.dog-empty-marker&quot; type=&quot;hidden&quot; value=&quot;1&quot; /&gt; &lt;/div&gt; Note that the options are ordered alphabetically. If the field is not required, we will also see a special choice labeled &quot;(nothing selected)&quot; at the top of the list &gt;&gt;&gt; dog.required = False &gt;&gt;&gt; print widget() &lt;div&gt; &lt;div class=&quot;value&quot;&gt; &lt;select id=&quot;field.dog&quot; name=&quot;field.dog&quot; size=&quot;5&quot; &gt; &lt;option selected=&quot;selected&quot; value=&quot;&quot;&gt;(nothing selected)&lt;/option&gt; &lt;option value=&quot;Ym93c2Vy&quot;&gt;bowser&lt;/option&gt; &lt;option value=&quot;ZHVjaGVzcw==&quot;&gt;duchess&lt;/option&gt; &lt;option value=&quot;bGFzc2ll&quot;&gt;lassie&lt;/option&gt; &lt;option value=&quot;cHJpbmNl&quot;&gt;prince&lt;/option&gt; &lt;option value=&quot;c3BvdA==&quot;&gt;spot&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;input name=&quot;field.dog-empty-marker&quot; type=&quot;hidden&quot; value=&quot;1&quot; /&gt; &lt;/div&gt; The utils module contains various helpers for working with data goverened by MIME content type information, as found in the HTTP Content-Type header: mime types and character sets. The decode function takes a string and an IANA character set name and returns a unicode object decoded from the string, using the codec associated with the character set name. Errors will generally arise from the unicode conversion rather than the mapping of character set to codec, and will be LookupErrors (the character set did not cleanly convert to a codec that Python knows about) or UnicodeDecodeErrors (the string included characters that were not in the range of the codec associated with the character set). &gt;&gt;&gt; original = 'This is an o with a slash through it: \xb8.' &gt;&gt;&gt; charset = 'Latin-7' # Baltic Rim or iso-8859-13 &gt;&gt;&gt; from zope.mimetype import utils &gt;&gt;&gt; utils.decode(original, charset) u'This is an o with a slash through it: \xf8.' &gt;&gt;&gt; utils.decode(original, 'foo bar baz') Traceback (most recent call last): ... LookupError: unknown encoding: foo bar baz &gt;&gt;&gt; utils.decode(original, 'iso-ir-6') # alias for ASCII ... # doctest: +ELLIPSIS Traceback (most recent call last): ... UnicodeDecodeError: 'ascii' codec can't decode... CHANGES 1.3.1 (2010-11-10) No longer depending on zope.app.form in configure.zcml by using zope.formlib instead, where the needed interfaces are living now. 1.3.0 (2010-06-26) Added testing dependency on zope.component [test]. Use zope.formlib instead of zope.app.form.browser for select widget. Conform to repository policy. 1.2.0 (2009-12-26) Converted functional tests to unit tests and get rid of all extra test dependencies as a result. Use the ITerms interface from zope.browser. Declared missing dependencies, resolved direct dependency on zope.app.publisher. Import content-type parser from zope.contenttype, adding a dependency on that package. 1.1.2 (2009-05-22) No longer depends on zope.app.component. 1.1.1 (2009-04-03) Fixed wrong package version (version 1.1.0 was released as 0.4.0 at pypi but as 1.1dev at download.zope.org/distribution) Fixed author email and home page address. 1.1.0 (2007-11-01) Package data update. First public release. 1.0.0 (2007-??-??) Initial release. File Type Py Version Uploaded on Size # downloads zope.mimetype-1.3.1.tar.gz (md5) Source 2010-11-10 66KB 410 Author: Zope Foundation and Contributors &lt;zope-dev at zope org&gt; Home Page: http://pypi.python.org/pypi/zope.mimetype Keywords: file content mimetype License: ZPL 2.1 Categories Development Status :: 5 - Production/Stable Environment :: Web Environment Framework :: Zope3 Intended Audience :: Developers License :: OSI Approved :: Zope Public License Natural Language :: English Operating System :: OS Independent Programming Language :: Python Topic :: Internet :: WWW/HTTP Package Index Owner: srichter, ignas, fdrake, philikon, chrism, baijum, J1m, benji, ctheune, projekt01, mgedmin, ccomb, pcardune, hathawsh, faassen, chrisw, nadako, zagy, tseaver, hannosch, icemac, alexsmith, gary, roymath, tlotze, agroszer, menesis DOAP record: zope.mimetype-1.3.1.xml The rating feature has been removed. See catalog-sig for the discussion of this removal. Website maintained by the Python community hosting by xs4all / design by Tim Parkin Copyright © 1990-2011, Python Software Foundation Legal Statements " />
/home/bani/Dropbox/Inbox/__inboxz/ak/Kubuntu/@AK/@FF/Fill profiles/cache.rdf:                   NS1:content="homepage skip to navigation skip to content Package Index Browse packages Package submission List trove classifiers List packages RSS (last 40 updates) Python 3 packages Tutorial Get help Bug reports Comments Developers About News Documentation Download Community Foundation Core Development Links Package Index &gt; zope.mimetype 1.3.1 Not Logged In Login Register Lost Login? Use OpenID Google myOpenID Launchpad zope.mimetype 1.3.1 A simple package for working with MIME content types Downloads ↓ This package provides a way to work with MIME content types. There are several interfaces defined here, many of which are used primarily to look things up based on different bits of information. Contents The Zope MIME Infrastructure Supported lookups Retrieving Content Type Information MIME Types Character Sets Finding Interfaces Codec handling Constraint Functions for Interfaces Single Token MIME Type Minimal IContentInfo Implementation Events and content-type changes MIME type and character set extraction MIME types mimeTypeGetter() mimeTypeGuesser() smartMimeTypeGuesser() charsetGetter() Source for MIME type interfaces TranslatableSourceSelectWidget CHANGES 1.3.1 (2010-11-10) 1.3.0 (2010-06-26) 1.2.0 (2009-12-26) 1.1.2 (2009-05-22) 1.1.1 (2009-04-03) 1.1.0 (2007-11-01) 1.0.0 (2007-??-??) The Zope MIME Infrastructure This package provides a way to work with MIME content types. There are several interfaces defined here, many of which are used primarily to look things up based on different bits of information. The basic idea behind this is that content objects should provide an interface based on the actual content type they implement. For example, objects that represent text/xml or application/xml documents should be marked mark with the IContentTypeXml interface. This can allow additional views to be registered based on the content type, or subscribers may be registered to perform other actions based on the content type. One aspect of the content type that's important for all documents is that the content type interface determines whether the object data is interpreted as an encoded text document. Encoded text documents, in particular, can be decoded to obtain a single Unicode string. The content type intefaces for encoded text must derive from IContentTypeEncoded. (All content type interfaces derive from IContentType and directly provide IContentTypeInterface.) The default configuration provides direct support for a variety of common document types found in office environments. Supported lookups Several different queries are supported by this package: Given a MIME type expressed as a string, the associated interface, if any, can be retrieved using: # `mimeType` is the MIME type as a string interface = queryUtility(IContentTypeInterface, mimeType) Given a charset name, the associated ICodec instance can be retrieved using: # `charsetName` is the charset name as a string codec = queryUtility(ICharsetCodec, charsetName) Given a codec, the preferred charset name can be retrieved using: # `codec` is an `ICodec` instance: charsetName = getUtility(ICodecPreferredCharset, codec.name).name Given any combination of a suggested file name, file data, and content type header, a guess at a reasonable MIME type can be made using: # `filename` is a suggested file name, or None # `data` is uploaded data, or None # `content_type` is a Content-Type header value, or None # mimeType = getUtility(IMimeTypeGetter)( name=filename, data=data, content_type=content_type) Given any combination of a suggested file name, file data, and content type header, a guess at a reasonable charset name can be made using: # `filename` is a suggested file name, or None # `data` is uploaded data, or None # `content_type` is a Content-Type header value, or None # charsetName = getUtility(ICharsetGetter)( name=filename, data=data, content_type=content_type) Retrieving Content Type Information MIME Types We'll start by initializing the interfaces and registrations for the content type interfaces. This is normally done via ZCML. &gt;&gt;&gt; from zope.mimetype import types &gt;&gt;&gt; types.setup() A utility is used to retrieve MIME types. &gt;&gt;&gt; from zope import component &gt;&gt;&gt; from zope.mimetype import typegetter &gt;&gt;&gt; from zope.mimetype.interfaces import IMimeTypeGetter &gt;&gt;&gt; component.provideUtility(typegetter.smartMimeTypeGuesser, ... provides=IMimeTypeGetter) &gt;&gt;&gt; mime_getter = component.getUtility(IMimeTypeGetter) To map a particular file name, file contents, and content type to a MIME type. &gt;&gt;&gt; mime_getter(name='file.txt', data='A text file.', ... content_type='text/plain') 'text/plain' In the default implementation if not enough information is given to discern a MIME type, None is returned. &gt;&gt;&gt; mime_getter() is None True Character Sets A utility is also used to retrieve character sets (charsets). &gt;&gt;&gt; from zope.mimetype.interfaces import ICharsetGetter &gt;&gt;&gt; component.provideUtility(typegetter.charsetGetter, ... provides=ICharsetGetter) &gt;&gt;&gt; charset_getter = component.getUtility(ICharsetGetter) To map a particular file name, file contents, and content type to a charset. &gt;&gt;&gt; charset_getter(name='file.txt', data='This is a text file.', ... content_type='text/plain;charset=ascii') 'ascii' In the default implementation if not enough information is given to discern a charset, None is returned. &gt;&gt;&gt; charset_getter() is None True Finding Interfaces Given a MIME type we need to be able to find the appropriate interface. &gt;&gt;&gt; from zope.mimetype.interfaces import IContentTypeInterface &gt;&gt;&gt; component.getUtility(IContentTypeInterface, name=u'text/plain') &lt;InterfaceClass zope.mimetype.types.IContentTypeTextPlain&gt; It is also possible to enumerate all content type interfaces. &gt;&gt;&gt; utilities = list(component.getUtilitiesFor(IContentTypeInterface)) If you want to find an interface from a MIME string, you can use the utilityies. &gt;&gt;&gt; component.getUtility(IContentTypeInterface, name='text/plain') &lt;InterfaceClass zope.mimetype.types.IContentTypeTextPlain&gt; Codec handling We can create codecs programatically. Codecs are registered as utilities for ICodec with the name of their python codec. &gt;&gt;&gt; from zope import component &gt;&gt;&gt; from zope.mimetype.interfaces import ICodec &gt;&gt;&gt; from zope.mimetype.codec import addCodec &gt;&gt;&gt; sorted(component.getUtilitiesFor(ICodec)) [] &gt;&gt;&gt; addCodec('iso8859-1', 'Western (ISO-8859-1)') &gt;&gt;&gt; codec = component.getUtility(ICodec, name='iso8859-1') &gt;&gt;&gt; codec &lt;zope.mimetype.codec.Codec instance at ...&gt; &gt;&gt;&gt; codec.name 'iso8859-1' &gt;&gt;&gt; addCodec('utf-8', 'Unicode (UTF-8)') &gt;&gt;&gt; codec2 = component.getUtility(ICodec, name='utf-8') We can programmatically add charsets to a given codec. This registers each charset as a named utility for ICharset. It also registers the codec as a utility for ICharsetCodec with the name of the charset. &gt;&gt;&gt; from zope.mimetype.codec import addCharset &gt;&gt;&gt; from zope.mimetype.interfaces import ICharset, ICharsetCodec &gt;&gt;&gt; sorted(component.getUtilitiesFor(ICharset)) [] &gt;&gt;&gt; sorted(component.getUtilitiesFor(ICharsetCodec)) [] &gt;&gt;&gt; addCharset(codec.name, 'latin1') &gt;&gt;&gt; charset = component.getUtility(ICharset, name='latin1') &gt;&gt;&gt; charset &lt;zope.mimetype.codec.Charset instance at ...&gt; &gt;&gt;&gt; charset.name 'latin1' &gt;&gt;&gt; component.getUtility(ICharsetCodec, name='latin1') is codec True When adding a charset we can state that we want that charset to be the preferred charset for its codec. &gt;&gt;&gt; addCharset(codec.name, 'iso8859-1', preferred=True) &gt;&gt;&gt; addCharset(codec2.name, 'utf-8', preferred=True) A codec can have at most one preferred charset. &gt;&gt;&gt; addCharset(codec.name, 'test', preferred=True) Traceback (most recent call last): ... ValueError: Codec already has a preferred charset. Preferred charsets are registered as utilities for ICodecPreferredCharset under the name of the python codec. &gt;&gt;&gt; from zope.mimetype.interfaces import ICodecPreferredCharset &gt;&gt;&gt; preferred = component.getUtility(ICodecPreferredCharset, name='iso8859-1') &gt;&gt;&gt; preferred &lt;zope.mimetype.codec.Charset instance at ...&gt; &gt;&gt;&gt; preferred.name 'iso8859-1' &gt;&gt;&gt; sorted(component.getUtilitiesFor(ICodecPreferredCharset)) [(u'iso8859-1', &lt;zope.mimetype.codec.Charset instance at ...&gt;), (u'utf-8', &lt;zope.mimetype.codec.Charset instance at ...&gt;)] We can look up a codec by the name of its charset: &gt;&gt;&gt; component.getUtility(ICharsetCodec, name='latin1') is codec True &gt;&gt;&gt; component.getUtility(ICharsetCodec, name='utf-8') is codec2 True Or we can look up all codecs: &gt;&gt;&gt; sorted(component.getUtilitiesFor(ICharsetCodec)) [(u'iso8859-1', &lt;zope.mimetype.codec.Codec instance at ...&gt;), (u'latin1', &lt;zope.mimetype.codec.Codec instance at ...&gt;), (u'test', &lt;zope.mimetype.codec.Codec instance at ...&gt;), (u'utf-8', &lt;zope.mimetype.codec.Codec instance at ...&gt;)] Constraint Functions for Interfaces The zope.mimetype.interfaces module defines interfaces that use some helper functions to define constraints on the accepted data. These helpers are used to determine whether values conform to the what's allowed for parts of a MIME type specification and other parts of a Content-Type header as specified in RFC 2045. Single Token The first is the simplest: the tokenConstraint() function returns True if the ASCII string it is passed conforms to the token production in section 5.1 of the RFC. Let's import the function: &gt;&gt;&gt; from zope.mimetype.interfaces import tokenConstraint Typical token are the major and minor parts of the MIME type and the parameter names for the Content-Type header. The function should return True for these values: &gt;&gt;&gt; tokenConstraint(&quot;text&quot;) True &gt;&gt;&gt; tokenConstraint(&quot;plain&quot;) True &gt;&gt;&gt; tokenConstraint(&quot;charset&quot;) True The function should also return True for unusual but otherwise normal token that may be used in some situations: &gt;&gt;&gt; tokenConstraint(&quot;not-your-fathers-token&quot;) True It must also allow extension tokens and vendor-specific tokens: &gt;&gt;&gt; tokenConstraint(&quot;x-magic&quot;) True &gt;&gt;&gt; tokenConstraint(&quot;vnd.zope.special-data&quot;) True Since we expect input handlers to normalize values to lower case, upper case text is not allowed: &gt;&gt;&gt; tokenConstraint(&quot;Text&quot;) False Non-ASCII text is also not allowed: &gt;&gt;&gt; tokenConstraint(&quot;\x80&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;\xC8&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;\xFF&quot;) False Note that lots of characters are allowed in tokens, and there are no constraints that the token &quot;look like&quot; something a person would want to read: &gt;&gt;&gt; tokenConstraint(&quot;.-.-.-.&quot;) True Other characters are disallowed, however, including all forms of whitespace: &gt;&gt;&gt; tokenConstraint(&quot;foo bar&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;foo\tbar&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;foo\nbar&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;foo\rbar&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;foo\x7Fbar&quot;) False Whitespace before or after the token is not accepted either: &gt;&gt;&gt; tokenConstraint(&quot; text&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;plain &quot;) False Other disallowed characters are defined in the tspecials production from the RFC (also in section 5.1): &gt;&gt;&gt; tokenConstraint(&quot;(&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;)&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;&lt;&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;&gt;&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;@&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;,&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;;&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;:&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;\\&quot;) False &gt;&gt;&gt; tokenConstraint('&quot;') False &gt;&gt;&gt; tokenConstraint(&quot;/&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;[&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;]&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;?&quot;) False &gt;&gt;&gt; tokenConstraint(&quot;=&quot;) False A token must contain at least one character, so tokenConstraint() returns false for an empty string: &gt;&gt;&gt; tokenConstraint(&quot;&quot;) False MIME Type A MIME type is specified using two tokens separated by a slash; whitespace between the tokens and the slash must be normalized away in the input handler. The mimeTypeConstraint() function is available to test a normalized MIME type value; let's import that function now: &gt;&gt;&gt; from zope.mimetype.interfaces import mimeTypeConstraint Let's test some common MIME types to make sure the function isn't obviously insane: &gt;&gt;&gt; mimeTypeConstraint(&quot;text/plain&quot;) True &gt;&gt;&gt; mimeTypeConstraint(&quot;application/xml&quot;) True &gt;&gt;&gt; mimeTypeConstraint(&quot;image/svg+xml&quot;) True If parts of the MIME type are missing, it isn't accepted: &gt;&gt;&gt; mimeTypeConstraint(&quot;text&quot;) False &gt;&gt;&gt; mimeTypeConstraint(&quot;text/&quot;) False &gt;&gt;&gt; mimeTypeConstraint(&quot;/plain&quot;) False As for individual tokens, whitespace is not allowed: &gt;&gt;&gt; mimeTypeConstraint(&quot;foo bar/plain&quot;) False &gt;&gt;&gt; mimeTypeConstraint(&quot;text/foo bar&quot;) False Whitespace is not accepted around the slash either: &gt;&gt;&gt; mimeTypeConstraint(&quot;text /plain&quot;) False &gt;&gt;&gt; mimeTypeConstraint(&quot;text/ plain&quot;) False Surrounding whitespace is also not accepted: &gt;&gt;&gt; mimeTypeConstraint(&quot; text/plain&quot;) False &gt;&gt;&gt; mimeTypeConstraint(&quot;text/plain &quot;) False Minimal IContentInfo Implementation The zope.mimetype.contentinfo module provides a minimal IContentInfo implementation that adds no information to what's provided by a content object. This represents the most conservative content-type policy that might be useful. Let's take a look at how this operates by creating a couple of concrete content-type interfaces: &gt;&gt;&gt; from zope.mimetype import interfaces &gt;&gt;&gt; class ITextPlain(interfaces.IContentTypeEncoded): ... &quot;&quot;&quot;text/plain&quot;&quot;&quot; &gt;&gt;&gt; class IApplicationOctetStream(interfaces.IContentType): ... &quot;&quot;&quot;application/octet-stream&quot;&quot;&quot; Now, we'll create a minimal content object that provide the necessary information: &gt;&gt;&gt; import zope.interface &gt;&gt;&gt; class Content(object): ... zope.interface.implements(interfaces.IContentTypeAware) ... ... def __init__(self, mimeType, charset=None): ... self.mimeType = mimeType ... self.parameters = {} ... if charset: ... self.parameters[&quot;charset&quot;] = charset We can now create examples of both encoded and non-encoded content: &gt;&gt;&gt; encoded = Content(&quot;text/plain&quot;, &quot;utf-8&quot;) &gt;&gt;&gt; zope.interface.alsoProvides(encoded, ITextPlain) &gt;&gt;&gt; unencoded = Content(&quot;application/octet-stream&quot;) &gt;&gt;&gt; zope.interface.alsoProvides(unencoded, IApplicationOctetStream) The minimal IContentInfo implementation only exposes the information available to it from the base content object. Let's take a look at the unencoded content first: &gt;&gt;&gt; from zope.mimetype import contentinfo &gt;&gt;&gt; ci = contentinfo.ContentInfo(unencoded) &gt;&gt;&gt; ci.effectiveMimeType 'application/octet-stream' &gt;&gt;&gt; ci.effectiveParameters {} &gt;&gt;&gt; ci.contentType 'application/octet-stream' For unencoded content, there is never a codec: &gt;&gt;&gt; print ci.getCodec() None It is also disallowed to try decoding such content: &gt;&gt;&gt; ci.decode(&quot;foo&quot;) Traceback (most recent call last): ... ValueError: no matching codec found Attemping to decode data using an uncoded object causes an exception to be raised: &gt;&gt;&gt; print ci.decode(&quot;data&quot;) Traceback (most recent call last): ... ValueError: no matching codec found If we try this with encoded data, we get somewhat different behavior: &gt;&gt;&gt; ci = contentinfo.ContentInfo(encoded) &gt;&gt;&gt; ci.effectiveMimeType 'text/plain' &gt;&gt;&gt; ci.effectiveParameters {'charset': 'utf-8'} &gt;&gt;&gt; ci.contentType 'text/plain;charset=utf-8' The getCodec() and decode() methods can be used to handle encoded data using the encoding indicated by the charset parameter. Let's store some UTF-8 data in a variable: &gt;&gt;&gt; utf8_data = unicode(&quot;\xAB\xBB&quot;, &quot;iso-8859-1&quot;).encode(&quot;utf-8&quot;) &gt;&gt;&gt; utf8_data '\xc2\xab\xc2\xbb' We want to be able to decode the data using the IContentInfo object. Let's try getting the corresponding ICodec object using getCodec(): &gt;&gt;&gt; codec = ci.getCodec() Traceback (most recent call last): ... ValueError: unsupported charset: 'utf-8' So, we can't proceed without some further preparation. What we need is to register an ICharset for UTF-8. The ICharset will need a reference (by name) to a ICodec for UTF-8. So let's create those objects and register them: &gt;&gt;&gt; import codecs &gt;&gt;&gt; from zope.mimetype.i18n import _ &gt;&gt;&gt; class Utf8Codec(object): ... zope.interface.implements(interfaces.ICodec) ... ... name = &quot;utf-8&quot; ... title = _(&quot;UTF-8&quot;) ... ... def __init__(self): ... ( self.encode, ... self.decode, ... self.reader, ... self.writer ... ) = codecs.lookup(self.name) &gt;&gt;&gt; utf8_codec = Utf8Codec() &gt;&gt;&gt; class Utf8Charset(object): ... zope.interface.implements(interfaces.ICharset) ... ... name = utf8_codec.name ... encoding = name &gt;&gt;&gt; utf8_charset = Utf8Charset() &gt;&gt;&gt; import zope.component &gt;&gt;&gt; zope.component.provideUtility( ... utf8_codec, interfaces.ICodec, utf8_codec.name) &gt;&gt;&gt; zope.component.provideUtility( ... utf8_charset, interfaces.ICharset, utf8_charset.name) Now that that's been initialized, let's try getting the codec again: &gt;&gt;&gt; codec = ci.getCodec() &gt;&gt;&gt; codec.name 'utf-8' &gt;&gt;&gt; codec.decode(utf8_data) (u'\xab\xbb', 4) We can now check that the decode() method of the IContentInfo will decode the entire data, returning the Unicode representation of the text: &gt;&gt;&gt; ci.decode(utf8_data) u'\xab\xbb' Another possibilty, of course, is that you have content that you know is encoded text of some sort, but you don't actually know what encoding it's in: &gt;&gt;&gt; encoded2 = Content(&quot;text/plain&quot;) &gt;&gt;&gt; zope.interface.alsoProvides(encoded2, ITextPlain) &gt;&gt;&gt; ci = contentinfo.ContentInfo(encoded2) &gt;&gt;&gt; ci.effectiveMimeType 'text/plain' &gt;&gt;&gt; ci.effectiveParameters {} &gt;&gt;&gt; ci.contentType 'text/plain' &gt;&gt;&gt; ci.getCodec() Traceback (most recent call last): ... ValueError: charset not known It's also possible that the initial content type information for an object is incorrect for some reason. If the browser provides a content type of &quot;text/plain; charset=utf-8&quot;, the content will be seen as encoded. A user correcting this content type using UI elements can cause the content to be considered un-encoded. At this point, there should no longer be a charset parameter to the content type, and the content info object should reflect this, though the previous encoding information will be retained in case the content type should be changed to an encoded type in the future. Let's see how this behavior will be exhibited in this API. We'll start by creating some encoded content: &gt;&gt;&gt; content = Content(&quot;text/plain&quot;, &quot;utf-8&quot;) &gt;&gt;&gt; zope.interface.alsoProvides(content, ITextPlain) We can see that the encoding information is included in the effective MIME type information provided by the content-info object: &gt;&gt;&gt; ci = contentinfo.ContentInfo(content) &gt;&gt;&gt; ci.effectiveMimeType 'text/plain' &gt;&gt;&gt; ci.effectiveParameters {'charset': 'utf-8'} We now change the content type information for the object: &gt;&gt;&gt; ifaces = zope.interface.directlyProvidedBy(content) &gt;&gt;&gt; ifaces -= ITextPlain &gt;&gt;&gt; ifaces += IApplicationOctetStream &gt;&gt;&gt; zope.interface.directlyProvides(content, *ifaces) &gt;&gt;&gt; content.mimeType = 'application/octet-stream' At this point, a content type object would provide different information: &gt;&gt;&gt; ci = contentinfo.ContentInfo(content) &gt;&gt;&gt; ci.effectiveMimeType 'application/octet-stream' &gt;&gt;&gt; ci.effectiveParameters {} The underlying content type parameters still contain the original encoding information, however: &gt;&gt;&gt; content.parameters {'charset': 'utf-8'} Events and content-type changes The IContentTypeChangedEvent is fired whenever an object's IContentTypeInterface is changed. This includes the cases when a content type interface is applied to an object that doesn't have one, and when the content type interface is removed from an object. Let's start the demonstration by defining a subscriber for the event that simply prints out the information from the event object: &gt;&gt;&gt; def handler(event): ... print &quot;changed content type interface:&quot; ... print &quot; from:&quot;, event.oldContentType ... print &quot; to:&quot;, event.newContentType We'll also define a simple content object: &gt;&gt;&gt; import zope.interface &gt;&gt;&gt; class IContent(zope.interface.Interface): ... pass &gt;&gt;&gt; class Content(object): ... ... zope.interface.implements(IContent) ... ... def __str__(self): ... return &quot;&lt;MyContent&gt;&quot; &gt;&gt;&gt; obj = Content() We'll also need a couple of content type interfaces: &gt;&gt;&gt; from zope.mimetype import interfaces &gt;&gt;&gt; class ITextPlain(interfaces.IContentTypeEncoded): ... &quot;&quot;&quot;text/plain&quot;&quot;&quot; &gt;&gt;&gt; ITextPlain.setTaggedValue(&quot;mimeTypes&quot;, [&quot;text/plain&quot;]) &gt;&gt;&gt; ITextPlain.setTaggedValue(&quot;extensions&quot;, [&quot;.txt&quot;]) &gt;&gt;&gt; zope.interface.directlyProvides( ... ITextPlain, interfaces.IContentTypeInterface) &gt;&gt;&gt; class IOctetStream(interfaces.IContentType): ... &quot;&quot;&quot;application/octet-stream&quot;&quot;&quot; &gt;&gt;&gt; IOctetStream.setTaggedValue(&quot;mimeTypes&quot;, [&quot;application/octet-stream&quot;]) &gt;&gt;&gt; IOctetStream.setTaggedValue(&quot;extensions&quot;, [&quot;.bin&quot;]) &gt;&gt;&gt; zope.interface.directlyProvides( ... IOctetStream, interfaces.IContentTypeInterface) Let's register our subscriber: &gt;&gt;&gt; import zope.component &gt;&gt;&gt; import zope.component.interfaces &gt;&gt;&gt; zope.component.provideHandler( ... handler, ... (zope.component.interfaces.IObjectEvent,)) Changing the content type interface on an object is handled by the zope.mimetype.event.changeContentType() function. Let's import that module and demonstrate that the expected event is fired appropriately: &gt;&gt;&gt; from zope.mimetype import event Since the object currently has no content type interface, &quot;removing&quot; the interface does not affect the object and the event is not fired: &gt;&gt;&gt; event.changeContentType(obj, None) Setting a content type interface on an object that doesn't have one will cause the event to be fired, with the .oldContentType attribute on the event set to None: &gt;&gt;&gt; event.changeContentType(obj, ITextPlain) changed content type interface: from: None to: &lt;InterfaceClass __builtin__.ITextPlain&gt; Calling the changeContentType() function again with the same &quot;new&quot; content type interface causes no change, so the event is not fired again: &gt;&gt;&gt; event.changeContentType(obj, ITextPlain) Providing a new interface does cause the event to be fired again: &gt;&gt;&gt; event.changeContentType(obj, IOctetStream) changed content type interface: from: &lt;InterfaceClass __builtin__.ITextPlain&gt; to: &lt;InterfaceClass __builtin__.IOctetStream&gt; Similarly, removing the content type interface triggers the event as well: &gt;&gt;&gt; event.changeContentType(obj, None) changed content type interface: from: &lt;InterfaceClass __builtin__.IOctetStream&gt; to: None MIME type and character set extraction The zope.mimetype.typegetter module provides a selection of MIME type extractors and charset extractors. These may be used to determine what the MIME type and character set for uploaded data should be. These two interfaces represent the site policy regarding interpreting upload data in the face of missing or inaccurate input. Let's go ahead and import the module: &gt;&gt;&gt; from zope.mimetype import typegetter MIME types There are a number of interesting MIME-type extractors: mimeTypeGetter() A minimal extractor that never attempts to guess. mimeTypeGuesser() An extractor that tries to guess the content type based on the name and data if the input contains no content type information. smartMimeTypeGuesser() An extractor that checks the content for a variety of constructs to try and refine the results of the mimeTypeGuesser(). This is able to do things like check for XHTML that's labelled as HTML in upload data. mimeTypeGetter() We'll start with the simplest, which does no content-based guessing at all, but uses the information provided by the browser directly. If the browser did not provide any content-type information, or if it cannot be parsed, the extractor simply asserts a &quot;safe&quot; MIME type of application/octet-stream. (The rationale for selecting this type is that since there's really nothing productive that can be done with it other than download it, it's impossible to mis-interpret the data.) When there's no information at all about the content, the extractor returns None: &gt;&gt;&gt; print typegetter.mimeTypeGetter() None Providing only the upload filename or data, or both, still produces None, since no guessing is being done: &gt;&gt;&gt; print typegetter.mimeTypeGetter(name=&quot;file.html&quot;) None &gt;&gt;&gt; print typegetter.mimeTypeGetter(data=&quot;&lt;html&gt;...&lt;/html&gt;&quot;) None &gt;&gt;&gt; print typegetter.mimeTypeGetter( ... name=&quot;file.html&quot;, data=&quot;&lt;html&gt;...&lt;/html&gt;&quot;) None If a content type header is available for the input, that is used since that represents explicit input from outside the application server. The major and minor parts of the content type are extracted and returned as a single string: &gt;&gt;&gt; typegetter.mimeTypeGetter(content_type=&quot;text/plain&quot;) 'text/plain' &gt;&gt;&gt; typegetter.mimeTypeGetter(content_type=&quot;text/plain; charset=utf-8&quot;) 'text/plain' If the content-type information is provided but malformed (not in conformance with RFC 2822), it is ignored, since the intent cannot be reliably guessed: &gt;&gt;&gt; print typegetter.mimeTypeGetter(content_type=&quot;foo bar&quot;) None This combines with ignoring the other values that may be provided as expected: &gt;&gt;&gt; print typegetter.mimeTypeGetter( ... name=&quot;file.html&quot;, data=&quot;&lt;html&gt;...&lt;/html&gt;&quot;, content_type=&quot;foo bar&quot;) None mimeTypeGuesser() A more elaborate extractor that tries to work around completely missing information can be found as the mimeTypeGuesser() function. This function will only guess if there is no usable content type information in the input. This extractor can be thought of as having the following pseudo-code: def mimeTypeGuesser(name=None, data=None, content_type=None): type = mimeTypeGetter(name=name, data=data, content_type=content_type) if type is None: type = guess the content type return type Let's see how this affects the results we saw earlier. When there's no input to use, we still get None: &gt;&gt;&gt; print typegetter.mimeTypeGuesser() None Providing only the upload filename or data, or both, now produces a non-None guess for common content types: &gt;&gt;&gt; typegetter.mimeTypeGuesser(name=&quot;file.html&quot;) 'text/html' &gt;&gt;&gt; typegetter.mimeTypeGuesser(data=&quot;&lt;html&gt;...&lt;/html&gt;&quot;) 'text/html' &gt;&gt;&gt; typegetter.mimeTypeGuesser(name=&quot;file.html&quot;, data=&quot;&lt;html&gt;...&lt;/html&gt;&quot;) 'text/html' Note that if the filename and data provided separately produce different MIME types, the result of providing both will be one of those types, but which is unspecified: &gt;&gt;&gt; mt_1 = typegetter.mimeTypeGuesser(name=&quot;file.html&quot;) &gt;&gt;&gt; mt_1 'text/html' &gt;&gt;&gt; mt_2 = typegetter.mimeTypeGuesser(data=&quot;&lt;?xml version='1.0'?&gt;...&quot;) &gt;&gt;&gt; mt_2 'text/xml' &gt;&gt;&gt; mt = typegetter.mimeTypeGuesser( ... data=&quot;&lt;?xml version='1.0'?&gt;...&quot;, name=&quot;file.html&quot;) &gt;&gt;&gt; mt in (mt_1, mt_2) True If a content type header is available for the input, that is used in the same way as for the mimeTypeGetter() function: &gt;&gt;&gt; typegetter.mimeTypeGuesser(content_type=&quot;text/plain&quot;) 'text/plain' &gt;&gt;&gt; typegetter.mimeTypeGuesser(content_type=&quot;text/plain; charset=utf-8&quot;) 'text/plain' If the content-type information is provided but malformed, it is ignored: &gt;&gt;&gt; print typegetter.mimeTypeGetter(content_type=&quot;foo bar&quot;) None When combined with values for the filename or content data, those are still used to provide reasonable guesses for the content type: &gt;&gt;&gt; typegetter.mimeTypeGuesser(name=&quot;file.html&quot;, content_type=&quot;foo bar&quot;) 'text/html' &gt;&gt;&gt; typegetter.mimeTypeGuesser( ... data=&quot;&lt;html&gt;...&lt;/html&gt;&quot;, content_type=&quot;foo bar&quot;) 'text/html' Information from a parsable content-type is still used even if a guess from the data or filename would provide a different or more-refined result: &gt;&gt;&gt; typegetter.mimeTypeGuesser( ... data=&quot;GIF89a...&quot;, content_type=&quot;application/octet-stream&quot;) 'application/octet-stream' smartMimeTypeGuesser() The smartMimeTypeGuesser() function applies more knowledge to the process of determining the MIME-type to use. Essentially, it takes the result of the mimeTypeGuesser() function and attempts to refine the content-type based on various heuristics. We still see the basic behavior that no input produces None: &gt;&gt;&gt; print typegetter.smartMimeTypeGuesser() None An unparsable content-type is still ignored: &gt;&gt;&gt; print typegetter.smartMimeTypeGuesser(content_type=&quot;foo bar&quot;) None The interpretation of uploaded data will be different in at least some interesting cases. For instance, the mimeTypeGuesser() function provides these results for some XHTML input data: &gt;&gt;&gt; typegetter.mimeTypeGuesser( ... data=&quot;&lt;?xml version='1.0' encoding='utf-8'?&gt;&lt;html&gt;...&lt;/html&gt;&quot;, ... name=&quot;file.html&quot;) 'text/html' The smart extractor is able to refine this into more usable data: &gt;&gt;&gt; typegetter.smartMimeTypeGuesser( ... data=&quot;&lt;?xml version='1.0' encoding='utf-8'?&gt;...&quot;, ... name=&quot;file.html&quot;) 'application/xhtml+xml' In this case, the smart extractor has refined the information determined from the filename using information from the uploaded data. The specific approach taken by the extractor is not part of the interface, however. charsetGetter() If you're interested in the character set of textual data, you can use the charsetGetter function (which can also be registered as the ICharsetGetter utility): The simplest case is when the character set is already specified in the content type. &gt;&gt;&gt; typegetter.charsetGetter(content_type='text/plain; charset=mambo-42') 'mambo-42' Note that the charset name is lowercased, because all the default ICharset and ICharsetCodec utilities are registered for lowercase names. &gt;&gt;&gt; typegetter.charsetGetter(content_type='text/plain; charset=UTF-8') 'utf-8' If it isn't, charsetGetter can try to guess by looking at actual data &gt;&gt;&gt; typegetter.charsetGetter(content_type='text/plain', data='just text') 'ascii' &gt;&gt;&gt; typegetter.charsetGetter(content_type='text/plain', data='\xe2\x98\xba') 'utf-8' &gt;&gt;&gt; import codecs &gt;&gt;&gt; typegetter.charsetGetter(data=codecs.BOM_UTF16_BE + '\x12\x34') 'utf-16be' &gt;&gt;&gt; typegetter.charsetGetter(data=codecs.BOM_UTF16_LE + '\x12\x34') 'utf-16le' If the character set cannot be determined, charsetGetter returns None. &gt;&gt;&gt; typegetter.charsetGetter(content_type='text/plain', data='\xff') &gt;&gt;&gt; typegetter.charsetGetter() Source for MIME type interfaces Some sample interfaces have been created in the zope.mimetype.tests module for use in this test. Let's import them: &gt;&gt;&gt; from zope.mimetype.tests import ( ... ISampleContentTypeOne, ISampleContentTypeTwo) The source should only include IContentTypeInterface interfaces that have been registered. Let's register one of these two interfaces so we can test this: &gt;&gt;&gt; import zope.component &gt;&gt;&gt; from zope.mimetype.interfaces import IContentTypeInterface &gt;&gt;&gt; zope.component.provideUtility( ... ISampleContentTypeOne, IContentTypeInterface, name=&quot;type/one&quot;) &gt;&gt;&gt; zope.component.provideUtility( ... ISampleContentTypeOne, IContentTypeInterface, name=&quot;type/two&quot;) We should see that these interfaces are included in the source: &gt;&gt;&gt; from zope.mimetype import source &gt;&gt;&gt; s = source.ContentTypeSource() &gt;&gt;&gt; ISampleContentTypeOne in s True &gt;&gt;&gt; ISampleContentTypeTwo in s False Interfaces that do not implement the IContentTypeInterface are not included in the source: &gt;&gt;&gt; import zope.interface &gt;&gt;&gt; class ISomethingElse(zope.interface.Interface): ... &quot;&quot;&quot;This isn't a content type interface.&quot;&quot;&quot; &gt;&gt;&gt; ISomethingElse in s False The source is iterable, so we can get a list of the values: &gt;&gt;&gt; values = list(s) &gt;&gt;&gt; len(values) 1 &gt;&gt;&gt; values[0] is ISampleContentTypeOne True We can get terms for the allowed values: &gt;&gt;&gt; terms = source.ContentTypeTerms(s, None) &gt;&gt;&gt; t = terms.getTerm(ISampleContentTypeOne) &gt;&gt;&gt; terms.getValue(t.token) is ISampleContentTypeOne True Interfaces that are not in the source cause an error when a term is requested: &gt;&gt;&gt; terms.getTerm(ISomethingElse) Traceback (most recent call last): ... LookupError: value is not an element in the source The term provides a token based on the module name of the interface: &gt;&gt;&gt; t.token 'zope.mimetype.tests.ISampleContentTypeOne' The term also provides the title based on the &quot;title&quot; tagged value from the interface: &gt;&gt;&gt; t.title u'Type One' Each interface provides a list of MIME types with which the interface is associated. The term object provides access to this list: &gt;&gt;&gt; t.mimeTypes ['type/one', 'type/foo'] A list of common extensions for files of this type is also available, though it may be empty: &gt;&gt;&gt; t.extensions [] The term's value, of course, is the interface passed in: &gt;&gt;&gt; t.value is ISampleContentTypeOne True This extended term API is defined by the IContentTypeTerm interface: &gt;&gt;&gt; from zope.mimetype.interfaces import IContentTypeTerm &gt;&gt;&gt; IContentTypeTerm.providedBy(t) True The value can also be retrieved using the getValue() method: &gt;&gt;&gt; iface = terms.getValue('zope.mimetype.tests.ISampleContentTypeOne') &gt;&gt;&gt; iface is ISampleContentTypeOne True Attempting to retrieve an interface that isn't in the source using the terms object generates a LookupError: &gt;&gt;&gt; terms.getValue('zope.mimetype.tests.ISampleContentTypeTwo') Traceback (most recent call last): ... LookupError: token does not represent an element in the source Attempting to look up a junk token also generates an error: &gt;&gt;&gt; terms.getValue('just.some.dotted.name.that.does.not.exist') Traceback (most recent call last): ... LookupError: could not import module for token TranslatableSourceSelectWidget TranslatableSourceSelectWidget is a SourceSelectWidget that translates and sorts the choices. We will borrow the boring set up code from the SourceSelectWidget test (source.txt in zope.formlib). &gt;&gt;&gt; import zope.interface &gt;&gt;&gt; import zope.component &gt;&gt;&gt; import zope.schema &gt;&gt;&gt; import zope.schema.interfaces &gt;&gt;&gt; class SourceList(list): ... zope.interface.implements(zope.schema.interfaces.IIterableSource) &gt;&gt;&gt; import zope.publisher.interfaces.browser &gt;&gt;&gt; from zope.browser.interfaces import ITerms &gt;&gt;&gt; from zope.schema.vocabulary import SimpleTerm &gt;&gt;&gt; class ListTerms: ... ... zope.interface.implements(ITerms) ... ... def __init__(self, source, request): ... pass # We don't actually need the source or the request :) ... ... def getTerm(self, value): ... title = unicode(value) ... try: ... token = title.encode('base64').strip() ... except binascii.Error: ... raise LookupError(token) ... return SimpleTerm(value, token=token, title=title) ... ... def getValue(self, token): ... return token.decode('base64') &gt;&gt;&gt; zope.component.provideAdapter( ... ListTerms, ... (SourceList, zope.publisher.interfaces.browser.IBrowserRequest)) &gt;&gt;&gt; dog = zope.schema.Choice( ... __name__ = 'dog', ... title=u&quot;Dogs&quot;, ... source=SourceList(['spot', 'bowser', 'prince', 'duchess', 'lassie']), ... ) &gt;&gt;&gt; dog = dog.bind(object()) Now that we have a field and a working source, we can construct and render a widget. &gt;&gt;&gt; from zope.mimetype.widget import TranslatableSourceSelectWidget &gt;&gt;&gt; from zope.publisher.browser import TestRequest &gt;&gt;&gt; request = TestRequest() &gt;&gt;&gt; widget = TranslatableSourceSelectWidget( ... dog, dog.source, request) &gt;&gt;&gt; print widget() &lt;div&gt; &lt;div class=&quot;value&quot;&gt; &lt;select id=&quot;field.dog&quot; name=&quot;field.dog&quot; size=&quot;5&quot; &gt; &lt;option value=&quot;Ym93c2Vy&quot;&gt;bowser&lt;/option&gt; &lt;option value=&quot;ZHVjaGVzcw==&quot;&gt;duchess&lt;/option&gt; &lt;option value=&quot;bGFzc2ll&quot;&gt;lassie&lt;/option&gt; &lt;option value=&quot;cHJpbmNl&quot;&gt;prince&lt;/option&gt; &lt;option value=&quot;c3BvdA==&quot;&gt;spot&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;input name=&quot;field.dog-empty-marker&quot; type=&quot;hidden&quot; value=&quot;1&quot; /&gt; &lt;/div&gt; Note that the options are ordered alphabetically. If the field is not required, we will also see a special choice labeled &quot;(nothing selected)&quot; at the top of the list &gt;&gt;&gt; dog.required = False &gt;&gt;&gt; print widget() &lt;div&gt; &lt;div class=&quot;value&quot;&gt; &lt;select id=&quot;field.dog&quot; name=&quot;field.dog&quot; size=&quot;5&quot; &gt; &lt;option selected=&quot;selected&quot; value=&quot;&quot;&gt;(nothing selected)&lt;/option&gt; &lt;option value=&quot;Ym93c2Vy&quot;&gt;bowser&lt;/option&gt; &lt;option value=&quot;ZHVjaGVzcw==&quot;&gt;duchess&lt;/option&gt; &lt;option value=&quot;bGFzc2ll&quot;&gt;lassie&lt;/option&gt; &lt;option value=&quot;cHJpbmNl&quot;&gt;prince&lt;/option&gt; &lt;option value=&quot;c3BvdA==&quot;&gt;spot&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;input name=&quot;field.dog-empty-marker&quot; type=&quot;hidden&quot; value=&quot;1&quot; /&gt; &lt;/div&gt; The utils module contains various helpers for working with data goverened by MIME content type information, as found in the HTTP Content-Type header: mime types and character sets. The decode function takes a string and an IANA character set name and returns a unicode object decoded from the string, using the codec associated with the character set name. Errors will generally arise from the unicode conversion rather than the mapping of character set to codec, and will be LookupErrors (the character set did not cleanly convert to a codec that Python knows about) or UnicodeDecodeErrors (the string included characters that were not in the range of the codec associated with the character set). &gt;&gt;&gt; original = 'This is an o with a slash through it: \xb8.' &gt;&gt;&gt; charset = 'Latin-7' # Baltic Rim or iso-8859-13 &gt;&gt;&gt; from zope.mimetype import utils &gt;&gt;&gt; utils.decode(original, charset) u'This is an o with a slash through it: \xf8.' &gt;&gt;&gt; utils.decode(original, 'foo bar baz') Traceback (most recent call last): ... LookupError: unknown encoding: foo bar baz &gt;&gt;&gt; utils.decode(original, 'iso-ir-6') # alias for ASCII ... # doctest: +ELLIPSIS Traceback (most recent call last): ... UnicodeDecodeError: 'ascii' codec can't decode... CHANGES 1.3.1 (2010-11-10) No longer depending on zope.app.form in configure.zcml by using zope.formlib instead, where the needed interfaces are living now. 1.3.0 (2010-06-26) Added testing dependency on zope.component [test]. Use zope.formlib instead of zope.app.form.browser for select widget. Conform to repository policy. 1.2.0 (2009-12-26) Converted functional tests to unit tests and get rid of all extra test dependencies as a result. Use the ITerms interface from zope.browser. Declared missing dependencies, resolved direct dependency on zope.app.publisher. Import content-type parser from zope.contenttype, adding a dependency on that package. 1.1.2 (2009-05-22) No longer depends on zope.app.component. 1.1.1 (2009-04-03) Fixed wrong package version (version 1.1.0 was released as 0.4.0 at pypi but as 1.1dev at download.zope.org/distribution) Fixed author email and home page address. 1.1.0 (2007-11-01) Package data update. First public release. 1.0.0 (2007-??-??) Initial release. File Type Py Version Uploaded on Size # downloads zope.mimetype-1.3.1.tar.gz (md5) Source 2010-11-10 66KB 410 Author: Zope Foundation and Contributors &lt;zope-dev at zope org&gt; Home Page: http://pypi.python.org/pypi/zope.mimetype Keywords: file content mimetype License: ZPL 2.1 Categories Development Status :: 5 - Production/Stable Environment :: Web Environment Framework :: Zope3 Intended Audience :: Developers License :: OSI Approved :: Zope Public License Natural Language :: English Operating System :: OS Independent Programming Language :: Python Topic :: Internet :: WWW/HTTP Package Index Owner: srichter, ignas, fdrake, philikon, chrism, baijum, J1m, benji, ctheune, projekt01, mgedmin, ccomb, pcardune, hathawsh, faassen, chrisw, nadako, zagy, tseaver, hannosch, icemac, alexsmith, gary, roymath, tlotze, agroszer, menesis DOAP record: zope.mimetype-1.3.1.xml The rating feature has been removed. See catalog-sig for the di